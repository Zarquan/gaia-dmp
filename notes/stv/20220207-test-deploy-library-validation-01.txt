#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#


    Target:

        Test a GaiaDMP deployment with benchmarks. Include Library validation notebook in benchmarks

    Result:
  
        SUCCESS (1 SLOW Notebook)




# -----------------------------------------------------
# Fetch target branch
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"
      	git checkout 'feature/add-library-test'


        # Edit the test configuration..

        nano deployments/zeppelin/test/config/notebooks.json

        # Remove the last two notebooks listed here as they take several hours to complete..
           ...
             {
                "name" : "QC_cuts_dev.json",
                "filepath" : "https://raw.githubusercontent.com/wfau/aglais-testing/main/notebooks/public_examples/QC_cuts_dev.json",
                "totaltime" : 4700,
                "results" : []
             },
             {
                "name" : "WD_detection_dev.json",
                "filepath" : "https://raw.githubusercontent.com/wfau/aglais-testing/main/notebooks/public_examples/WD_detection_dev.json",
                "totaltime" : 3750,
                "results" : []
             },
           ..
            

    popd

	




# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2021.08.25 \
        bash


# -----------------------------------------------------
# Set the cloud and configuration.
#[root@ansibler]

    cloudname=iris-gaia-red

    configname=zeppelin-27.45-spark-6.27.45

# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}" \


# -----------------------------------------------------
# Create everything, using the new config.
# Using 'test' to run the built-in tests.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
            'test' \
        | tee /tmp/create-all.log

..


> 
TASK [Run benchmarker] **************************************************************************************************************************************************************************************
changed: [localhost] => {"changed": true, "cmd": "python3 /tmp/run-test.py | tee /tmp/test-result.json", "delta": "0:10:17.599725", "end": "2022-02-07 13:26:09.217505", "rc": 0, "start": "2022-02-07 13:15:51.617780", "stderr": "", "stderr_lines": [], "stdout": "Test completed after: 617.47 seconds\n{'SetUp': {'totaltime': '41.27', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 'Mean_proper_motions_over_the_sky': {'totaltime': '43.65', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '507.02', 'status': 'SLOW', 'msg': '', 'valid': 'TRUE'}, 'Source_counts_over_the_sky.json': {'totaltime': '19.20', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 'Library Validation': {'totaltime': '6.33', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}}", "stdout_lines": ["Test completed after: 617.47 seconds", "{'SetUp': {'totaltime': '41.27', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 'Mean_proper_motions_over_the_sky': {'totaltime': '43.65', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '507.02', 'status': 'SLOW', 'msg': '', 'valid': 'TRUE'}, 'Source_counts_over_the_sky.json': {'totaltime': '19.20', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 'Library Validation': {'totaltime': '6.33', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}}"]}

PLAY RECAP **************************************************************************************************************************************************************************************************
localhost                  : ok=9    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   



# -----------------------------------------------------
# Test Results:


'SetUp': {'totaltime': '41.27', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 
'Mean_proper_motions_over_the_sky': {'totaltime': '43.65', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 
'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '507.02', 'status': 'SLOW', 'msg': '', 'valid': 'TRUE'}, 
'Source_counts_over_the_sky.json': {'totaltime': '19.20', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 
'Library Validation': {'totaltime': '6.33', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}}"



# Note that I also tried changing the version of one of the packages (astroquery upgraded to 0.4.4) and then re-running the test to check if the Library validation notebook will catch the error:


'Library Validation': {
    'totaltime': '5.64', 'status': 'ERROR', 
    'msg': 'Fail to execute line 6: assert astroquery.__version__ == \"0.4.1\"\
           Traceback (most recent call last):\
            File \"/tmp/1644238363239-0/zeppelin_python.py\", line 158, in <module>\
              exec(code, _zcUserQueryNameSpace)\
                File \"<stdin>\", line 6, in <module>\
           AssertionError', 
    'valid': 'TRUE'}}"


# This confirms that we can catch the missmatch, however the output message is ugly unfortunately, could use some parsing/pretty printing at some point.

