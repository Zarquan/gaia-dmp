#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#

    Target:

        Run benchmark tests via Ansible


    Result:

       SUCCESS


# -----------------------------------------------------
# Fetch target branch
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"
	git checkout 'issue-benchmarking'

    popd

	

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

 
    source "${HOME:?}/aglais.env"

    docker run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2021.08.25 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudname=gaia-test


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

	> Done

	> real	3m48.394s
	> user	0m46.416s
	> sys	0m4.422s


# -----------------------------------------------------
# Create everything, using a standard config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            'cclake-medium-04' \
            'test'

TASK [Run benchmarker] **************************************************************************************************************************************************************************************
changed: [monitor] => {"changed": true, "cmd": ["python", "/tmp/run-test.py"], "delta": "4:46:47.879708", "end": "2021-10-13 21:15:25.260592", "rc": 0, "start": "2021-10-13 16:28:37.380884", "stderr": "", "stderr_lines": [], "stdout": "Test completed after: 17207.59 seconds\n{u'Mean_proper_motions_over_the_sky': {'totaltime': '63.75', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'SetUp': {'totaltime': '42.83', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'Source_counts_over_the_sky.json': {'totaltime': '21.17', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'QC_cuts_dev.json': {'totaltime': '6572.31', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'WD_detection_dev.json': {'totaltime': '9976.49', 'status': 'SLOW', 'valid': 'TRUE', 'msg': ''}, u'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '531.04', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}}", "stdout_lines": ["Test completed after: 17207.59 seconds", "{u'Mean_proper_motions_over_the_sky': {'totaltime': '63.75', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'SetUp': {'totaltime': '42.83', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'Source_counts_over_the_sky.json': {'totaltime': '21.17', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'QC_cuts_dev.json': {'totaltime': '6572.31', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'WD_detection_dev.json': {'totaltime': '9976.49', 'status': 'SLOW', 'valid': 'TRUE', 'msg': ''}, u'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '531.04', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}}"]}

PLAY RECAP **************************************************************************************************************************************************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
monitor                    : ok=6    changed=5    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

/

	> real	329m17.950s
	> user	60m8.987s
	> sys	8m6.424s

{u'Mean_proper_motions_over_the_sky': {'totaltime': '63.75', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'SetUp': {'totaltime': '42.83', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'Source_counts_over_the_sky.json': {'totaltime': '21.17', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'QC_cuts_dev.json': {'totaltime': '6572.31', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'WD_detection_dev.json': {'totaltime': '9976.49', 'status': 'SLOW', 'valid': 'TRUE', 'msg': ''}, u'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '531.04', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}}", "stdout_lines": ["Test completed after: 17207.59 seconds", "{u'Mean_proper_motions_over_the_sky': {'totaltime': '63.75', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'SetUp': {'totaltime': '42.83', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'Source_counts_over_the_sky.json': {'totaltime': '21.17', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'QC_cuts_dev.json': {'totaltime': '6572.31', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'WD_detection_dev.json': {'totaltime': '9976.49', 'status': 'SLOW', 'valid': 'TRUE', 'msg': ''}, u'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '531.04', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}}


# Is there a better way to output the results for readability? (Definitely..)	


# Results:		

	'Mean_proper_motions_over_the_sky': {'totaltime': '63.75', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''},
	'SetUp': {'totaltime': '42.83', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, 
	'Source_counts_over_the_sky.json': {'totaltime': '21.17', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, 
	'QC_cuts_dev.json': {'totaltime': '6572.31', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, 
	'WD_detection_dev.json': {'totaltime': '9976.49', 'status': 'SLOW', 'valid': 'TRUE', 'msg': ''}, 
	'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '531.04', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}


# First time QC_cuts_dev & WD_detection_dev work, so keep track of duration
# Try the same tests with the large deploy, and take the lowest value between the two

