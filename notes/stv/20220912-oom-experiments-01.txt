#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#



# Target: Run various configurations to try to run the notebook provided by Nigel (Work in progress with Gaia XP spectra) successfully
#    The following two cells fails for the existing configuration, with the symptoms being failed tasks, which eventually make the cells fail with an error message
#    The logs of the failed tasks, imply that the containers that are failing are running out of Memory


# The Cell in question:

# Cell # 1
----------
%pyspark
#similar_df.count()

# collect/cash stats to the head for plotting in the next cell - this actually actions the full workflow on the Spark cluster
stats_pdf = similar_df.select('p_xp_similar').toPandas()
# benchmarks: 1 in 10000 in 45min 21sec; no failed tasks
#             1 in 1000  in 45min 21sec; ditto
#             1 in 10    in 46min 57sec; successful completion albeit with 10 failed tasks 



# Second cell that also fails
# Cell # 2
----------
%pyspark

# convert to a Pandas dataframe for GaiaXPy
continuous_spectra = similar_df.toPandas()

# convert to sampled form:
sampled_spectra, sampling = convert(continuous_spectra, save_file = False)
    
# plot to sanity check:
plot_spectra(sampled_spectra, sampling = sampling, multi=True, show_plot=True, output_path=None, legend=True)




# -----------------------------------------------------------------
# Try reducing total executors and cores per executor



# Spark Settings

spark.driver.memory                 37888m
spark.driver.memoryOverhead           5120
spark.driver.cores                       5
spark.driver.maxResultSize          20480m

spark.executor.memory                 7168m
spark.executor.memoryOverhead         1024
spark.executor.cores                     2
#spark.executor.instances               30

#spark.default.parallelism              100
#spark.sql.shuffle.partitions          100

# YARN Application Master settings
spark.yarn.am.memory                 2048m
spark.yarn.am.cores                      1

spark.dynamicAllocation.enabled          true
spark.shuffle.service.enabled            true
spark.dynamicAllocation.minExecutors      1
 # spark.executor.instances from Cheatsheet
spark.dynamicAllocation.maxExecutors     15
 # maxExecutors / 2
spark.dynamicAllocation.initialExecutors          1
spark.dynamicAllocation.cachedExecutorIdleTimeout 60s
spark.dynamicAllocation.executorIdleTimeout       60s
spark.sql.execution.arrow.pyspark.enabled            true



# Failed Tasks


# Notes:
# RAM usage on workers ranged from 4% to 96% during processing
# So some of the worker nodes were idle
# 104 Active tasks, 113 Failed tasks after 10 mins


# -----------------------------------------------------------------
# Try reducing RAM per executor


# Spark Settings

spark.driver.memory                 37888m
spark.driver.memoryOverhead           5120
spark.driver.cores                       5
spark.driver.maxResultSize          30720m

spark.executor.memory                 3072m
spark.executor.memoryOverhead         384m
spark.executor.cores                     5
#spark.executor.instances               30

#spark.default.parallelism              100
#spark.sql.shuffle.partitions          100

# YARN Application Master settings
spark.yarn.am.memory                 2048m
spark.yarn.am.cores                      1

spark.dynamicAllocation.enabled          true
spark.shuffle.service.enabled            true
spark.dynamicAllocation.minExecutors	  1
 # spark.executor.instances from Cheatsheet
spark.dynamicAllocation.maxExecutors     30
 # maxExecutors / 2
spark.dynamicAllocation.initialExecutors          15
spark.dynamicAllocation.cachedExecutorIdleTimeout 60s
spark.dynamicAllocation.executorIdleTimeout	  60s
spark.sql.execution.arrow.pyspark.enabled            true


spark.sql.execution.arrow.pyspark.enabled            true



# Failed Tasks


# Notes:
# RAM usage on workers ranged from 3% to 99% during processing
# One of the worker nodes were idle 
# 150 Active tasks, 78 Failed tasks after 20 mins

# Logs

2022-09-12 10:55:42,170 ERROR executor.Executor: Exception in task 0.0 in stage 3.0 (TID 4097)
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:233)
	at org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)
	at org.apache.spark.scheduler.DirectTaskResult$$Lambda$1245/906964877.apply$mcV$sp(Unknown Source)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1405)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:606)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2022-09-12 10:55:42,553 INFO memory.MemoryStore: MemoryStore cleared




# -----------------------------------------------------------------
# Add memoryOverhead values for yarn
# https://spark.apache.org/docs/2.2.0/running-on-yarn.html

# Calculated using Cheatsheet.xlsx
spark.driver.memory                 37888m
spark.driver.memoryOverhead           5120
spark.driver.cores                       5
spark.driver.maxResultSize          30720m

spark.executor.memory                 7168m
spark.executor.memoryOverhead         1024m
spark.executor.cores                     5
#spark.executor.instances               30

spark.yarn.executor.memoryOverhead	1024m
spark.yarn.driver.memoryOverhead  1024m
spark.yarn.am.memoryOverhead    1024m

#spark.default.parallelism              100
#spark.sql.shuffle.partitions          100

# YARN Application Master settings
spark.yarn.am.memory                 2048m
spark.yarn.am.cores                      1

spark.dynamicAllocation.enabled          true
spark.shuffle.service.enabled            true
spark.dynamicAllocation.minExecutors	  1
 # spark.executor.instances from Cheatsheet
spark.dynamicAllocation.maxExecutors     30
 # maxExecutors / 2
spark.dynamicAllocation.initialExecutors          15
spark.dynamicAllocation.cachedExecutorIdleTimeout 60s
spark.dynamicAllocation.executorIdleTimeout	  60s
spark.sql.execution.arrow.pyspark.enabled            true

# Both cells Failed
# High memory usage on a few of the nodes



# -----------------------------------------------------------------
# Reduce Cores & maxExecutors


spark.driver.memory                 37888m
spark.driver.memoryOverhead           5120
spark.driver.cores                       2
spark.driver.maxResultSize          30720m

spark.executor.memory                 7168m
spark.executor.memoryOverhead         1024m
spark.executor.cores                     5
#spark.executor.instances               30

#spark.yarn.executor.memoryOverhead     1024m
#spark.yarn.driver.memoryOverhead  1024m        
#spark.yarn.am.memoryOverhead   1024m

#spark.default.parallelism              100
#spark.sql.shuffle.partitions          100

# YARN Application Master settings
spark.yarn.am.memory                 2048m
spark.yarn.am.cores                      1

spark.dynamicAllocation.enabled          true
spark.shuffle.service.enabled            true
spark.dynamicAllocation.minExecutors	  1
 # spark.executor.instances from Cheatsheet
spark.dynamicAllocation.maxExecutors     5
 # maxExecutors / 2
spark.dynamicAllocation.initialExecutors          1
spark.dynamicAllocation.cachedExecutorIdleTimeout 60s
spark.dynamicAllocation.executorIdleTimeout	  60s
spark.sql.execution.arrow.pyspark.enabled            true

# 0 Failed tasks
# 30 Concurrent Active Tasks, 25 Cores, 40  Gb RAM used (After 2-3 hours)

# Cell #1 Success
> Took 3 hrs 44 min 18 sec. Last updated by Evison at September 12 2022, 6:54:22 PM.

# Cell #2 
# Tasks failed immediately

2022-09-12 16:01:29,516 ERROR util.SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 28.0 in stage 4.0 (TID 6173),5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:233)
	at org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)
	at org.apache.spark.scheduler.DirectTaskResult$$Lambda$2076/390642980.apply$mcV$sp(Unknown Source)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1405)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:606)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

# Looking at the same logs, is this relevant?

> 2022-09-12 12:10:07,894 INFO memory.MemoryStore: MemoryStore started with capacity 3.6 GiB


# -----------------------------------------------------------------
# Increase Cores & maxExecutors


spark.driver.memory                 37888m
spark.driver.memoryOverhead           5120
spark.driver.cores                       5
spark.driver.maxResultSize          30720m

spark.executor.memory                 7168m
spark.executor.memoryOverhead         720m
spark.executor.cores                     5
#spark.executor.instances               30


#spark.default.parallelism              100
#spark.sql.shuffle.partitions          2001

# YARN Application Master settings
spark.yarn.am.memory                 2048m
spark.yarn.am.cores                      1

spark.dynamicAllocation.enabled          true
spark.shuffle.service.enabled            true

spark.dynamicAllocation.minExecutors      1
spark.dynamicAllocation.maxExecutors     20
spark.dynamicAllocation.initialExecutors          1

spark.dynamicAllocation.cachedExecutorIdleTimeout 60s
spark.dynamicAllocation.executorIdleTimeout       60s
spark.sql.execution.arrow.pyspark.enabled            true


# Cell #1
# Success with 5 failed tasks

# Cell #2
# Failed with several failed tasks

