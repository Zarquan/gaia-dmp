#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# Benchmarking the Zeppelin REST API
# ------------------------------------

# Target: 
 # Test a deployed version of Aglais using the benchmarking suite at:
 # https://github.com/stvoutsin/aglais-testing

# Result:
 # Success

# -------------------------------------



# The following was run a local machine (Ubuntu). 
# [Update] I have also tested on a remote VM which was also however an Ubuntu machine
# For the concurrent test, we need to create the users before hand in Zeppelin


# Install Python2.7 (Required by zdairi)
# user@local
# -----------------------------------
apt install python-minimal



# Clone Aglais-testing Github project
# user@local
# -----------------------------------
git clone https://github.com/stvoutsin/aglais-testing
pushd aglais-testing



# Setup Virtualenv
# user@local
# --------------------

virtualenv --python=python2.7 mypython
source mypython/bin/activate



# Install Benchmarking Suite
# user@local
# --------------------------
	
python setup.py install



# Edit our secrets yaml files
# For a single user benchmark, we need to edit "user.yml"
# For a multi user test, we need to setup a yml for each concurrent user, numbered as: "user1.yml", "user2.yml ..."
# (mypython) user@local
# --------------------------------

nano config/zeppelin/user.yml
..
zeppelin_url: http://128.232.227.178:8080
zeppelin_auth: true
zeppelin_user: user
zeppelin_password: pass
..  





# -- Test #1 --
# Run Public examples tests
# (mypython) user@local
>>> from aglais_benchmark import AglaisBenchmarker
>>> AglaisBenchmarker("https://raw.githubusercontent.com/stvoutsin/aglais-testing/main/config/notebooks/notebooks.json", "./config/zeppelin/").run(concurrent=False, users=1)


Test completed after: 914.43 seconds
-----------
{u'SetUp': {'totaltime': '42.07', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'Source_counts_over_the_sky.json': {'totaltime': '33.23', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '732.92', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}, u'Mean_proper_motions_over_the_sky': {'totaltime': '106.21', 'status': u'SUCCESS', 'valid': 'TRUE', 'msg': ''}}


# Restart Spark Context,and try again just to double check


# -- Test #2 --
# Run Public examples tests second time
# (mypython) user@local
>>> from aglais_benchmark import AglaisBenchmarker
>>> AglaisBenchmarker("https://raw.githubusercontent.com/stvoutsin/aglais-testing/main/config/notebooks/notebooks.json", "./config/zeppelin/").run(concurrent=False, users=1)


Test completed after: 1027.47 seconds
-----------
{'SetUp': {'totaltime': '44.70', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 'Mean_proper_motions_over_the_sky': {'totaltime': '132.56', 'status': 'SLOW', 'msg': '', 'valid': 'TRUE'}, 'Source_counts_over_the_sky.json': {'totaltime': '36.93', 'status': 'SUCCESS', 'msg': '', 'valid': 'TRUE'}, 'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': '813.28', 'status': 'SLOW', 'msg': '', 'valid': 'TRUE'}}


