#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#


# Targets
# -----------------------------------------------------
  # Experiment with latest changes to allow multiple users running jobs concurrently with Dynamic Allocation [Done]
  


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    docker run \
        --rm \
        --tty \
        --interactive \
        --name ansibler2 \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Set the target cloud to delete.
#[root@ansibler]

    cloudname=gaia-test



# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"


	> Done

# -----------------------------------------------------
# Create everything, using a standard config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            'medium-04'


	> Done



# ----------------------------------------------------------------
# Login via Firefox, in two separate windows, as two separate users
# For second user, open new Incognito tab
#[user@desktop]

    firefox --new-window "http://128.232.227.237:8080/" &



# -------------------------------------------------------------------
# Run example notebooks on two separate accounts, one after the other
#[user@desktop]

 
    # Run imported notebooks from Zeppelin as user #1

     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Success]
   

     /AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier   
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G5NU6HTK/note.json
	

        [Success]

        # Raw catalogue with selected columns
        > Took 6 min 6 sec. Last updated by admin at July 14 2021, 1:37:09 AM.

        # Train up the Random Forrest
        > Took 3 min 36 sec. Last updated by admin at July 14 2021, 1:40:54 AM.


        # 95% Resource Usage by application #1

 
    # Run imported notebooks from Zeppelin as user #2, after user #1's notebooks have completed

     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Not started]
   


     # Application for user #1 is using 95% of resoures, so the second application is not able to use any 

     # If we restart interpreter of Application #1, then application #2 now starts, and starts using 95% when we run the Forrest Classifier
     
     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Success]
   

     /AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier   
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G5NU6HTK/note.json

        [Success]

	# Raw catalogue with selected columns
	> Took 5 min 48 sec. Last updated by gaiauser at July 15 2021, 11:07:27 AM.

	# Train up the Random Forrest
	> Took 3 min 48 sec. Last updated by gaiauser at July 15 2021, 11:11:24 AM.

     
     # After a comment from Enrique and looking through comments online, it seems to be the case that if something is cached in a notebook, 
     # then the executors will not be released to the shuffler until the cache period has expired. So it makes sense that when the  "Raw catalogue with selected columns" cell is run
     # then we aren't able to start any other jobs, since that cell runs a cache command.
 
     # https://issues.apache.org/jira/browse/SPARK-21097
     # https://stackoverflow.com/questions/43639178/spark-jupyter-dynamic-allocation


# -------------------------------------------------------------------
# Run example notebooks on two separate accounts concurrently
# Run Setup on both, and then run the Forrest classifier on both
#[user@desktop]



     # User #1

     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Success]
   

     /AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier   
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G5NU6HTK/note.json
	
        [Success]

        # Raw catalogue with selected columns
        > Took 8 min 44 sec. Last updated by admin at July 15 2021, 11:47:37 AM.

        # Train up the Random Forrest
        > Took 5 min 25 sec. Last updated by admin at July 15 2021, 11:53:14 AM.



     # User #2
     
     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Success]
   

     /AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier   
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G5NU6HTK/note.json

        [Success]
        
        # Raw catalogue with selected columns
        > Took 8 min 54 sec. Last updated by gaiauser at July 15 2021, 11:47:37 AM.

        # Train up the Random Forrest
        > Took 5 min 33 sec. Last updated by gaiauser at July 15 2021, 11:53:23 AM.




# From the Spark Documentation, some info on how resources are allocated with Dynamic allocation

Request Policy
A Spark application with dynamic allocation enabled requests additional executors when it has pending tasks waiting to be scheduled. This condition necessarily implies that the existing set of executors is insufficient to simultaneously saturate all tasks that have been submitted but not yet finished.

Spark requests executors in rounds. The actual request is triggered when there have been pending tasks for spark.dynamicAllocation.schedulerBacklogTimeout seconds, and then triggered again every spark.dynamicAllocation.sustainedSchedulerBacklogTimeout seconds thereafter if the queue of pending tasks persists. Additionally, the number of executors requested in each round increases exponentially from the previous round. For instance, an application will add 1 executor in the first round, and then 2, 4, 8 and so on executors in the subsequent rounds.

The motivation for an exponential increase policy is twofold. First, an application should request executors cautiously in the beginning in case it turns out that only a few additional executors is sufficient. This echoes the justification for TCP slow start. Second, the application should be able to ramp up its resource usage in a timely manner in case it turns out that many executors are actually needed.

Remove Policy
The policy for removing executors is much simpler. A Spark application removes an executor when it has been idle for more than spark.dynamicAllocation.executorIdleTimeout seconds. Note that, under most circumstances, this condition is mutually exclusive with the request condition, in that an executor should not be idle if there are still pending tasks to be scheduled.



# -------------------------------------------------------
# Check if we can change the timeout of a cache

# https://spark.apache.org/docs/2.3.0/configuration.html

nano /opt/spark/conf/spark-defaults.conf
   ..
   spark.dynamicAllocation.cachedExecutorIdleTimeout 60
   ..

# Defaults to infinity


# Repeat first test (Complete user #1 run of both notebooks, then run both notebooks for user #2)




     # User #1

     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Success]
   

     /AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier   
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G5NU6HTK/note.json
	
        [Success]

        # Raw catalogue with selected columns
        > Took 6 min 3 sec. Last updated by gaiauser at July 15 2021, 12:58:34 PM.

        # Train up the Random Forrest
        > Took 3 min 53 sec. Last updated by gaiauser at July 15 2021, 1:02:36 PM.


     # 95% Usage while job is running


     # Once job is completed, wait a minute and start second job


     # User #2
     
     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Success]
   

     /AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier   
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G5NU6HTK/note.json

        [Success]
        
        # Raw catalogue with selected columns
        > Took 43 sec. Last updated by gaiauser at July 15 2021, 1:08:11 PM.

        # Train up the Random Forrest
        > Been running for 20 minutes..
          .. Not sure what is going on
         

# Restart Interpreters and try again..





     # User #1

     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Success]
   

     /AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier   
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G5NU6HTK/note.json
	
        [Success]

        # Raw catalogue with selected columns
        > Took 5 min 58 sec. Last updated by gaiauser at July 15 2021, 1:47:10 PM.

        # Train up the Random Forrest
        > Took 3 min 52 sec. Last updated by gaiauser at July 15 2021, 1:51:11 PM.


     # 95% Usage while job is running


     # Once job is completed, wait a minute and start second job


     # User #2
     
     /AglaisPublicExamples/SetUp                                                          
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G7GZKWUH/note.json

        [Success]
   

     /AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier   
        https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2G5NU6HTK/note.json

        [Success]
        
        # Raw catalogue with selected columns
        > Took 8 min 24 sec. Last updated by admin at July 15 2021, 2:07:02 PM.


        # Train up the Random Forrest
       	> Took 5 min 10 sec. Last updated by admin at July 15 2021, 2:12:22 PM.


# Worked this time

# Odd, but at least we can confirm that the caching causes the executors to not be released

# Question is, how long should the timeout be for a cached dataset?

