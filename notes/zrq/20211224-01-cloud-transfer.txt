#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        s3cmd is very slow
        VM dies a few hours into the transfer - no idea why.

        Try again using s4cmd ?
        https://github.com/bloomreach/s4cmd

    Result:

        s4cmd crappy software
        sync operation fails with a stack trace
        Not working, wasting time.

# -----------------------------------------------------
# Copy our YAML file across.
#[user@ansibler]

    scp /deployments/common/manila/datashares.yaml \
        zrq@zeppelin:datashares.yaml


# -----------------------------------------------------
# -----------------------------------------------------
# Install yq YAML parser.
#[user@zeppelin]

    sudo wget -O   '/usr/bin/yq' 'https://github.com/mikefarah/yq/releases/download/v4.12.0/yq_linux_amd64'
    sudo chmod a+x '/usr/bin/yq'


# -----------------------------------------------------
# Install s4cmd.
#[user@zeppelin]

    sudo pip install s4cmd


# -----------------------------------------------------
# Sync the data directories.
#[user@zeppelin]

        sharelist="${HOME:?}/datashares.yaml"

        for shareid in $(
            yq eval '.datashares.[].id' "${sharelist}"
            )
        do

            sharename=$(
                yq eval ".datashares.[] | select(.id == \"${shareid}\").sharename" "${sharelist}"
                )
            sharepath=$(
                yq eval ".datashares.[] | select(.id == \"${shareid}\").mountpath" "${sharelist}"
                )

            echo ""
            echo "-----------------------------------------------------"
            echo "Share name [${sharename:?}]"
            echo "Share path [${sharepath:?}]"

            # Create the bucket
            s3cmd mb "s3://${sharename:?}"

            # Sync the contents
            s4cmd dsync \
                --verbose \
                --recursive \
                --sync-check \
                "${sharepath:?}" \
                "s3://${sharename:?}/"

        done


    >   [Exception] An error occurred (403) when calling the HeadObject operation: Forbidden
    >   [Exception] An error occurred (403) when calling the HeadObject operation: Forbidden
    >   [Exception] An error occurred (403) when calling the HeadObject operation: Forbidden
    >   [Exception] An error occurred (403) when calling the HeadObject operation: Forbidden
    >   [Exception] An error occurred (403) when calling the HeadObject operation: Forbidden
    >   [Exception] An error occurred (403) when calling the HeadObject operation: Forbidden
    >   Exception in thread Thread-24:
    >   Traceback (most recent call last):
    >     File "/home/zrq/.local/bin/s4cmd.py", line 520, in run
    >       self.__class__.__dict__[func_name](self, *args, **kargs)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 129, in wrapper
    >       ret = func(*args, **kargs)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 1313, in upload
    >       obj = self.lookup(s3url)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 129, in wrapper
    >       ret = func(*args, **kargs)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 1294, in lookup
    >       raise e
    >     File "/home/zrq/.local/bin/s4cmd.py", line 1289, in lookup
    >       return self.s3.head_object(Bucket=s3url.bucket, Key=s3url.path)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 402, in wrapped_method
    >       ret = getattr(self.client, method)(*args, **merged_kargs)
    >     File "/home/zrq/.local/lib/python3.7/site-packages/botocore/client.py", line 391, in _api_call
    >       return self._make_api_call(operation_name, kwargs)
    >     File "/home/zrq/.local/lib/python3.7/site-packages/botocore/client.py", line 719, in _make_api_call
    >       raise error_class(parsed_response, operation_name)
    >   botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden
    >   
    >   During handling of the above exception, another exception occurred:
    >   
    >   Traceback (most recent call last):
    >     File "/usr/lib64/python3.7/threading.py", line 926, in _bootstrap_inner
    >       self.run()
    >     File "/home/zrq/.local/bin/s4cmd.py", line 542, in run
    >       fail('[Exception] ', exc_info=e)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 189, in fail
    >       raise RuntimeError(status)
    >   RuntimeError: 1


    #
    # Not working, time wasting.
    # Revert to s3cmd instead.
    #


# -----------------------------------------------------
# Try listing a directory using s4cmd.
#[user@zeppelin]

    sharename=aglais-data-gaia-dr2-6514
    sharepath=/data/gaia/GDR2_6514

    s4cmd ls --debug "s3://${sharename:?}"

    >     (D)s4cmd.py:658  read S3 keys from $HOME/.s3cfg file
    >     (D)s4cmd.py:128  >> ls_handler(<s4cmd.CommandHandler object at 0x7f2842570c10>, ['ls', 's3://aglais-data-gaia-dr2-6514'])
    >     (D)s4cmd.py:128  >> validate(<s4cmd.CommandHandler object at 0x7f2842570c10>, 'cmd|s3', ['ls', 's3://aglais-data-gaia-dr2-6514'])
    >     (D)s4cmd.py:130  << validate(<s4cmd.CommandHandler object at 0x7f2842570c10>, 'cmd|s3', ['ls', 's3://aglais-data-gaia-dr2-6514']): None
    >     (D)s4cmd.py:128  >> s3walk(<s4cmd.S3Handler object at 0x7f2842570b90>, 's3://aglais-data-gaia-dr2-6514')
    >     (D)s4cmd.py:128  >> s3walk(<ThreadUtil(Thread-1, started daemon 139810879690496)>, <s4cmd.S3URL object at 0x7f28424fb350>, '', '', [])
    >     (D)s4cmd.py:401  >> S3APICALL get_paginator('list_objects')
    >     (D)s4cmd.py:403  << S3APICALL get_paginator('list_objects'): <botocore.client.S3.Paginator.ListObjects object at 0x7f2770567850>
    >     (E)s4cmd.py:182  [Exception] An error occurred (InvalidAccessKeyId) when calling the ListObjects operation: The AWS Access Key Id you provided does not exist in our records.
    >     (E)s4cmd.py:182  [Thread Failure] An error occurred (InvalidAccessKeyId) when calling the ListObjects operation: The AWS Access Key Id you provided does not exist in our records.
    >     (E)s4cmd.py:182  [Runtime Exception] 1
    >     (E)s4cmd.py:184  Traceback (most recent call last):
    >     File "/home/zrq/.local/bin/s4cmd.py", line 1928, in main
    >       CommandHandler(opt).run(args)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 1557, in run
    >       CommandHandler.__dict__[cmd + '_handler'](self, args)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 129, in wrapper
    >       ret = func(*args, **kargs)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 1632, in ls_handler
    >       self.pretty_print(self.s3handler().s3walk(args[1]))
    >     File "/home/zrq/.local/bin/s4cmd.py", line 129, in wrapper
    >       ret = func(*args, **kargs)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 724, in s3walk
    >       pool.join()
    >     File "/home/zrq/.local/bin/s4cmd.py", line 594, in join
    >       self.tasks.join()
    >     File "/home/zrq/.local/bin/s4cmd.py", line 469, in join
    >       fail('[Thread Failure] ', exc_info=self.exc_info)
    >     File "/home/zrq/.local/bin/s4cmd.py", line 189, in fail
    >       raise RuntimeError(status)
    >   RuntimeError: 1


# -----------------------------------------------------
# Try listing the same directory using s3cmd.
#[user@zeppelin]

    sharename=aglais-data-gaia-dr2-6514
    sharepath=/data/gaia/GDR2_6514

    s3cmd ls "s3://${sharename:?}"

    >   DIR  s3://aglais-data-gaia-dr2-6514/GDR2_6514/


    s3cmd ls "s3://aglais-data-gaia-dr2-6514/GDR2_6514/"

    >   DIR  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/


    s3cmd ls "s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/"

    >   2021-12-24 01:22     74114220  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/part-00000-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet
    >   2021-12-24 01:22    104411815  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/part-00001-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet
    >   2021-12-24 01:22     99035704  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/part-00002-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet
    >   2021-12-24 01:22     96996784  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/part-00003-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet
    >   ....
    >   ....
    >   2021-12-24 04:26     85893981  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/part-02386-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet
    >   2021-12-24 04:26     86006304  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/part-02387-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet
    >   2021-12-24 04:26     85861577  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/part-02388-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet
    >   2021-12-24 04:26     85925003  s3://aglais-data-gaia-dr2-6514/GDR2_6514/GDR2_6514_GAIASOURCE/part-02389-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet


    #
    # conclusion - s4cmd is broken
    #


