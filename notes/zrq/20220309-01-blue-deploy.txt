#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        New deployment on green cloud.

    Result:

        Success.
        Passes all the tests and is ready to go.


# -----------------------------------------------------
# Merge upstream changes.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        git checkout master

    >   Already on 'master'
    >   Your branch is up to date with 'origin/master'.


        git fetch upstream

    >   remote: Enumerating objects: 1, done.
    >   remote: Counting objects: 100% (1/1), done.
    >   remote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0
    >   Unpacking objects: 100% (1/1), 626 bytes | 626.00 KiB/s, done.
    >   From github.com:wfau/aglais
    >      560da17..3ba4314  master     -> upstream/master


        git merge upstream/master

    >   Updating 560da17..3ba4314
    >   Fast-forward
    >    notes/zrq/20220223-01-green-deploy.txt | 1272 +++++++++
    >    notes/zrq/20220224-01-green-deploy.txt |  865 +++++++++
    >    notes/zrq/20220225-01-green-deploy.txt |  129 +++++++++
    >    notes/zrq/20220225-02-live-deploy.txt  |  112 +++++++++
    >    4 files changed, 2378 insertions(+)
    >    create mode 100644 notes/zrq/20220223-01-green-deploy.txt
    >    create mode 100644 notes/zrq/20220224-01-green-deploy.txt
    >    create mode 100644 notes/zrq/20220225-01-green-deploy.txt
    >    create mode 100644 notes/zrq/20220225-02-live-deploy.txt


        git status

    >   On branch master
    >   Your branch is ahead of 'origin/master' by 5 commits.


        git push

    >   Total 0 (delta 0), reused 0 (delta 0), pack-reused 0
    >   To github.com:Zarquan/aglais.git
    >      560da17..3ba4314  master -> master


    popd


# -----------------------------------------------------
# Create a new branch.
#[user@desktop]

    branchname=blue-deploy

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        branchprev=$(git branch --show-current)
        branchnext=$(date '+%Y%m%d')-zrq-${branchname:?}

        git checkout master
        git checkout -b "${branchnext:?}"

    >   Already on 'master'
    >   Your branch is up to date with 'origin/master'.

    >   Switched to a new branch '20220309-zrq-blue-deploy'


        git push --set-upstream 'origin' "$(git branch --show-current)"

    >   ....
    >   ....
    >   To github.com:Zarquan/aglais.git
    >    * [new branch]      20220309-zrq-blue-deploy -> 20220309-zrq-blue-deploy
    >   Branch '20220309-zrq-blue-deploy' set up to track remote branch '20220309-zrq-blue-deploy' from 'origin'.


    popd


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2021.08.25 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudbase='arcus'
    cloudname='iris-gaia-blue'


# -----------------------------------------------------
# List details of the available flavors.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        flavor list

    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
    >   | ID                                   | Name                  |   RAM | Disk | Ephemeral | VCPUs | Is Public |
    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
    >   | 0997c60d-3460-432a-a7fc-78d2cd466b4c | gaia.vm.cclake.26vcpu | 44032 |   20 |       180 |    26 | False     |
    >   | 166497c3-a0bb-4276-bee3-e56932e6f3e4 | gaia.vm.cclake.1vcpu  |  1024 |    8 |         0 |     1 | False     |
    >   | 2e5dc624-1d3b-4da7-8107-cc2dd4cb5073 | vm.v1.large           | 32768 |   60 |         0 |     8 | True      |
    >   | 56c420d5-abea-41da-9863-f5bc08b08430 | gaia.vm.cclake.54vcpu | 88064 |   20 |       380 |    54 | False     |
    >   | 6793b213-5efa-4b51-96bf-1340ff066499 | vm.v1.xsmall          |  2048 |   20 |         0 |     1 | True      |
    >   | 698a8d46-eceb-4c55-91ff-38286bf9eabb | vm.v1.tiny            |  1024 |   10 |         0 |     1 | True      |
    >   | 6b56d6e9-5397-4543-87fb-e0c0b6d47961 | vm.v1.small           | 16384 |   20 |         0 |     4 | True      |
    >   | 80e0721d-db0f-407f-a2bf-fe6641312204 | gaia.vm.cclake.4vcpu  |  6144 |   22 |         0 |     4 | False     |
    >   | a1b2789c-761a-4843-8ea8-603a9209dec8 | gaia.vm.cclake.6vcpu  |  9216 |   20 |        24 |     6 | False     |
    >   | df5133ea-1bfb-45fd-ba39-71fc820abcb1 | gaia.vm.cclake.2vcpu  |  3072 |   14 |         0 |     2 | False     |
    >   | ef01ce36-283f-4df3-a039-1b47504de078 | gaia.vm.cclake.12vcpu | 21504 |   20 |        80 |    12 | False     |
    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+


    #
    # Sort by memory size ..
    #

    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
    >   | ID                                   | Name                  |   RAM | Disk | Ephemeral | VCPUs | Is Public |
    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
    >   | 166497c3-a0bb-4276-bee3-e56932e6f3e4 | gaia.vm.cclake.1vcpu  |  1024 |    8 |         0 |     1 | False     |
    >   | 698a8d46-eceb-4c55-91ff-38286bf9eabb | vm.v1.tiny            |  1024 |   10 |         0 |     1 | True      |
    >   | 6793b213-5efa-4b51-96bf-1340ff066499 | vm.v1.xsmall          |  2048 |   20 |         0 |     1 | True      |
    >   | df5133ea-1bfb-45fd-ba39-71fc820abcb1 | gaia.vm.cclake.2vcpu  |  3072 |   14 |         0 |     2 | False     |
    >   | 80e0721d-db0f-407f-a2bf-fe6641312204 | gaia.vm.cclake.4vcpu  |  6144 |   22 |         0 |     4 | False     |
    >   | a1b2789c-761a-4843-8ea8-603a9209dec8 | gaia.vm.cclake.6vcpu  |  9216 |   20 |        24 |     6 | False     |
    >   | 6b56d6e9-5397-4543-87fb-e0c0b6d47961 | vm.v1.small           | 16384 |   20 |         0 |     4 | True      |
    >   | ef01ce36-283f-4df3-a039-1b47504de078 | gaia.vm.cclake.12vcpu | 21504 |   20 |        80 |    12 | False     |
    >   | 0997c60d-3460-432a-a7fc-78d2cd466b4c | gaia.vm.cclake.26vcpu | 44032 |   20 |       180 |    26 | False     |
    >   | 2e5dc624-1d3b-4da7-8107-cc2dd4cb5073 | vm.v1.large           | 32768 |   60 |         0 |     8 | True      |
    >   | 56c420d5-abea-41da-9863-f5bc08b08430 | gaia.vm.cclake.54vcpu | 88064 |   20 |       380 |    54 | False     |
    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+


    #
    # Select just the gaia flavors
    #

    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
    >   | ID                                   | Name                  |   RAM | Disk | Ephemeral | VCPUs | Is Public |
    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
    >   | 166497c3-a0bb-4276-bee3-e56932e6f3e4 | gaia.vm.cclake.1vcpu  |  1024 |    8 |         0 |     1 | False     |
    >   | df5133ea-1bfb-45fd-ba39-71fc820abcb1 | gaia.vm.cclake.2vcpu  |  3072 |   14 |         0 |     2 | False     |
    >   | 80e0721d-db0f-407f-a2bf-fe6641312204 | gaia.vm.cclake.4vcpu  |  6144 |   22 |         0 |     4 | False     |
    >   | a1b2789c-761a-4843-8ea8-603a9209dec8 | gaia.vm.cclake.6vcpu  |  9216 |   20 |        24 |     6 | False     |
    >   | ef01ce36-283f-4df3-a039-1b47504de078 | gaia.vm.cclake.12vcpu | 21504 |   20 |        80 |    12 | False     |
    >   | 0997c60d-3460-432a-a7fc-78d2cd466b4c | gaia.vm.cclake.26vcpu | 44032 |   20 |       180 |    26 | False     |
    >   | 56c420d5-abea-41da-9863-f5bc08b08430 | gaia.vm.cclake.54vcpu | 88064 |   20 |       380 |    54 | False     |
    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+


    #
    # Convert the memory size to Gbytes
    #

    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
    >   | ID                                   | Name                  |   RAM | Disk | Ephemeral | VCPUs | Is Public |
    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
    >   | 166497c3-a0bb-4276-bee3-e56932e6f3e4 | gaia.vm.cclake.1vcpu  |     1 |    8 |         0 |     1 | False     |
    >   | df5133ea-1bfb-45fd-ba39-71fc820abcb1 | gaia.vm.cclake.2vcpu  |     3 |   14 |         0 |     2 | False     |
    >   | 80e0721d-db0f-407f-a2bf-fe6641312204 | gaia.vm.cclake.4vcpu  |     6 |   22 |         0 |     4 | False     |
    >   | a1b2789c-761a-4843-8ea8-603a9209dec8 | gaia.vm.cclake.6vcpu  |     9 |   20 |        24 |     6 | False     |
    >   | ef01ce36-283f-4df3-a039-1b47504de078 | gaia.vm.cclake.12vcpu |    21 |   20 |        80 |    12 | False     |
    >   | 0997c60d-3460-432a-a7fc-78d2cd466b4c | gaia.vm.cclake.26vcpu |    43 |   20 |       180 |    26 | False     |
    >   | 56c420d5-abea-41da-9863-f5bc08b08430 | gaia.vm.cclake.54vcpu |    86 |   20 |       380 |    54 | False     |
    >   +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+


# -----------------------------------------------------
# -----------------------------------------------------
# Rename our config files to match.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        pushd deployments/hadoop-yarn/ansible/config

            ls -1

    >   ansible.yml
    >   hadoop.yml
    >   openstack.yml
    >   spark.yml
    >   users.yml
    >   yarn.yml
    >   zeppelin-13.22-spark-4.13.22.yml
    >   zeppelin-14.45-spark-4.14.45.yml
    >   zeppelin-27.45-spark-6.27.45.yml
    >   zeppelin-28.180-spark-6.27.45.yml
    >   zeppelin-55.90-spark-6.27.45.yml
    >   zeppelin.yml


            git mv zeppelin-13.22-spark-4.13.22.yml \
                   zeppelin-12.21-spark-4.11.21.yml

            git rm zeppelin-14.45-spark-4.14.45.yml

            git mv zeppelin-27.45-spark-6.27.45.yml \
                   zeppelin-26.43-spark-6.26.43.yml

            git rm zeppelin-28.180-spark-6.27.45.yml

            git mv zeppelin-55.90-spark-6.27.45.yml \
                   zeppelin-54.86-spark-6.54.86.yml

            git status

    >   On branch 20220309-zrq-blue-deploy
    >   Your branch is up to date with 'origin/20220309-zrq-blue-deploy'.
    >
    >   Changes to be committed:
    >     (use "git restore --staged <file>..." to unstage)
    >   	renamed:    zeppelin-13.22-spark-4.13.22.yml -> zeppelin-12.21-spark-4.11.21.yml
    >   	deleted:    zeppelin-14.45-spark-4.14.45.yml
    >   	renamed:    zeppelin-27.45-spark-6.27.45.yml -> zeppelin-26.43-spark-6.26.43.yml
    >   	deleted:    zeppelin-28.180-spark-6.27.45.yml
    >   	renamed:    zeppelin-55.90-spark-6.27.45.yml -> zeppelin-54.86-spark-6.54.86.yml


            git add .
            git commit -m "Updated config files to match available flavors"

    >   [20220309-zrq-blue-deploy 98271ad] Updated config files to match available flavors
    >    5 files changed, 377 deletions(-)
    >    rename deployments/hadoop-yarn/ansible/config/{zeppelin-13.22-spark-4.13.22.yml => zeppelin-12.21-spark-4.11.21.yml} (100%)
    >    delete mode 100644 deployments/hadoop-yarn/ansible/config/zeppelin-14.45-spark-4.14.45.yml
    >    rename deployments/hadoop-yarn/ansible/config/{zeppelin-27.45-spark-6.27.45.yml => zeppelin-26.43-spark-6.26.43.yml} (100%)
    >    delete mode 100644 deployments/hadoop-yarn/ansible/config/zeppelin-28.180-spark-6.27.45.yml
    >    rename deployments/hadoop-yarn/ansible/config/{zeppelin-55.90-spark-6.27.45.yml => zeppelin-54.86-spark-6.54.86.yml} (100%)


    popd


    # Typo fix ...

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        pushd deployments/hadoop-yarn/ansible/config

            git mv zeppelin-54.86-spark-6.54.86.yml \
                   zeppelin-54.86-spark-6.26.43.yml

            git add .
            git commit -m "Updated config files to match available flavors"


        popd
    popd


# -----------------------------------------------------
# Update the configurations to match the flavors.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        pushd deployments/hadoop-yarn/ansible/config


            ls -1

    >   ....
    >   ....
    >   zeppelin-12.21-spark-4.12.21.yml
    >   zeppelin-26.43-spark-6.26.43.yml
    >   zeppelin-54.86-spark-6.26.43.yml

            gedit zeppelin-12.21-spark-4.12.21.yml

                ....
                ....


            gedit zeppelin-26.43-spark-6.26.43.yml

                ....
                ....


            gedit zeppelin-54.86-spark-6.26.43.yml

                ....
                ....


            meld \
                zeppelin-12.21-spark-4.12.21.yml \
                zeppelin-26.43-spark-6.26.43.yml \
                zeppelin-54.86-spark-6.26.43.yml

            git add .
            git commit -m "Updated config files to match available flavors"


        popd
    popd


# -----------------------------------------------------
# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudbase='arcus'
    cloudname='iris-gaia-blue'
    configname=zeppelin-54.86-spark-6.26.43


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}" \

    >   real    3m45.526s
    >   user    1m22.963s
    >   sys     0m10.588s


# -----------------------------------------------------
# Create everything, using the new config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
        | tee /tmp/create-all.log

    >   real    41m53.100s
    >   user    12m11.105s
    >   sys     4m38.908s


# -----------------------------------------------------
# Quick test with one user.
#[root@ansibler]

    numusers=1
    testlevel=quick

    concurrent=True
    testdate=$(date '+%Y%m%d-%H%M%S')

    time \
        /deployments/hadoop-yarn/bin/restart-zeppelin.sh

    time \
        /deployments/hadoop-yarn/bin/run-tests.sh \
            "${cloudname:?}"  \
            "${configname:?}" \
            "${testlevel:?}"  \
	        "${concurrent:?}" \
	        "${numusers:?}"  \
        | tee /tmp/test-${testlevel:?}-${testdate:?}.log

    sed "
        1,3 d
        s/'\([0-9.]*\)'/\1/g
        s/:[[:space:]],/: '',/g
        s/'/\"/g
        " \
        '/tmp/test-result.json' \
    | jq '.' \
    | tee /tmp/test-${testlevel:?}-${testdate:?}.json


    >   real	3m55.228s
    >   user	1m58.095s
    >   sys	0m14.297s

    >   [
    >     {
    >       "SetUp": {
    >         "totaltime": 44.37,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Mean_proper_motions_over_the_sky": {
    >         "totaltime": 48.73,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Source_counts_over_the_sky.json": {
    >         "totaltime": 17.02,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Library_Validation.json": {
    >         "totaltime": 8.74,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       }
    >     }
    >   ]

    #
    # Why does the test script create 4 users ?
    # user1,2,3 I know about, what is user for ?
    #

    ls -1 /tmp/user*

    >   /tmp/user.yml  <-- what is this one for ?
    >   /tmp/user1.yml
    >   /tmp/user2.yml
    >   /tmp/user3.yml


# -----------------------------------------------------
# -----------------------------------------------------
# Setup a SSH tunnel SOCKS proxy.
# Running 'htop' on the Zeppelin node to keep the connection alive.
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh \
                -t \
                -D "3000"  \
                zeppelin \
                    "
                    htop
                    "
            '

    >   ....
    >   ....


# -----------------------------------------------------
# Login to the Zeppelin UI using FoxyProxy SOCKS proxy.
#[user@desktop]

    firefox \
        'http://zeppelin:8080/' \
        'http://master01:8088/cluster' \
        'http://monitor:3000/login' \
        &

    firefox \
        'http://monitor:3000/datasources/new' \
        'http://monitor:3000/dashboard/import' \
        'http://monitor:3000/dashboard/import' \
        &

        Create our Prometheus data source.
        http://monitor:3000/datasources/new

            URL: http://monitor:9090/
            scrape: 1s

        Import our dashboards from local disc.
        http://monitor:3000/dashboard/import

            deployments/common/grafana/20210705-02-grafana-dash.json
            deployments/common/grafana/node-exporter-v20201010-1633446087511.json

            http://monitor:3000/d/34S3C8k7z/my-first-dash&refresh=5s
            http://monitor:3000/d/xfpJB9FGz/1-node-exporter-for-prometheus-dashboard-en-v20201010?orgId=1&refresh=5s


# -----------------------------------------------------
# -----------------------------------------------------
# Full test with one user.
#[root@ansibler]

    numusers=1
    testlevel=full

    concurrent=True
    testdate=$(date '+%Y%m%d-%H%M%S')

    time \
        /deployments/hadoop-yarn/bin/restart-zeppelin.sh

    time \
        /deployments/hadoop-yarn/bin/run-tests.sh \
            "${cloudname:?}"  \
            "${configname:?}" \
            "${testlevel:?}"  \
	        "${concurrent:?}" \
	        "${numusers:?}"  \
        | tee /tmp/test-${testlevel:?}-${testdate:?}.log

    sed "
        1,3 d
        s/'\([0-9.]*\)'/\1/g
        s/:[[:space:]],/: '',/g
        s/'/\"/g
        " \
        '/tmp/test-result.json' \
    | jq '.' \
    | tee /tmp/test-${testlevel:?}-${testdate:?}.json

    >   real    160m55.626s
    >   user    26m23.040s
    >   sys     2m22.794s

    >   [
    >     {
    >       "SetUp": {
    >         "totaltime": 50.72,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Mean_proper_motions_over_the_sky": {
    >         "totaltime": 44.96,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Source_counts_over_the_sky.json": {
    >         "totaltime": 14.23,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Good_astrometric_solutions_via_ML_Random_Forrest_classifier": {
    >         "totaltime": 546.85,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "QC_cuts_dev.json": {
    >         "totaltime": 4542.51,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "WD_detection_dev.json": {
    >         "totaltime": 4413.75,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Library_Validation.json": {
    >         "totaltime": 9.36,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       }
    >     }
    >   ]


# -----------------------------------------------------
# -----------------------------------------------------
# Add admin tools to monitor IO performance.
# https://haydenjames.io/what-is-iowait-and-linux-performance
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh \
                worker01 \
                    "
                    sudo dnf install atop sysstat
                    "
            '

    >   ....
    >   ....


    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh \
                -t \
                worker02 \
                    "
                    sudo atop
                    "
            '

    >   ....
    >   ....


    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh \
                -t \
                worker02 \
                    "
                    sudo iotop -oPa
                    "
            '
    >   ....
    >   ....


    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh \
                -t \
                worker02 \
                    "
                    iostat -xm 2
                    "
            '

    >   ....
    >   avg-cpu:  %user   %nice %system %iowait  %steal   %idle
    >              2.56    0.00    2.00   42.80    0.02   52.61
    >
    >   Device            r/s     rMB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wMB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dMB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
    >   vda              0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
    >   vdb              3.50      0.04     0.00   0.00    0.29    12.57    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.15
    >   vdc              0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Check the deployment status.
#[root@ansibler]

    cat '/tmp/aglais-status.yml'

    >   aglais:
    >     status:
    >       deployment:
    >         type: hadoop-yarn
    >         conf: zeppelin-54.86-spark-6.26.43
    >         name: iris-gaia-blue-20220309
    >         date: 20220309T181337
    >     spec:
    >       openstack:
    >         cloud:
    >           base: arcus
    >           name: iris-gaia-blue


# -----------------------------------------------------
# Add the Zeppelin user accounts.
# TODO Install this fragment from a secret.
#[root@ansibler]

    ssh zeppelin

        pushd "${HOME}"
        ln -s "zeppelin-0.10.0-bin-all" "zeppelin"

            pushd "zeppelin"

                # Manual edit to add names and passwords
                vi conf/shiro.ini

                # Restart Zeppelin for the changes to take.
                bin/zeppelin-daemon.sh restart

            popd
        popd
    exit

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]

    #
    # We REALLY need to replace this.
    #


# -----------------------------------------------------
# Add the notebooks from github.
#[root@ansibler]

    ssh zeppelin

        pushd /home/fedora/zeppelin

            mv -b notebook \
               notebook-old

	        git clone git@github.com:wfau/aglais-notebooks.git notebook

	        bin/zeppelin-daemon.sh restart

        popd
    exit

    >   Cloning into 'notebook'...
    >   The authenticity of host 'github.com (140.82.121.3)' can't be established.
    >   ECDSA key fingerprint is SHA256:p2QAMXNIC1TJYWeIOttrVc98/R1BUFWu3/LiyKgUfQM.
    >   Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
    >   Warning: Permanently added 'github.com,140.82.121.3' (ECDSA) to the list of known hosts.
    >   remote: Enumerating objects: 603, done.
    >   remote: Counting objects: 100% (603/603), done.
    >   remote: Compressing objects: 100% (269/269), done.
    >   remote: Total 603 (delta 212), reused 534 (delta 149), pack-reused 0
    >   Receiving objects: 100% (603/603), 54.37 MiB | 17.52 MiB/s, done.
    >   Resolving deltas: 100% (212/212), done.

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# Add our secret function to the ansibler container.
# TODO Move our secrets to a service in the data cloud.
#[root@ansibler]

    # TODO Move this into the Ansible setup.
    # TODO Move our secrets onto our infra-ops server.

    if [ ! -e "${HOME}/bin" ]
    then
        mkdir "${HOME}/bin"
    fi

    cat > "${HOME}/bin/secret" << 'EOF'
ssh -n \
    'secretserver' \
    "bin/secret '${1}'"
EOF

    chmod u+x "${HOME}/bin/secret"

    if [ ! -e "${HOME}/.ssh" ]
    then
        mkdir "${HOME}/.ssh"
    fi

    cat >> "${HOME}/.ssh/config" << 'EOF'
Host secretserver
  User     Zarquan
  Hostname data.metagrid.co.uk
  PubkeyAcceptedKeyTypes +ssh-rsa
EOF

    ssh-keyscan 'data.metagrid.co.uk' >> "${HOME}/.ssh/known_hosts"

    secret frog

    >   Green Frog


# -----------------------------------------------------
# Get the public IP address of our Zeppelin node.
#[root@ansibler]

    cloudname=$(
        yq eval \
            '.aglais.spec.openstack.cloud.name' \
            '/tmp/aglais-status.yml'
        )

    deployname=$(
        yq eval \
            '.aglais.status.deployment.name' \
            '/tmp/aglais-status.yml'
        )

    zeppelinid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server list \
                --format json \
        | jq -r '.[] | select(.Name == "'${deployname:?}'-zeppelin") | .ID'
        )

    zeppelinip=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server show \
                --format json \
                "${zeppelinid:?}" \
        | jq -r ".addresses | .\"${deployname}-internal-network\" | .[1]"
        )

cat << EOF
Zeppelin ID [${zeppelinid:?}]
Zeppelin IP [${zeppelinip:?}]
EOF

    >   Zeppelin ID [3faa4489-1e50-4ce4-a74e-d9aa48873cec]
    >   Zeppelin IP [128.232.222.91]


# -----------------------------------------------------
# Add bind-utils to the client.
# TODO Add this to our client container.
# https://github.com/wfau/atolmis/issues/17
#[root@ansibler]

    dnf -y install bind-utils

    >   ....
    >   Installed:
    >     bind-libs-32:9.16.21-1.fc34.x86_64
    >     bind-license-32:9.16.21-1.fc34.noarch
    >     bind-utils-32:9.16.21-1.fc34.x86_64


# -----------------------------------------------------
# Update our DuckDNS records.
#[root@ansibler]

    ducktoken=$(secret 'aglais.duckdns.token')

    curl "https://www.duckdns.org/update/${cloudname:?}/${ducktoken:?}/${zeppelinip:?}"

    >   OK


# -----------------------------------------------------
# Check the DuckDNS record.
#[root@ansibler]

    dig "${cloudname:?}.duckdns.org"

    >   ;; ANSWER SECTION:
    >   iris-gaia-blue.duckdns.org. 60	IN	A	128.232.222.91


    dig "${cloudname:?}.aglais.uk"

    >   ;; ANSWER SECTION:
    >   iris-gaia-blue.aglais.uk. 600	IN	CNAME	iris-gaia-blue.duckdns.org.
    >   iris-gaia-blue.duckdns.org. 47	IN	A	128.232.222.91


# -----------------------------------------------------
# -----------------------------------------------------
# Login via Firefox and run the public examples.
#[user@desktop]

    firefox \
        'http://iris-gaia-blue.aglais.uk:8080/'

# -----------------------------------------------------

    Setup

        Looks OK ..


# -----------------------------------------------------

    Source counts over the sky

        Lots of warning messages when plotting the results.
        Not a good look for a public example.

    >   WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:920: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_over(newcm(1.0))
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:921: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_under(bgcolor)
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:922: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_bad(badcolor)
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:211: MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax simultaneously is deprecated since 3.3 and will become an error two minor releases later. Please pass vmin/vmax directly to the norm when creating it.
    >     **kwds
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:543: UserWarning: 0.0 180.0 -180.0 180.0
    >     pmin / dtor, pmax / dtor, mmin / dtor, mmax / dtor
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:658: UserWarning: The interval between parallels is 30 deg -0.00'.
    >     vdeg, varcmin
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:666: UserWarning: The interval between meridians is 30 deg -0.00'.
    >     vdeg, varcmin


# -----------------------------------------------------

    Mean proper motions over the sky

        Looks OK ..

        Do we need the explicit cache directives ?

    >   ....
    >   df = spark.sql(query).cache()
    >   ....
    >   ....
    >   sqlContext.clearCache()

# -----------------------------------------------------

    Random Forrest classifier

        Training step took 2min53sec

        Garfana dash shows iowait peaks at 49%

        iostat shows iowait peaks at 49%, cpu is 50% idle

    >   ....
    >   avg-cpu:  %user   %nice %system %iowait  %steal   %idle
    >              0.19    0.00    1.99   47.15    0.00   50.68
    >   ....
    >   ....
    >   avg-cpu:  %user   %nice %system %iowait  %steal   %idle
    >             20.60    0.00    6.63   37.05    0.17   35.55
    >   ....
    >   ....
    >   avg-cpu:  %user   %nice %system %iowait  %steal   %idle
    >              6.45    0.00    2.64   42.72    0.06   48.13
    >   ....
    >   ....
    >   avg-cpu:  %user   %nice %system %iowait  %steal   %idle
    >              0.35    0.00    2.30   45.51    0.00   51.85
    >   ....
    >   ....
    >   avg-cpu:  %user   %nice %system %iowait  %steal   %idle
    >              0.56    0.00    2.06   49.18    0.02   48.18
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------


    Looks good to me.
    Ready to go live tomorrow :-)


# -----------------------------------------------------
# -----------------------------------------------------
# Full test with three users.
#[root@ansibler]

    numusers=3
    testlevel=full

    concurrent=True
    testdate=$(date '+%Y%m%d-%H%M%S')

    time \
        /deployments/hadoop-yarn/bin/restart-zeppelin.sh

    time \
        /deployments/hadoop-yarn/bin/run-tests.sh \
            "${cloudname:?}"  \
            "${configname:?}" \
            "${testlevel:?}"  \
	        "${concurrent:?}" \
	        "${numusers:?}"  \
        | tee /tmp/test-${testlevel:?}-${testdate:?}.log

    sed "
        1,3 d
        s/'\([0-9.]*\)'/\1/g
        s/:[[:space:]],/: '',/g
        s/'/\"/g
        " \
        '/tmp/test-result.json' \
    | jq '.' \
    | tee /tmp/test-${testlevel:?}-${testdate:?}.json

    >   real    443m46.952s
    >   user    84m2.382s
    >   sys     7m43.787s

    >   [
    >     {
    >       "SetUp": {
    >         "totaltime": 15113.86,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Mean_proper_motions_over_the_sky": {
    >         "totaltime": 502.19,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Source_counts_over_the_sky.json": {
    >         "totaltime": 164.48,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Good_astrometric_solutions_via_ML_Random_Forrest_classifier": {
    >         "totaltime": 1555.35,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "QC_cuts_dev.json": {
    >         "totaltime": 4748.29,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "WD_detection_dev.json": {
    >         "totaltime": 4493.78,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Library_Validation.json": {
    >         "totaltime": 7.91,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       }
    >     },
    >     {
    >       "SetUp": {
    >         "totaltime": 44.95,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Mean_proper_motions_over_the_sky": {
    >         "totaltime": 65.99,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Source_counts_over_the_sky.json": {
    >         "totaltime": 18.42,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Good_astrometric_solutions_via_ML_Random_Forrest_classifier": {
    >         "totaltime": 837.2,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "QC_cuts_dev.json": {
    >         "totaltime": 7119.65,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "WD_detection_dev.json": {
    >         "totaltime": 6962.6,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Library_Validation.json": {
    >         "totaltime": 7.89,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       }
    >     },
    >     {
    >       "SetUp": {
    >         "totaltime": 54.47,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Mean_proper_motions_over_the_sky": {
    >         "totaltime": 62.75,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Source_counts_over_the_sky.json": {
    >         "totaltime": 23.49,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Good_astrometric_solutions_via_ML_Random_Forrest_classifier": {
    >         "totaltime": 849.41,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "QC_cuts_dev.json": {
    >         "totaltime": 8704.74,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "WD_detection_dev.json": {
    >         "totaltime": 7173.54,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Library_Validation.json": {
    >         "totaltime": 7.94,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       }
    >     }
    >   ]

    #
    # All done, and system seems to recover OK.
    # No obvious resource leaks.
    #

    #
    # I think this means that the third user had to wait ~4hrs for their first notebook to run ?
    #

    >   ....
    >       "SetUp": {
    >         "totaltime": 15113.86,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >   ....


# -----------------------------------------------------
# Full test with two users.
#[root@ansibler]

    numusers=2
    testlevel=full

    concurrent=True
    testdate=$(date '+%Y%m%d-%H%M%S')

    time \
        /deployments/hadoop-yarn/bin/restart-zeppelin.sh

    time \
        /deployments/hadoop-yarn/bin/run-tests.sh \
            "${cloudname:?}"  \
            "${configname:?}" \
            "${testlevel:?}"  \
	        "${concurrent:?}" \
	        "${numusers:?}"  \
        | tee /tmp/test-${testlevel:?}-${testdate:?}.log

    sed "
        1,3 d
        s/'\([0-9.]*\)'/\1/g
        s/:[[:space:]],/: '',/g
        s/'/\"/g
        " \
        '/tmp/test-result.json' \
    | jq '.' \
    | tee /tmp/test-${testlevel:?}-${testdate:?}.json

    >   real	304m10.173s
    >   user	54m33.822s
    >   sys	4m59.404s

    >   [
    >     {
    >       "SetUp": {
    >         "totaltime": 51.74,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Mean_proper_motions_over_the_sky": {
    >         "totaltime": 69.02,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Source_counts_over_the_sky.json": {
    >         "totaltime": 24.47,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Good_astrometric_solutions_via_ML_Random_Forrest_classifier": {
    >         "totaltime": 855.94,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "QC_cuts_dev.json": {
    >         "totaltime": 9048.98,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "WD_detection_dev.json": {
    >         "totaltime": 6002.85,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Library_Validation.json": {
    >         "totaltime": 7.94,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       }
    >     },
    >     {
    >       "SetUp": {
    >         "totaltime": 43.25,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Mean_proper_motions_over_the_sky": {
    >         "totaltime": 75.75,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Source_counts_over_the_sky.json": {
    >         "totaltime": 24.62,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Good_astrometric_solutions_via_ML_Random_Forrest_classifier": {
    >         "totaltime": 867.04,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "QC_cuts_dev.json": {
    >         "totaltime": 8540.75,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "WD_detection_dev.json": {
    >         "totaltime": 8639.22,
    >         "status": "SLOW",
    >         "msg": "",
    >         "valid": "TRUE"
    >       },
    >       "Library_Validation.json": {
    >         "totaltime": 8.87,
    >         "status": "SUCCESS",
    >         "msg": "",
    >         "valid": "TRUE"
    >       }
    >     }
    >   ]


# -----------------------------------------------------
# Update the notebooks to include new changes from github.
#[root@ansibler]

    ssh zeppelin

        pushd /home/fedora/zeppelin

            pushd notebook

                git status

    >   On branch main
    >   Your branch is up to date with 'origin/main'.
    >
    >   Changes not staged for commit:
    >     (use "git add <file>..." to update what will be committed)
    >     (use "git restore <file>..." to discard changes in working directory)
    >   	modified:   Public Examples/Good astrometric solutions via ML Random Forrest classifier_2GQDKZ59J.zpln
    >   	modified:   Public Examples/Mean proper motions over the sky_2GSNYBDWB.zpln
    >   	modified:   Public Examples/SetUp_2GP53P3PZ.zpln
    >   	modified:   Public Examples/Source counts over the sky_2GQ6WMH9W.zpln
    >
    >   Untracked files:
    >     (use "git add <file>..." to include in what will be committed)
    >   	tmp/


                git diff 'Public Examples/SetUp_2GP53P3PZ.zpln'

    >   diff --git a/Public Examples/SetUp_2GP53P3PZ.zpln b/Public Examples/SetUp_2GP53P3PZ.zpln
    >   index a8b17d9..6809b60 100644
    >   --- a/Public Examples/SetUp_2GP53P3PZ.zpln
    >   +++ b/Public Examples/SetUp_2GP53P3PZ.zpln
    >   @@ -2,8 +2,8 @@
    >      "paragraphs": [
    >        {
    >          "text": "%md\n\n# Platform set-up following Spark restart \n\n....",
    >   -      "user": "gaiauser",
    >   -      "dateUpdated": "2021-12-12 21:50:49.502",
    >   +      "user": "zrq",
    >   +      "dateUpdated": "2022-03-10 03:20:06.240",
    >          "progress": 0,
    >          "config": {
    >            "tableHide": false,
    >   @@ -29,7 +29,7 @@
    >            "msg": [
    >              {
    >                "type": "HTML",
    >   -            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003ePlatform set-up following Spark restart\u003c...."
    >   +            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003ePlatform set-up following Spark restart\u003c...."
    >              }
    >            ]
    >          },
    >   ....
    >   ....

                #
                # The notebooks haven't changed.
                # The last modified date and user name have changed, and the output has changed.
                #
                # There is no realistoc way of merging changes to the notebook content
                # because it is all mangled into a single line (JSON sucks).
                #
                # Easier to just nuke everything and start again.
                #

                git restore .
                git status

    >   On branch main
    >   Your branch is up to date with 'origin/main'.
    >
    >   Untracked files:
    >     (use "git add <file>..." to include in what will be committed)
    >   	tmp/


                #
                # Now we can pull in Nigel's changes from GitHub.
                #

                git pull

    >   remote: Enumerating objects: 81, done.
    >   remote: Counting objects: 100% (81/81), done.
    >   remote: Compressing objects: 100% (56/56), done.
    >   remote: Total 70 (delta 29), reused 54 (delta 14), pack-reused 0
    >   Unpacking objects: 100% (70/70), done.
    >   From github.com:wfau/aglais-notebooks
    >      76303f4..86f2517  main       -> origin/main
    >   Updating 76303f4..86f2517
    >   Fast-forward
    >    Public Examples/1. Start here_2GRTQZFUM.zpln                                                      |  365 +++++++++++++
    >    Public Examples/Data holdings_2GRA39HCN.zpln                                                      |  144 +++---
    >    Public Examples/Good astrometric solutions via ML Random Forrest classifier_2GQDKZ59J.zpln        |  576 +++++++++++++++------
    >    Public Examples/Mean proper motions over the sky_2GSNYBDWB.zpln                                   |  230 ++++++---
    >    ....
    >    ....
    >    rename {Archive => Users/nch}/Kounkel & Covey Spark (Vectorized)_2GS5K9R39.zpln (100%)
    >    rename {Archive => Users/nch}/Kounkel and Covey groups demo_2GQ4VB9YP.zpln (100%)
    >    rename {Archive => Users/nch}/Mean proper motions over the sky_2GSFCR1ZK.zpln (100%)
    >    rename {Public Examples => Users/nch}/SetUp_2GP53P3PZ.zpln (100%)


                git status

    >   On branch main
    >   Your branch is up to date with 'origin/main'.
    >
    >   Untracked files:
    >     (use "git add <file>..." to include in what will be committed)
    >   	tmp/


            #
            # Restart Zeppelin.
            #

                popd

	        bin/zeppelin-daemon.sh restart

        popd
    exit


        #
        # Notes about the test notebooks...
        # At the moment the test system writes it's notebooks to a 'tmp' directory inside the 'notebooks' directory.
        # Git lists this directory as 'Untracked files' because it doesn't know where they came from.
        # We should create a .gitignore file and add 'tmp' to it to avoid the test notebooks getting included by accident.
        #





# -----------------------------------------------------
# -----------------------------------------------------
# Login via Firefox and run the public examples.
#[user@desktop]

    firefox \
        'http://iris-gaia-blue.aglais.uk:8080/'

# -----------------------------------------------------

    Setup

        Looks good
        Show details took 3 sec.

# -----------------------------------------------------

    Data holdings

        Looks good
        Database and table details took 8 sec.

# -----------------------------------------------------

    Source counts over the sky

        Looks bad
        Lots of warnings
        Plot the results took 30 sec.

    >   WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]

    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:920: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_over(newcm(1.0))
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:921: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_under(bgcolor)
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:922: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_bad(badcolor)
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:211: MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax simultaneously is deprecated since 3.3 and will become an error two minor releases later. Please pass vmin/vmax directly to the norm when creating it.
    >     **kwds
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:543: UserWarning: 0.0 180.0 -180.0 180.0
    >     pmin / dtor, pmax / dtor, mmin / dtor, mmax / dtor
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:658: UserWarning: The interval between parallels is 30 deg -0.00'.
    >     vdeg, varcmin
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:666: UserWarning: The interval between meridians is 30 deg -0.00'.
    >     vdeg, varcmin

        #
        # Should the public example be wrting to Nigel's home directory ?
        #

    >   %spark.pyspark
    >
    >   f = open('/user/nch/source-counts-hpx%d.asc'%(healpix_level), mode = 'w')
    >   f.write('# hpx%did count\n'%(healpix_level))
    >   for i in range(len(array_data)): f.write('%d %d\n'%(i, array_data[i]))
    >   f.close()


# -----------------------------------------------------

    Mean proper motions over the sky

        Looks good.
        IO wait peaks at 40%
        Mean RA plot took 24 sec.

        Do we need the explicit cache directives ?
        What effect does this have in a multi-user environment,
        and do we want to encourage users to do this ?

    >   # define a data frame aggregation of the relevant quantities (note this is cached for use in two subsequent cells)
    >   df = spark.sql(query).cache()....
    >   ....
    >   ....
    >   sqlContext.clearCache()


# -----------------------------------------------------

    Random Forrest classifier

        Looks good.
        IO wait peaks at 50%

        Raw catalogue with selected columns took 4 min 48 sec
        Training the random forest took 2 min 59 sec.

        Again, do we need the explicit cache command ?
        .. if we do, should we also clear the cache ?

    >   # cache it for speedy access below (all subsequent samples are derived from this):
    >   raw_sources_cached = raw_sources_df.cache()
    >   ....
    >   ....

    Second pass

        Raw catalogue with selected columns took 5 min 1 sec
        Training the random forest took 3 min 3 sec.



