#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#


    Target:

        Deploy a large system for Dennis to use.

    Result:

        Work in progress ...

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Delete everything from the test and dev systems.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            'gaia-dev'

    >   real	3m6.583s
    >   user	1m5.399s
    >   sys	0m8.692s


    time \
        /deployments/openstack/bin/delete-all.sh \
            'gaia-test'

    >   real	3m7.701s
    >   user	1m5.218s
    >   sys	0m8.684s


# -----------------------------------------------------
# -----------------------------------------------------
# Create large deployment configuration.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        pushd deployments/hadoop-yarn/ansible/config

            cp cclake-medium-04.yml \
               cclake-large-06.yml

            gedit cclake-large-06.yml &

        popd
    popd

    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Create everything, using the new config.
#[root@ansibler]

    cloudname=gaia-dev

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            'cclake-large-06'

    >   real    96m53.675s
    >   user    21m15.287s
    >   sys     6m56.112s


# -----------------------------------------------------
# Check the deployment status.
#[root@ansibler]

    cat '/tmp/aglais-status.yml'

    >   aglais:
    >     status:
    >       deployment:
    >         type: hadoop-yarn
    >         conf: cclake-large-06
    >         name: gaia-dev-20210802
    >         date: 20210802T123825
    >     spec:
    >       openstack:
    >         cloud: gaia-dev


# -----------------------------------------------------
# Add the Zeppelin user accounts.
#[root@ansibler]

    ssh zeppelin

        pushd "${HOME}"
        ln -s "zeppelin-0.8.2-bin-all" "zeppelin"

            pushd "zeppelin"

                # Manual edit to add names and passwords
                vi conf/shiro.ini

                # Restart Zeppelin for the changes to take.
                bin/zeppelin-daemon.sh restart

            popd
        popd
    exit

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# Add the notebooks from github.
#[root@ansibler]

    ssh zeppelin

        pushd /home/fedora/zeppelin

            mv -b notebook \
               notebook-origin

	        git clone git@github.com:wfau/aglais-notebooks.git notebook

	        bin/zeppelin-daemon.sh restart

        popd
    exit

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# Get the public IP address of our Zeppelin node.
#[root@ansibler]

    deployname=$(
        yq read \
            '/tmp/aglais-status.yml' \
                'aglais.status.deployment.name'
        )

    zeppelinid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server list \
                --format json \
        | jq -r '.[] | select(.Name == "'${deployname:?}'-zeppelin") | .ID'
        )

    zeppelinip=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server show \
                --format json \
                "${zeppelinid:?}" \
        | jq -r '.addresses' \
        | sed '
            s/[[:space:]]//
            s/.*=\(.*\)/\1/
            s/.*,\(.*\)/\1/
            '
        )

cat << EOF
Zeppelin ID [${zeppelinid:?}]
Zeppelin IP [${zeppelinip:?}]
EOF

    >   Zeppelin ID [7be8bc51-b8f8-4a87-865a-0280fdaeb991]
    >   Zeppelin IP [128.232.227.162]


# -----------------------------------------------------
# Update our DNS record.
#[root@ansibler]

    ssh root@infra-ops.aglais.uk

        vi /var/aglais/dnsmasq/hosts/gaia-dev.hosts

        ~   128.232.227.162  zeppelin.gaia-dev.aglais.uk


        podman kill --signal SIGHUP dnsmasq

        podman logs dnsmasq | tail

        exit

    >   dnsmasq[1]: read /etc/dnsmasq/hosts/gaia-prod.hosts - 1 addresses
    >   dnsmasq[1]: read /etc/dnsmasq/hosts/gaia-test.hosts - 1 addresses
    >   dnsmasq[1]: read /etc/dnsmasq/hosts/gaia-dev.hosts - 1 addresses


# -----------------------------------------------------
# Check the DNS record.
#[root@ansibler]

    # TODO Add bind-utils to our client container
    # https://github.com/wfau/aglais/issues/391

    dnf install bind-utils

    dig @infra-ops.aglais.uk zeppelin.${cloudname}.aglais.uk

    >   ;; ANSWER SECTION:
    >   zeppelin.gaia-dev.aglais.uk. 300 IN	A	128.232.227.162


# -----------------------------------------------------
# Check the data shares.
# TODO Move this to a bash script in the source tree.
#[root@ansibler]

    sharelist="/deployments/common/manila/datashares.yaml"

    for shareid in $(
        yq read "${sharelist}" 'datashares.[*].id'
        )
    do
        #echo ""
        #echo "Share [${shareid}]"

        checkbase=$(
            yq read "${sharelist}" "datashares.(id == ${shareid}).mountpath"
            )
        checknum=$(
            yq read "${sharelist}" --length "datashares.(id == ${shareid}).checksums"
            )

        for (( i=0; i<checknum; i++ ))
        do
            checkpath=$(
                yq read "${sharelist}" "datashares.(id == ${shareid}).checksums[${i}].path"
                )
            checkcount=$(
                yq read "${sharelist}" "datashares.(id == ${shareid}).checksums[${i}].count"
                )
            checkhash=$(
                yq read "${sharelist}" "datashares.(id == ${shareid}).checksums[${i}].md5sum"
                )

            echo ""
            #echo "Base  [${checkbase}]"
            echo "Share [${checkbase}/${checkpath}]"

            testcount=$(
                ssh zeppelin \
                    "
                    ls -1 ${checkbase}/${checkpath} | wc -l
                    "
                )

            if [ "${testcount}" == "${checkcount}" ]
            then
                echo "Count [PASS]"
            else
                echo "Count [FAIL][${checkcount}][${testcount}]"
            fi

            testhash=$(
                ssh zeppelin \
                    "
                    ls -1 -v ${checkbase}/${checkpath} | md5sum | cut -d ' ' -f 1
                    "
                )

            if [ "${testhash}" == "${checkhash}" ]
            then
                echo "Hash  [PASS]"
            else
                echo "Hash  [FAIL][${checkhash}][${testhash}]"
            fi
        done
    done

    >   Share [/data/gaia/GDR2_6514/GDR2_6514_GAIASOURCE]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_11932/GEDR3_11932_GAIASOURCE]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_2048/GEDR3_2048_GAIASOURCE]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_2048/GEDR3_2048_PS1_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_2048/GEDR3_2048_ALLWISE_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_2048/GEDR3_2048_2MASSPSC_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_4096/GEDR3_4096_GAIASOURCE]
    >   Count [PASS]
    >   Hash  [FAIL][bd9b1270867c50fd310fd4535ace1bab][dc89c58bed3e06063679f27526f0c9cf]
    >
    >   Share [/data/gaia/GEDR3_4096/GEDR3_4096_PS1_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_4096/GEDR3_4096_ALLWISE_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_4096/GEDR3_4096_2MASSPSC_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_8192/GEDR3_8192_GAIASOURCE]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_8192/GEDR3_8192_PS1_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_8192/GEDR3_8192_ALLWISE_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/gaia/GEDR3_8192/GEDR3_8192_2MASSPSC_BEST_NEIGHBOURS]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/wise/ALLWISE/]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/panstarrs/PS1/]
    >   Count [PASS]
    >   Hash  [PASS]
    >
    >   Share [/data/twomass/2MASSPSC/]
    >   Count [PASS]
    >   Hash  [PASS]


# -----------------------------------------------------
# -----------------------------------------------------
# Login to our Zeppelin node and generate a new interpreter.json file.
#[root@ansibler]

    ssh zeppelin

        # Create a new list of interpreter bindings.
        find /home/fedora/zeppelin/notebook \
            -mindepth 1 \
            -maxdepth 1 \
            -type d \
            ! -name '.git' \
            -printf '%f\n' \
        | sed '
            1 i \
"interpreterBindings": {
        s/^\(.*\)$/"\1": ["spark", "md", "sh"]/
        $ ! s/^\(.*\)$/\1,/
        $ a \
},
            ' \
            | tee /tmp/bindings.json


    >   "interpreterBindings": {
    >   "2C35YU814": ["spark", "md", "sh"],
    >   "2EZ3MQG4S": ["spark", "md", "sh"],
    >   ....
    >   ....
    >   "2G9BXYCKP": ["spark", "md", "sh"],
    >   "2FF2VTAAM": ["spark", "md", "sh"]
    >   },


        # Replace the existing interpreter bindings.
        jq '
            del(.interpreterBindings[])
            ' \
        /home/fedora/zeppelin/conf/interpreter.json \
        | sed '
            /interpreterBindings/ {
                r /tmp/bindings.json
                d
                }
            ' \
        | jq '.' \
        | tee /tmp/interpreter-new.json

    >   {
    >     "interpreterSettings": {
    >     ....
    >     ....
    >     },
    >     "interpreterBindings": {
    >       "2C35YU814": [
    >         "spark",
    >         "md",
    >         "sh"
    >       ],
    >       ....
    >       ....
    >       "2FF2VTAAM": [
    >         "spark",
    >         "md",
    >         "sh"
    >       ]
    >     },
    >     "interpreterRepositories": [
    >     ....
    >     ....
    >     ]
    >   }
    >


    # Replace the original interpreter.json
    mv /home/fedora/zeppelin/conf/interpreter.json \
       /home/fedora/zeppelin/conf/interpreter.origin

    cp /tmp/interpreter-new.json \
       /home/fedora/zeppelin/conf/interpreter.json

    # Restart Zeppelin to take effect
    /home/fedora/zeppelin/bin/zeppelin-daemon.sh restart

    exit

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# -----------------------------------------------------
# Add our secret function to the ansibler container.
#[root@ansibler]

    # TODO Move this into the Ansible setup.
    # TODO Move our secrets onto our infra-ops server.

    if [ ! -e "${HOME}/bin" ]
    then
        mkdir "${HOME}/bin"
    fi

    cat > "${HOME}/bin/secret" << 'EOF'
ssh -n \
    'secretserver' \
    "bin/secret '${1}'"
EOF

    chmod u+x "${HOME}/bin/secret"


    if [ ! -e "${HOME}/.ssh" ]
    then
        mkdir "${HOME}/.ssh"
    fi

    # Fix for the out of date ssh server.
    # RSA key have been deprecated, so we need to explicitly allow them for now.
    # https://www.reddit.com/r/Fedora/comments/jh9iyi/f33_openssh_no_mutual_signature_algorithm/

    cat >> "${HOME}/.ssh/config" << 'EOF'
Host secretserver
  User     Zarquan
  Hostname data.metagrid.co.uk
  PubkeyAcceptedKeyTypes +ssh-rsa
EOF

    ssh-keyscan 'data.metagrid.co.uk' >> "${HOME}/.ssh/known_hosts"

    secret frog

    >   Green Frog


# -----------------------------------------------------
# -----------------------------------------------------
# Create shell script functions to wrap the REST API.
#[root@ansibler]

    # TODO Add this to the client container.
    # https://github.com/wfau/aglais/issues/542
    # https://github.com/wfau/aglais/issues/495
    dnf install -y dateutils

    zeppelinhost=zeppelin.${cloudname:?}.aglais.uk
    zeppelinport=8080
    zeppelinurl="http://${zeppelinhost:?}:${zeppelinport:?}"

    zeplogin()
        {
        local username=${1:?}
        local password=${2:?}
        zepcookies=/tmp/${username:?}.cookies
        curl \
            --silent \
            --request 'POST' \
            --cookie-jar "${zepcookies:?}" \
            --data "userName=${username:?}" \
            --data "password=${password:?}" \
            "${zeppelinurl:?}/api/login" \
        | jq '.'
        }

    zepnbjsonfile()
        {
        local nbident=${1:?}
        echo "/tmp/${nbident:?}.json"
        }

    zepnbjsonclr()
        {
        local nbident=${1:?}
        local jsonfile=$(zepnbjsonfile ${nbident})
        if [ -f "${jsonfile}" ]
        then
            rm -f "${jsonfile}"
        fi
        }

    zepnbclear()
        {
        local nbident=${1:?}
        zepnbjsonclr ${nbident}
        curl \
            --silent \
            --request PUT \
            --cookie "${zepcookies:?}" \
            "${zeppelinurl:?}/api/notebook/${nbident:?}/clear" \
        | jq '.'
        }

    zepnbstatus()
        {
        local nbident=${1:?}
        zepnbjsonclr ${nbident}
        curl \
            --silent \
            --request GET \
            --cookie "${zepcookies:?}" \
            "${zeppelinurl:?}/api/notebook/${nbident:?}" \
        | jq '.' | tee $(zepnbjsonfile ${nbident}) | jq 'del(.body.paragraphs[])'
        }

    zepnbexecute()
        {
        local nbident=${1:?}
        zepnbjsonclr ${nbident}
        curl \
            --silent \
            --request POST \
            --cookie "${zepcookies:?}" \
            "${zeppelinurl:?}/api/notebook/job/${nbident:?}" \
        | jq '.'
        }


# -----------------------------------------------------
# Calculate the elapsed time for each paragraph.
#[root@ansibler]

    zepnbparatime()
        {
        local nbident=${1:?}

        cat $(zepnbjsonfile ${nbident}) \
        | sed '
            /"dateStarted": null,/d
            /"dateStarted":/ {
                h
                s/\([[:space:]]*\)"dateStarted":[[:space:]]*\("[^"]*"\).*$/\1\2/
                x
                }
            /"dateFinished": null,/ d
            /"dateFinished":/ {
                H
                x
                s/[[:space:]]*"dateFinished":[[:space:]]*\("[^"]*"\).*$/ \1/
                s/\([[:space:]]*\)\(.*\)/\1echo "\1\\"elapsedTime\\": \\"$(datediff --format "%H:%M:%S" --input-format "%b %d, %Y %H:%M:%S %p" \2)\\","/e
                x
                G
                }
            ' \
        | jq '
            .body.paragraphs[] | select(.results.code != null) | {
                title,
                result: .results.code,
                time:   .elapsedTime,
                }
            '
        }

# -----------------------------------------------------
# Calculate the elapsed time for the whole notebook.
#[root@ansibler]

    zepnbtotaltime()
        {
        local nbident=${1:?}
        local jsonfile=$(zepnbjsonfile ${nbident})

        local first=$(
            jq -r '
                [.body.paragraphs[] | select(.dateStarted != null) | .dateStarted] | first
                ' \
                "${jsonfile}"
            )

        local last=$(
            jq -r '
                [.body.paragraphs[] | select(.dateFinished != null) | .dateFinished] | last
                ' \
                "${jsonfile}"
            )

        datediff --format "%H:%M:%S" --input-format "%b %d, %Y %H:%M:%S %p" "${first}" "${last}"
        }

# -----------------------------------------------------
# Login to Zeppelin as a normal user.
#[root@ansibler]

    gaiauser=$(secret aglais.zeppelin.gaiauser)
    gaiapass=$(secret aglais.zeppelin.gaiapass)

    zeplogin "${gaiauser:?}" "${gaiapass}"

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "principal": "gaiauser",
    >       "ticket": "2f2f000a-f9d1-4c9e-8701-38115eda7cf4",
    >       "roles": "[\"user\"]"
    >     }
    >   }


# -----------------------------------------------------
# Run the SetUp notebook.
#[root@ansibler]

    noteid=2G7GZKWUH

    zepnbclear ${noteid}

    zepnbexecute ${noteid}

    zepnbstatus ${noteid}

    zepnbparatime ${noteid}


    >   {
    >     "title": null,
    >     "result": "SUCCESS",
    >     "time": "0:0:1"
    >   }
    >   {
    >     "title": "Catalogue structure definitions",
    >     "result": "ERROR",
    >     "time": "0:0:9"
    >   }


    >   java.lang.IllegalArgumentException:
    >       Required executor memory (20480), overhead (2048 MB), and PySpark memory (0 MB) is above the max threshold (14000 MB) of this cluster!
    >           Please check the values of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'.


# -----------------------------------------------------
# -----------------------------------------------------
# Edit the deployment configuration.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        pushd deployments/hadoop-yarn/ansible/config

            gedit cclake-large-06.yml &

        popd
    popd

    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Run the Spark and Yarn configuration steps.
#[root@ansibler]

    deployconf=cclake-large-06

    pushd '/deployments/hadoop-yarn/ansible'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '16-config-yarn-masters.yml'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '17-config-yarn-workers.yml'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '22-config-spark-master.yml'

    popd


# -----------------------------------------------------
# Restart the services to recognise changes.
#[root@ansibler]

    ssh master01 \
        '
        /opt/hadoop/sbin/stop-all.sh

        sleep 30

        /opt/hadoop/sbin/start-all.sh
        '

    >   WARNING: Stopping all Apache Hadoop daemons as fedora in 10 seconds.
    >   WARNING: Use CTRL-C to abort.
    >   Stopping namenodes on [master01]
    >   Stopping datanodes
    >   Stopping secondary namenodes [gaia-dev-20210802-master01.novalocal]
    >   Stopping nodemanagers
    >   Stopping resourcemanager

    >   WARNING: Attempting to start all Apache Hadoop daemons as fedora in 10 seconds.
    >   WARNING: This is not a recommended production deployment configuration.
    >   WARNING: Use CTRL-C to abort.
    >   Starting namenodes on [master01]
    >   Starting datanodes
    >   Starting secondary namenodes [gaia-dev-20210802-master01.novalocal]
    >   Starting resourcemanager
    >   Starting nodemanagers


    ssh zeppelin \
        '
        /home/fedora/zeppelin/bin/zeppelin-daemon.sh restart
        '

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# Login to Zeppelin as a normal user.
#[root@ansibler]

    gaiauser=$(secret aglais.zeppelin.gaiauser)
    gaiapass=$(secret aglais.zeppelin.gaiapass)

    zeplogin "${gaiauser:?}" "${gaiapass}"

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "principal": "gaiauser",
    >       "ticket": "2f2f000a-f9d1-4c9e-8701-38115eda7cf4",
    >       "roles": "[\"user\"]"
    >     }
    >   }


# -----------------------------------------------------
# Run the SetUp notebook.
#[root@ansibler]

    noteid=2G7GZKWUH

    zepnbclear ${noteid}

    zepnbexecute ${noteid}

    zepnbstatus ${noteid}

    zepnbparatime ${noteid}

    >   java.lang.IllegalArgumentException:
    >       Required executor memory (8192), overhead (819 MB), and PySpark memory (0 MB) is above the max threshold (8192 MB) of this cluster!
    >           Please check the values of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'.


# -----------------------------------------------------
# -----------------------------------------------------
# Edit the deployment configuration.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        pushd deployments/hadoop-yarn/ansible/config

            gedit cclake-large-06.yml &

        popd
    popd

    # Increase the maximum to allow for a 10% overhead.
    # - yarn.scheduler.maximum-allocation-mb = 8G
    # + yarn.scheduler.maximum-allocation-mb = 9G


# -----------------------------------------------------
# -----------------------------------------------------
# Run the Spark and Yarn configuration steps.
#[root@ansibler]

    deployconf=cclake-large-06

    pushd '/deployments/hadoop-yarn/ansible'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '16-config-yarn-masters.yml'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '17-config-yarn-workers.yml'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '22-config-spark-master.yml'

    popd


# -----------------------------------------------------
# Restart the services to recognise changes.
#[root@ansibler]

    ssh master01 \
        '
        /opt/hadoop/sbin/stop-all.sh

        echo "---- ----"
        echo "Pause ...."
        sleep 30
        echo "---- ----"

        /opt/hadoop/sbin/start-all.sh
        '


    >   WARNING: Stopping all Apache Hadoop daemons as fedora in 10 seconds.
    >   WARNING: Use CTRL-C to abort.
    >   Stopping namenodes on [master01]
    >   Stopping datanodes
    >   Stopping secondary namenodes [gaia-dev-20210802-master01.novalocal]
    >   Stopping nodemanagers
    >   Stopping resourcemanager

    >   WARNING: Attempting to start all Apache Hadoop daemons as fedora in 10 seconds.
    >   WARNING: This is not a recommended production deployment configuration.
    >   WARNING: Use CTRL-C to abort.
    >   Starting namenodes on [master01]
    >   Starting datanodes
    >   Starting secondary namenodes [gaia-dev-20210802-master01.novalocal]
    >   Starting resourcemanager
    >   Starting nodemanagers


    ssh zeppelin \
        '
        /home/fedora/zeppelin/bin/zeppelin-daemon.sh restart
        '

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# Login to Zeppelin as a normal user.
#[root@ansibler]

    gaiauser=$(secret aglais.zeppelin.gaiauser)
    gaiapass=$(secret aglais.zeppelin.gaiapass)

    zeplogin "${gaiauser:?}" "${gaiapass}"

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "principal": "gaiauser",
    >       "ticket": "34e0f9d8-12c4-4d08-8884-04a435494ab5",
    >       "roles": "[\"user\"]"
    >     }
    >   }


# -----------------------------------------------------
# Run the SetUp notebook.
#[root@ansibler]

    noteid=2G7GZKWUH

    zepnbclear ${noteid}

    zepnbexecute ${noteid}

    zepnbstatus ${noteid}

    zepnbparatime ${noteid}

    >   {
    >     "title": null,
    >     "result": "SUCCESS",
    >     "time": "0:0:0"
    >   }
    >   {
    >     "title": "Catalogue structure definitions",
    >     "result": "ERROR",
    >     "time": "0:0:42"
    >   }


    >   java.lang.IllegalStateException: Spark context stopped while waiting for backend

    #
    # https://stackoverflow.com/a/56281079

        "This is because I tried sending a request with a lower --executor-memory
         (which happens to set Xmx, max heap size) than Xms (initial heap size),
         which was configured on the initial spark submit."
         The exception was thrown since max heap size can never be smaller than
         initial heap size."


