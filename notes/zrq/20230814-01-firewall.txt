#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2023, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#
# AIMetrics: []
#


    Target:

        Add firewall rules to limit access to the kubectl endpoint.

    Result:

        Work in progress ...


# -----------------------------------------------------
# Check which platform is live.
#[user@desktop]

    ssh fedora@live.gaia-dmp.uk \
        '
        date
        hostname
        '

    >   Mon 14 Aug 16:54:23 UTC 2023
    >   iris-gaia-green-20230308-zeppelin


# -----------------------------------------------------
# Create our client container.
#[user@desktop]

    agclient blue

    >   ....
    >   ....


# -----------------------------------------------------
# Delete and deploy everything.
#[root@ansibler]

    /deployments/openstack/bin/delete-all.sh \
        "${cloudname:?}"

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/00-create-all.yml'

    >   ....
    >   ....

# -----------------------------------------------------
# -----------------------------------------------------
# Login to our bootstrap node as root.
#[root@ansibler]

    ssh root@bootstrap

    source loadconfig

cat << EOF
kindclustername [${kindclustername}]
kindclusterconf [${kindclusterconf}]
workclustername [${workclustername}]
workclusterconf [${workclusterconf}]
EOF

    >   kindclustername [iris-gaia-blue-20230814-kind]
    >   kindclusterconf [/opt/aglais/iris-gaia-blue-20230814-kind.yml]
    >   workclustername [iris-gaia-blue-20230814-work]
    >   workclusterconf [/opt/aglais/iris-gaia-blue-20230814-work.yml]


# -----------------------------------------------------
# Check the cluster status.
#[root@bootstrap]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackClusters

    >   NAME                           CLUSTER                        READY   NETWORK                                SUBNET                                 BASTION IP   AGE
    >   iris-gaia-blue-20230814-work   iris-gaia-blue-20230814-work   true    be3043ab-84b7-4d50-a762-3620ab6f9e28   bdfdb7a3-3476-4cca-ae30-946e5144c326                11m


# -----------------------------------------------------
# Check the cluster status.
#[root@bootstrap]

    clusterctl \
        --kubeconfig "${kindclusterconf:?}" \
        describe cluster \
            "${workclustername:?}"

    >               "${workclustername:?}"
    >   NAME                                                                             READY  SEVERITY  REASON  SINCE  MESSAGE
    >   Cluster/iris-gaia-blue-20230814-work                                             True                     6m48s
    >   ├─ClusterInfrastructure - OpenStackCluster/iris-gaia-blue-20230814-work
    >   ├─ControlPlane - KubeadmControlPlane/iris-gaia-blue-20230814-work-control-plane  True                     6m48s
    >   │  └─3 Machines...                                                                True                     10m    See iris-gaia-blue-20230814-work-control-plane-j5b7n, iris-gaia-blue-20230814-work-control-plane-kmjml, ...
    >   └─Workers
    >       └─MachineDeployment/iris-gaia-blue-20230814-work-md-0                          True                     8m4s
    >           └─3 Machines...                                                              True                     9m     See iris-gaia-blue-20230814-work-md-0-58465fc9c8xqslgq-5kxkj, iris-gaia-blue-20230814-work-md-0-58465fc9c8xqslgq-7j959, ...


# -----------------------------------------------------
# -----------------------------------------------------
# Start a new shell connected to our client container.
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler-blue \
            bash

    >   ....
    >   ....


# -----------------------------------------------------
# Load the kubeconfig locations.
#[root@ansibler]

    source /deployments/cluster-api/bootstrap/ansible/files/aglais/bin/loadconfig

cat << EOF
kindclustername [${kindclustername}]
kindclusterconf [${kindclusterconf}]
workclustername [${workclustername}]
workclusterconf [${workclusterconf}]
EOF

    >   kindclustername [iris-gaia-blue-20230814-kind]
    >   kindclusterconf [/opt/aglais/iris-gaia-blue-20230814-kind.yml]
    >   workclustername [iris-gaia-blue-20230814-work]
    >   workclusterconf [/opt/aglais/iris-gaia-blue-20230814-work.yml]


# -----------------------------------------------------
# Check we have the kubeconfig files in our client.
#[root@ansibler]

    yq '
        .
      | .clusters[].cluster.certificate-authority-data="...."
      | .users[].user.client-certificate-data="...."
      | .users[].user.client-key-data="...."
        ' "${kindclusterconf:?}"

    >   apiVersion: v1
    >   clusters:
    >     - cluster:
    >         certificate-authority-data: '....'
    >         server: https://127.0.0.1:35039
    >       name: kind-iris-gaia-blue-20230814-kind
    >   contexts:
    >     - context:
    >         cluster: kind-iris-gaia-blue-20230814-kind
    >         user: kind-iris-gaia-blue-20230814-kind
    >       name: kind-iris-gaia-blue-20230814-kind
    >   current-context: kind-iris-gaia-blue-20230814-kind
    >   kind: Config
    >   preferences: {}
    >   users:
    >     - name: kind-iris-gaia-blue-20230814-kind
    >       user:
    >         client-certificate-data: '....'
    >         client-key-data: '....'


    yq '
        .
      | .clusters[].cluster.certificate-authority-data="...."
      | .users[].user.client-certificate-data="...."
      | .users[].user.client-key-data="...."
        ' "${workclusterconf:?}"

    >   apiVersion: v1
    >   clusters:
    >     - cluster:
    >         certificate-authority-data: '....'
    >         server: https://128.232.226.67:6443
    >       name: iris-gaia-blue-20230814-work
    >   contexts:
    >     - context:
    >         cluster: iris-gaia-blue-20230814-work
    >         user: iris-gaia-blue-20230814-work-admin
    >       name: iris-gaia-blue-20230814-work-admin@iris-gaia-blue-20230814-work
    >   current-context: iris-gaia-blue-20230814-work-admin@iris-gaia-blue-20230814-work
    >   kind: Config
    >   preferences: {}
    >   users:
    >     - name: iris-gaia-blue-20230814-work-admin
    >       user:
    >         client-certificate-data: '....'
    >         client-key-data: '....'


# -----------------------------------------------------
# Check we can reach the work cluster from our client container.
#[root@ansibler]

    kubectl \
        --kubeconfig "${workclusterconf:?}" \
        cluster-info

    >   Kubernetes control plane is running at https://128.232.226.67:6443
    >   CoreDNS is running at https://128.232.226.67:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
    >   ....


    kubectl \
        --kubeconfig "${workclusterconf:?}" \
        top Nodes

    >   NAME                                                        CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
    >   iris-gaia-blue-20230814-work-control-plane-8b319b28-dczxf   111m         2%     1212Mi          20%
    >   iris-gaia-blue-20230814-work-control-plane-8b319b28-pmtt5   188m         4%     1685Mi          28%
    >   iris-gaia-blue-20230814-work-control-plane-8b319b28-twn49   111m         2%     1340Mi          22%
    >   iris-gaia-blue-20230814-work-md-0-8b319b28-ccmt6            64m          1%     1072Mi          18%
    >   iris-gaia-blue-20230814-work-md-0-8b319b28-p97kz            51m          1%     847Mi           14%
    >   iris-gaia-blue-20230814-work-md-0-8b319b28-v5v8j            51m          1%     700Mi           11%


# -----------------------------------------------------
# List the firewall rules currently in place.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        security group list

    >   +--------------------------------------+------------------------------------------------------------------------+---------------------------+----------------------------------+------+
    >   | ID                                   | Name                                                                   | Description               | Project                          | Tags |
    >   +--------------------------------------+------------------------------------------------------------------------+---------------------------+----------------------------------+------+
    >   | 4662925b-b3b7-4746-b35b-fbcc440a8cb9 | iris-gaia-blue-20230814-bootstrap-security                             |                           | e918a13fed2648758175a15fac083569 | []   |
    >   | 6f1da941-0dcd-4f72-8f1d-3c00001030aa | k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-worker       | Cluster API managed group | e918a13fed2648758175a15fac083569 | []   |
    >   | c76f55b9-df80-4262-a855-26c4111a9a43 | k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-controlplane | Cluster API managed group | e918a13fed2648758175a15fac083569 | []   |
    >   | e1c6a1db-3caf-47f5-91e2-51a3e1967dc6 | default                                                                | Default security group    | e918a13fed2648758175a15fac083569 | []   |
    >   +--------------------------------------+------------------------------------------------------------------------+---------------------------+----------------------------------+------+


    openstack \
        --os-cloud "${cloudname:?}" \
        security group rule list \
            '6f1da941-0dcd-4f72-8f1d-3c00001030aa'

    >   +--------------------------------------+-------------+-----------+-----------+-------------+-----------+--------------------------------------+----------------------+
    >   | ID                                   | IP Protocol | Ethertype | IP Range  | Port Range  | Direction | Remote Security Group                | Remote Address Group |
    >   +--------------------------------------+-------------+-----------+-----------+-------------+-----------+--------------------------------------+----------------------+
    >   | 2586e14a-4086-4ee6-a610-8691f5d5d023 | None        | IPv4      | 0.0.0.0/0 |             | ingress   | c76f55b9-df80-4262-a855-26c4111a9a43 | None                 |
    >   | 8f8efbb4-509b-4640-882e-f5f9328ad36b | None        | IPv4      | 0.0.0.0/0 |             | egress    | None                                 | None                 |
    >   | 94679ec3-6d73-4db1-9979-59a44690a03c | None        | IPv6      | ::/0      |             | egress    | None                                 | None                 |
    >   | c26e6034-b9a3-4645-b51f-5615d5e1db3e | tcp         | IPv4      | 0.0.0.0/0 | 30000:32767 | ingress   | None                                 | None                 |
    >   | c98da75d-d1b3-4ddc-9e20-3c0237e480d3 | None        | IPv4      | 0.0.0.0/0 |             | ingress   | 6f1da941-0dcd-4f72-8f1d-3c00001030aa | None                 |
    >   | f78c7887-2d3a-4833-a235-60aca0ab86d8 | udp         | IPv4      | 0.0.0.0/0 | 30000:32767 | ingress   | None                                 | None                 |
    >   +--------------------------------------+-------------+-----------+-----------+-------------+-----------+--------------------------------------+----------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        security group rule list \
            'c76f55b9-df80-4262-a855-26c4111a9a43'

    >   +--------------------------------------+-------------+-----------+-----------+------------+-----------+--------------------------------------+----------------------+
    >   | ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Direction | Remote Security Group                | Remote Address Group |
    >   +--------------------------------------+-------------+-----------+-----------+------------+-----------+--------------------------------------+----------------------+
    >   | 1c3734a1-94cb-48fd-a902-626645ee23ea | None        | IPv4      | 0.0.0.0/0 |            | egress    | None                                 | None                 |
    >   | 2939887a-6f02-427f-9d20-daf4032029a3 | tcp         | IPv4      | 0.0.0.0/0 | 6443:6443  | ingress   | None                                 | None                 |
    >   | 3287a8bc-febe-4a05-90ef-b367852ec845 | None        | IPv6      | ::/0      |            | egress    | None                                 | None                 |
    >   | 331368f0-e24f-4f2e-ade5-0bbabd4dc618 | None        | IPv4      | 0.0.0.0/0 |            | ingress   | c76f55b9-df80-4262-a855-26c4111a9a43 | None                 |
    >   | b034be04-e850-4663-9896-9ca760212e5e | None        | IPv4      | 0.0.0.0/0 |            | ingress   | 6f1da941-0dcd-4f72-8f1d-3c00001030aa | None                 |
    >   +--------------------------------------+-------------+-----------+-----------+------------+-----------+--------------------------------------+----------------------+

    #
    # We want to block the kubectl port on the ControlPlane group and the NodePort ports on the workers.
    # In theory we could just edit the security group rules directly,
    # but it is worth trying to use ClusterAPI to edit them.
    #

# -----------------------------------------------------
# -----------------------------------------------------
# ChatGPT

    >   Can we use ClusterAPI to edit the control nodes security group on an openstack system ?

    >   As of my last knowledge update in September 2021, ClusterAPI is a project that aims to provide
    >   declarative APIs and tooling for managing Kubernetes clusters. It abstracts the underlying
    >   infrastructure, allowing you to create, update, and delete Kubernetes clusters on various cloud
    >   providers and infrastructure platforms, including OpenStack.
    >   
    >   While ClusterAPI provides a way to manage Kubernetes clusters, it typically focuses on managing
    >   the Kubernetes components and their configuration, rather than directly manipulating the
    >   underlying infrastructure components like security groups.
    >   
    >   To edit the security group of control nodes in an OpenStack system, you would usually interact
    >   with OpenStack's APIs or command-line tools directly. OpenStack provides tools like
    >   `openstack security group rule create`, `openstack security group rule delete`, etc.,
    >   to manage security group rules.
    >   
    >   If you're looking to automate this process as part of managing your Kubernetes clusters,
    >   you might need to integrate ClusterAPI with your OpenStack-specific scripts or tools to
    >   manipulate security groups. ClusterAPI itself might not directly handle security group
    >   management.
    >   
    >   However, please note that developments could have occurred after September 2021. I recommend
    >   checking the ClusterAPI documentation and the OpenStack documentation for any updates or new
    >   features related to this topic.

# -----------------------------------------------------
# -----------------------------------------------------
# Check what components we have in the KinD cluster.
#[root@bootstrap]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        api-resources

    >   NAME                              SHORTNAMES   APIVERSION                                 NAMESPACED   KIND
    >   bindings                                       v1                                         true         Binding
    >   componentstatuses                 cs           v1                                         false        ComponentStatus
    >   configmaps                        cm           v1                                         true         ConfigMap
    >   endpoints                         ep           v1                                         true         Endpoints
    >   events                            ev           v1                                         true         Event
    >   limitranges                       limits       v1                                         true         LimitRange
    >   namespaces                        ns           v1                                         false        Namespace
    >   nodes                             no           v1                                         false        Node
    >   persistentvolumeclaims            pvc          v1                                         true         PersistentVolumeClaim
    >   persistentvolumes                 pv           v1                                         false        PersistentVolume
    >   pods                              po           v1                                         true         Pod
    >   podtemplates                                   v1                                         true         PodTemplate
    >   replicationcontrollers            rc           v1                                         true         ReplicationController
    >   resourcequotas                    quota        v1                                         true         ResourceQuota
    >   secrets                                        v1                                         true         Secret
    >   serviceaccounts                   sa           v1                                         true         ServiceAccount
    >   services                          svc          v1                                         true         Service
    >   challenges                                     acme.cert-manager.io/v1                    true         Challenge
    >   orders                                         acme.cert-manager.io/v1                    true         Order
    >   clusterresourcesetbindings                     addons.cluster.x-k8s.io/v1beta1            true         ClusterResourceSetBinding
    >   clusterresourcesets                            addons.cluster.x-k8s.io/v1beta1            true         ClusterResourceSet
    >   helmreleases                                   addons.stackhpc.com/v1alpha1               true         HelmRelease
    >   manifests                                      addons.stackhpc.com/v1alpha1               true         Manifests
    >   mutatingwebhookconfigurations                  admissionregistration.k8s.io/v1            false        MutatingWebhookConfiguration
    >   validatingwebhookconfigurations                admissionregistration.k8s.io/v1            false        ValidatingWebhookConfiguration
    >   customresourcedefinitions         crd,crds     apiextensions.k8s.io/v1                    false        CustomResourceDefinition
    >   apiservices                                    apiregistration.k8s.io/v1                  false        APIService
    >   controllerrevisions                            apps/v1                                    true         ControllerRevision
    >   daemonsets                        ds           apps/v1                                    true         DaemonSet
    >   deployments                       deploy       apps/v1                                    true         Deployment
    >   replicasets                       rs           apps/v1                                    true         ReplicaSet
    >   statefulsets                      sts          apps/v1                                    true         StatefulSet
    >   tokenreviews                                   authentication.k8s.io/v1                   false        TokenReview
    >   localsubjectaccessreviews                      authorization.k8s.io/v1                    true         LocalSubjectAccessReview
    >   selfsubjectaccessreviews                       authorization.k8s.io/v1                    false        SelfSubjectAccessReview
    >   selfsubjectrulesreviews                        authorization.k8s.io/v1                    false        SelfSubjectRulesReview
    >   subjectaccessreviews                           authorization.k8s.io/v1                    false        SubjectAccessReview
    >   horizontalpodautoscalers          hpa          autoscaling/v2                             true         HorizontalPodAutoscaler
    >   cronjobs                          cj           batch/v1                                   true         CronJob
    >   jobs                                           batch/v1                                   true         Job
    >   kubeadmconfigs                                 bootstrap.cluster.x-k8s.io/v1beta1         true         KubeadmConfig
    >   kubeadmconfigtemplates                         bootstrap.cluster.x-k8s.io/v1beta1         true         KubeadmConfigTemplate
    >   certificaterequests               cr,crs       cert-manager.io/v1                         true         CertificateRequest
    >   certificates                      cert,certs   cert-manager.io/v1                         true         Certificate
    >   clusterissuers                                 cert-manager.io/v1                         false        ClusterIssuer
    >   issuers                                        cert-manager.io/v1                         true         Issuer
    >   certificatesigningrequests        csr          certificates.k8s.io/v1                     false        CertificateSigningRequest
    >   clusterclasses                    cc           cluster.x-k8s.io/v1beta1                   true         ClusterClass
    >   clusters                          cl           cluster.x-k8s.io/v1beta1                   true         Cluster
    >   machinedeployments                md           cluster.x-k8s.io/v1beta1                   true         MachineDeployment
    >   machinehealthchecks               mhc,mhcs     cluster.x-k8s.io/v1beta1                   true         MachineHealthCheck
    >   machinepools                      mp           cluster.x-k8s.io/v1beta1                   true         MachinePool
    >   machines                          ma           cluster.x-k8s.io/v1beta1                   true         Machine
    >   machinesets                       ms           cluster.x-k8s.io/v1beta1                   true         MachineSet
    >   providers                                      clusterctl.cluster.x-k8s.io/v1alpha3       true         Provider
    >   kubeadmcontrolplanes              kcp          controlplane.cluster.x-k8s.io/v1beta1      true         KubeadmControlPlane
    >   kubeadmcontrolplanetemplates                   controlplane.cluster.x-k8s.io/v1beta1      true         KubeadmControlPlaneTemplate
    >   leases                                         coordination.k8s.io/v1                     true         Lease
    >   endpointslices                                 discovery.k8s.io/v1                        true         EndpointSlice
    >   events                            ev           events.k8s.io/v1                           true         Event
    >   flowschemas                                    flowcontrol.apiserver.k8s.io/v1beta3       false        FlowSchema
    >   prioritylevelconfigurations                    flowcontrol.apiserver.k8s.io/v1beta3       false        PriorityLevelConfiguration
    >   openstackclusters                 osc          infrastructure.cluster.x-k8s.io/v1alpha6   true         OpenStackCluster
    >   openstackclustertemplates         osct         infrastructure.cluster.x-k8s.io/v1alpha6   true         OpenStackClusterTemplate
    >   openstackmachines                 osm          infrastructure.cluster.x-k8s.io/v1alpha6   true         OpenStackMachine
    >   openstackmachinetemplates         osmt         infrastructure.cluster.x-k8s.io/v1alpha6   true         OpenStackMachineTemplate
    >   ipaddressclaims                                ipam.cluster.x-k8s.io/v1alpha1             true         IPAddressClaim
    >   ipaddresses                                    ipam.cluster.x-k8s.io/v1alpha1             true         IPAddress
    >   ingressclasses                                 networking.k8s.io/v1                       false        IngressClass
    >   ingresses                         ing          networking.k8s.io/v1                       true         Ingress
    >   networkpolicies                   netpol       networking.k8s.io/v1                       true         NetworkPolicy
    >   runtimeclasses                                 node.k8s.io/v1                             false        RuntimeClass
    >   poddisruptionbudgets              pdb          policy/v1                                  true         PodDisruptionBudget
    >   clusterrolebindings                            rbac.authorization.k8s.io/v1               false        ClusterRoleBinding
    >   clusterroles                                   rbac.authorization.k8s.io/v1               false        ClusterRole
    >   rolebindings                                   rbac.authorization.k8s.io/v1               true         RoleBinding
    >   roles                                          rbac.authorization.k8s.io/v1               true         Role
    >   extensionconfigs                  ext          runtime.cluster.x-k8s.io/v1alpha1          false        ExtensionConfig
    >   priorityclasses                   pc           scheduling.k8s.io/v1                       false        PriorityClass
    >   csidrivers                                     storage.k8s.io/v1                          false        CSIDriver
    >   csinodes                                       storage.k8s.io/v1                          false        CSINode
    >   csistoragecapacities                           storage.k8s.io/v1                          true         CSIStorageCapacity
    >   storageclasses                    sc           storage.k8s.io/v1                          false        StorageClass
    >   volumeattachments                              storage.k8s.io/v1                          false        VolumeAttachment


    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackClusters \
            --all-namespaces

    >   NAMESPACE   NAME                           CLUSTER                        READY   NETWORK                                SUBNET                                 BASTION IP   AGE
    >   default     iris-gaia-blue-20230814-work   iris-gaia-blue-20230814-work   true    be3043ab-84b7-4d50-a762-3620ab6f9e28   bdfdb7a3-3476-4cca-ae30-946e5144c326                65m


    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}"

    >   {
    >       "apiVersion": "infrastructure.cluster.x-k8s.io/v1alpha6",
    >       "kind": "OpenStackCluster",
    >       "metadata": {
    >           "annotations": {
    >               "helm.sh/resource-policy": "keep",
    >               "meta.helm.sh/release-name": "iris-gaia-blue-20230814-work",
    >               "meta.helm.sh/release-namespace": "default"
    >           },
    >           "creationTimestamp": "2023-08-14T16:57:11Z",
    >           "finalizers": [
    >               "openstackcluster.infrastructure.cluster.x-k8s.io"
    >           ],
    >           "generation": 2,
    >           "labels": {
    >               "app.kubernetes.io/managed-by": "Helm",
    >               "capi.stackhpc.com/cluster": "iris-gaia-blue-20230814-work",
    >               "capi.stackhpc.com/infrastructure-provider": "openstack",
    >               "capi.stackhpc.com/managed-by": "Helm",
    >               "cluster.x-k8s.io/cluster-name": "iris-gaia-blue-20230814-work",
    >               "helm.sh/chart": "openstack-cluster-0.1.0"
    >           },
    >           "name": "iris-gaia-blue-20230814-work",
    >           "namespace": "default",
    >           "ownerReferences": [
    >               {
    >                   "apiVersion": "cluster.x-k8s.io/v1beta1",
    >                   "blockOwnerDeletion": true,
    >                   "controller": true,
    >                   "kind": "Cluster",
    >                   "name": "iris-gaia-blue-20230814-work",
    >                   "uid": "066d47c1-8ece-454e-ad20-5b420bad47e9"
    >               }
    >           ],
    >           "resourceVersion": "1846",
    >           "uid": "945adf34-cdd0-4b6c-b8b3-3bc24a347470"
    >       },
    >       "spec": {
    >           "allowAllInClusterTraffic": true,
    >           "apiServerLoadBalancer": {
    >               "enabled": true
    >           },
    >           "apiServerPort": 6443,
    >           "cloudName": "openstack",
    >           "controlPlaneEndpoint": {
    >               "host": "128.232.226.67",
    >               "port": 6443
    >           },
    >           "controlPlaneOmitAvailabilityZone": true,
    >           "disableAPIServerFloatingIP": false,
    >           "dnsNameservers": [
    >               "131.111.8.42"
    >           ],
    >           "externalNetworkId": "57add367-d205-4030-a929-d75617a7c63e",
    >           "identityRef": {
    >               "kind": "Secret",
    >               "name": "iris-gaia-blue-20230814-work-cloud-credentials"
    >           },
    >           "managedSecurityGroups": true,
    >           "network": {},
    >           "nodeCidr": "192.168.3.0/24",
    >           "subnet": {}
    >       },
    >       "status": {
    >           "controlPlaneSecurityGroup": {
    >               "id": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >               "name": "k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-controlplane",
    >               "rules": [
    >                   {
    >                       "description": "Full open",
    >                       "direction": "egress",
    >                       "etherType": "IPv4",
    >                       "name": "1c3734a1-94cb-48fd-a902-626645ee23ea",
    >                       "portRangeMax": 0,
    >                       "portRangeMin": 0,
    >                       "protocol": "",
    >                       "remoteGroupID": "",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >                   },
    >                   {
    >                       "description": "Full open",
    >                       "direction": "egress",
    >                       "etherType": "IPv6",
    >                       "name": "3287a8bc-febe-4a05-90ef-b367852ec845",
    >                       "portRangeMax": 0,
    >                       "portRangeMin": 0,
    >                       "protocol": "",
    >                       "remoteGroupID": "",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >                   },
    >                   {
    >                       "description": "Kubernetes API",
    >                       "direction": "ingress",
    >                       "etherType": "IPv4",
    >                       "name": "2939887a-6f02-427f-9d20-daf4032029a3",
    >                       "portRangeMax": 6443,
    >                       "portRangeMin": 6443,
    >                       "protocol": "tcp",
    >                       "remoteGroupID": "",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >                   },
    >                   {
    >                       "description": "In-cluster Ingress",
    >                       "direction": "ingress",
    >                       "etherType": "IPv4",
    >                       "name": "331368f0-e24f-4f2e-ade5-0bbabd4dc618",
    >                       "portRangeMax": 0,
    >                       "portRangeMin": 0,
    >                       "protocol": "",
    >                       "remoteGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >                   },
    >                   {
    >                       "description": "In-cluster Ingress",
    >                       "direction": "ingress",
    >                       "etherType": "IPv4",
    >                       "name": "b034be04-e850-4663-9896-9ca760212e5e",
    >                       "portRangeMax": 0,
    >                       "portRangeMin": 0,
    >                       "protocol": "",
    >                       "remoteGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >                   }
    >               ]
    >           },
    >           "externalNetwork": {
    >               "id": "57add367-d205-4030-a929-d75617a7c63e",
    >               "name": "CUDN-Internet"
    >           },
    >           "failureDomains": {
    >               "nova": {}
    >           },
    >           "network": {
    >               "apiServerLoadBalancer": {
    >                   "id": "7bf0e534-d801-4db0-8124-d49fb6bc99a9",
    >                   "internalIP": "192.168.3.98",
    >                   "ip": "128.232.226.67",
    >                   "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi"
    >               },
    >               "id": "be3043ab-84b7-4d50-a762-3620ab6f9e28",
    >               "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work",
    >               "router": {
    >                   "id": "d680f527-1708-47bb-905d-5d9cb4c7e8af",
    >                   "ips": [
    >                       "128.232.226.165"
    >                   ],
    >                   "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work"
    >               },
    >               "subnet": {
    >                   "cidr": "192.168.3.0/24",
    >                   "id": "bdfdb7a3-3476-4cca-ae30-946e5144c326",
    >                   "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work"
    >               }
    >           },
    >           "ready": true,
    >           "workerSecurityGroup": {
    >               "id": "6f1da941-0dcd-4f72-8f1d-3c00001030aa",
    >               "name": "k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-worker",
    >               "rules": [
    >                   {
    >                       "description": "Full open",
    >                       "direction": "egress",
    >                       "etherType": "IPv4",
    >                       "name": "8f8efbb4-509b-4640-882e-f5f9328ad36b",
    >                       "portRangeMax": 0,
    >                       "portRangeMin": 0,
    >                       "protocol": "",
    >                       "remoteGroupID": "",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa"
    >                   },
    >                   {
    >                       "description": "Full open",
    >                       "direction": "egress",
    >                       "etherType": "IPv6",
    >                       "name": "94679ec3-6d73-4db1-9979-59a44690a03c",
    >                       "portRangeMax": 0,
    >                       "portRangeMin": 0,
    >                       "protocol": "",
    >                       "remoteGroupID": "",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa"
    >                   },
    >                   {
    >                       "description": "Node Port Services",
    >                       "direction": "ingress",
    >                       "etherType": "IPv4",
    >                       "name": "c26e6034-b9a3-4645-b51f-5615d5e1db3e",
    >                       "portRangeMax": 32767,
    >                       "portRangeMin": 30000,
    >                       "protocol": "tcp",
    >                       "remoteGroupID": "",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa"
    >                   },
    >                   {
    >                       "description": "Node Port Services",
    >                       "direction": "ingress",
    >                       "etherType": "IPv4",
    >                       "name": "f78c7887-2d3a-4833-a235-60aca0ab86d8",
    >                       "portRangeMax": 32767,
    >                       "portRangeMin": 30000,
    >                       "protocol": "udp",
    >                       "remoteGroupID": "",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa"
    >                   },
    >                   {
    >                       "description": "In-cluster Ingress",
    >                       "direction": "ingress",
    >                       "etherType": "IPv4",
    >                       "name": "c98da75d-d1b3-4ddc-9e20-3c0237e480d3",
    >                       "portRangeMax": 0,
    >                       "portRangeMin": 0,
    >                       "protocol": "",
    >                       "remoteGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa"
    >                   },
    >                   {
    >                       "description": "In-cluster Ingress",
    >                       "direction": "ingress",
    >                       "etherType": "IPv4",
    >                       "name": "2586e14a-4086-4ee6-a610-8691f5d5d023",
    >                       "portRangeMax": 0,
    >                       "portRangeMin": 0,
    >                       "protocol": "",
    >                       "remoteGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >                       "remoteIPPrefix": "",
    >                       "securityGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa"
    >                   }
    >               ]
    >           }
    >       }
    >   }

    #
    # Interesting part is here ...
    #

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.controlPlaneSecurityGroup'

    >   {
    >     "id": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >     "name": "k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-controlplane",
    >     "rules": [
    >       {
    >         "description": "Full open",
    >         "direction": "egress",
    >         "etherType": "IPv4",
    >         "name": "1c3734a1-94cb-48fd-a902-626645ee23ea",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "Full open",
    >         "direction": "egress",
    >         "etherType": "IPv6",
    >         "name": "3287a8bc-febe-4a05-90ef-b367852ec845",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "Kubernetes API",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "2939887a-6f02-427f-9d20-daf4032029a3",
    >         "portRangeMax": 6443,
    >         "portRangeMin": 6443,
    >         "protocol": "tcp",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "In-cluster Ingress",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "331368f0-e24f-4f2e-ade5-0bbabd4dc618",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "In-cluster Ingress",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "b034be04-e850-4663-9896-9ca760212e5e",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       }
    >     ]
    >   }

    #
    # My guess this is generated from spec.apiServerLoadBalancer.allowedCidrs.
    # https://github.com/kubernetes-sigs/cluster-api-provider-openstack/blob/main/docs/book/src/clusteropenstack/configuration.md#restrict-access-to-the-api-server
    #
    # In which case, what happens if we update the spec to include a list of allowed address ranges.
    #

    cat > /tmp/cluster-access-patch.yml << EOF
spec:
  apiServerLoadBalancer:
    allowedCidrs:
    - 128.232.227.20
    - 90.155.51.57
EOF

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        patch OpenStackCluster \
            "${workclustername:?}" \
            --patch-file '/tmp/cluster-access-patch.yml'

    >   error: application/strategic-merge-patch+json is not supported by infrastructure.cluster.x-k8s.io/v1alpha6, Kind=OpenStackCluster:
    >       the body of the request was in an unknown format
    >       - accepted media types include:
    >           application/json-patch+json, application/merge-patch+json, application/apply-patch+yaml

    #
    # I've seen this before and it wasn't the unknown format it was the patch strategy.
    #

    cat > /tmp/cluster-access-patch.yml << EOF
spec:
  apiServerLoadBalancer:
    allowedCidrs:
    - 128.232.227.20
    - 90.155.51.57
EOF

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        patch OpenStackCluster \
            "${workclustername:?}" \
            --type merge \
            --patch-file '/tmp/cluster-access-patch.yml'

    >   openstackcluster.infrastructure.cluster.x-k8s.io/iris-gaia-blue-20230814-work patched

    #
    # Patch to the spec worked OK.
    #

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.spec.apiServerLoadBalancer'

    >   {
    >     "allowedCidrs": [
    >       "128.232.227.20",
    >       "90.155.51.57"
    >     ],
    >     "enabled": true
    >   }

    #
    # Hasn't shown up in the security groups yet ...
    #

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "id": "7bf0e534-d801-4db0-8124-d49fb6bc99a9",
    >     "internalIP": "192.168.3.98",
    >     "ip": "128.232.226.67",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi"
    >   }


    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.controlPlaneSecurityGroup'

    >   ....
    >       {
    >         "description": "Kubernetes API",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "2939887a-6f02-427f-9d20-daf4032029a3",
    >         "portRangeMax": 6443,
    >         "portRangeMin": 6443,
    >         "protocol": "tcp",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >   ....

    #
    # Should we specify full CIDRs rather than just IP addresses ?
    #

    cat > /tmp/cluster-access-patch.yml << EOF
spec:
  apiServerLoadBalancer:
    allowedCidrs:
    - 128.232.227.20/32
    - 90.155.51.57/32
EOF

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        patch OpenStackCluster \
            "${workclustername:?}" \
            --type merge \
            --patch-file '/tmp/cluster-access-patch.yml'

    >   openstackcluster.infrastructure.cluster.x-k8s.io/iris-gaia-blue-20230814-work patched


    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.spec.apiServerLoadBalancer'

    >   {
    >     "allowedCidrs": [
    >       "128.232.227.20/32",
    >       "90.155.51.57/32"
    >     ],
    >     "enabled": true
    >   }

    #
    # Yep, that got picked up in the status ..
    #

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "allowedCIDRs": [
    >       "128.232.226.165/32",
    >       "128.232.227.20/32",
    >       "192.168.3.0/24",
    >       "90.155.51.57/32"
    >     ],
    >     "id": "7bf0e534-d801-4db0-8124-d49fb6bc99a9",
    >     "internalIP": "192.168.3.98",
    >     "ip": "128.232.226.67",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi"
    >   }

    #
    # .. but not in the security groups yet ..
    #

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.controlPlaneSecurityGroup'

    >   {
    >     "id": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >     "name": "k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-controlplane",
    >     "rules": [
    >       {
    >         "description": "Full open",
    >         "direction": "egress",
    >         "etherType": "IPv4",
    >         "name": "1c3734a1-94cb-48fd-a902-626645ee23ea",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "Full open",
    >         "direction": "egress",
    >         "etherType": "IPv6",
    >         "name": "3287a8bc-febe-4a05-90ef-b367852ec845",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "Kubernetes API",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "2939887a-6f02-427f-9d20-daf4032029a3",
    >         "portRangeMax": 6443,
    >         "portRangeMin": 6443,
    >         "protocol": "tcp",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "In-cluster Ingress",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "331368f0-e24f-4f2e-ade5-0bbabd4dc618",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "In-cluster Ingress",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "b034be04-e850-4663-9896-9ca760212e5e",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       }
    >     ]
    >   }

    #
    # Dinner interrupts ....
    #

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "id": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >     "name": "k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-controlplane",
    >     "rules": [
    >       {
    >         "description": "Full open",
    >         "direction": "egress",
    >         "etherType": "IPv4",
    >         "name": "1c3734a1-94cb-48fd-a902-626645ee23ea",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "Full open",
    >         "direction": "egress",
    >         "etherType": "IPv6",
    >         "name": "3287a8bc-febe-4a05-90ef-b367852ec845",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "Kubernetes API",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "2939887a-6f02-427f-9d20-daf4032029a3",
    >         "portRangeMax": 6443,
    >         "portRangeMin": 6443,
    >         "protocol": "tcp",
    >         "remoteGroupID": "",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "In-cluster Ingress",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "331368f0-e24f-4f2e-ade5-0bbabd4dc618",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       },
    >       {
    >         "description": "In-cluster Ingress",
    >         "direction": "ingress",
    >         "etherType": "IPv4",
    >         "name": "b034be04-e850-4663-9896-9ca760212e5e",
    >         "portRangeMax": 0,
    >         "portRangeMin": 0,
    >         "protocol": "",
    >         "remoteGroupID": "6f1da941-0dcd-4f72-8f1d-3c00001030aa",
    >         "remoteIPPrefix": "",
    >         "securityGroupID": "c76f55b9-df80-4262-a855-26c4111a9a43"
    >       }
    >     ]
    >   }

    #
    # Still not reflected in the SecurityRules.
    #

# -----------------------------------------------------
# -----------------------------------------------------
# List the firewall rules currently in place.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        security group list

    >   +--------------------------------------+------------------------------------------------------------------------+---------------------------+----------------------------------+------+
    >   | ID                                   | Name                                                                   | Description               | Project                          | Tags |
    >   +--------------------------------------+------------------------------------------------------------------------+---------------------------+----------------------------------+------+
    >   | 4662925b-b3b7-4746-b35b-fbcc440a8cb9 | iris-gaia-blue-20230814-bootstrap-security                             |                           | e918a13fed2648758175a15fac083569 | []   |
    >   | 6f1da941-0dcd-4f72-8f1d-3c00001030aa | k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-worker       | Cluster API managed group | e918a13fed2648758175a15fac083569 | []   |
    >   | c76f55b9-df80-4262-a855-26c4111a9a43 | k8s-cluster-default-iris-gaia-blue-20230814-work-secgroup-controlplane | Cluster API managed group | e918a13fed2648758175a15fac083569 | []   |
    >   | e1c6a1db-3caf-47f5-91e2-51a3e1967dc6 | default                                                                | Default security group    | e918a13fed2648758175a15fac083569 | []   |
    >   +--------------------------------------+------------------------------------------------------------------------+---------------------------+----------------------------------+------+


    openstack \
        --os-cloud "${cloudname:?}" \
        security group rule list \
            '6f1da941-0dcd-4f72-8f1d-3c00001030aa'

    >   +--------------------------------------+-------------+-----------+-----------+-------------+-----------+--------------------------------------+----------------------+
    >   | ID                                   | IP Protocol | Ethertype | IP Range  | Port Range  | Direction | Remote Security Group                | Remote Address Group |
    >   +--------------------------------------+-------------+-----------+-----------+-------------+-----------+--------------------------------------+----------------------+
    >   | 2586e14a-4086-4ee6-a610-8691f5d5d023 | None        | IPv4      | 0.0.0.0/0 |             | ingress   | c76f55b9-df80-4262-a855-26c4111a9a43 | None                 |
    >   | 8f8efbb4-509b-4640-882e-f5f9328ad36b | None        | IPv4      | 0.0.0.0/0 |             | egress    | None                                 | None                 |
    >   | 94679ec3-6d73-4db1-9979-59a44690a03c | None        | IPv6      | ::/0      |             | egress    | None                                 | None                 |
    >   | c26e6034-b9a3-4645-b51f-5615d5e1db3e | tcp         | IPv4      | 0.0.0.0/0 | 30000:32767 | ingress   | None                                 | None                 |
    >   | c98da75d-d1b3-4ddc-9e20-3c0237e480d3 | None        | IPv4      | 0.0.0.0/0 |             | ingress   | 6f1da941-0dcd-4f72-8f1d-3c00001030aa | None                 |
    >   | f78c7887-2d3a-4833-a235-60aca0ab86d8 | udp         | IPv4      | 0.0.0.0/0 | 30000:32767 | ingress   | None                                 | None                 |
    >   +--------------------------------------+-------------+-----------+-----------+-------------+-----------+--------------------------------------+----------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        security group rule list \
            'c76f55b9-df80-4262-a855-26c4111a9a43'

    >   +--------------------------------------+-------------+-----------+-----------+------------+-----------+--------------------------------------+----------------------+
    >   | ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Direction | Remote Security Group                | Remote Address Group |
    >   +--------------------------------------+-------------+-----------+-----------+------------+-----------+--------------------------------------+----------------------+
    >   | 1c3734a1-94cb-48fd-a902-626645ee23ea | None        | IPv4      | 0.0.0.0/0 |            | egress    | None                                 | None                 |
    >   | 2939887a-6f02-427f-9d20-daf4032029a3 | tcp         | IPv4      | 0.0.0.0/0 | 6443:6443  | ingress   | None                                 | None                 |
    >   | 3287a8bc-febe-4a05-90ef-b367852ec845 | None        | IPv6      | ::/0      |            | egress    | None                                 | None                 |
    >   | 331368f0-e24f-4f2e-ade5-0bbabd4dc618 | None        | IPv4      | 0.0.0.0/0 |            | ingress   | c76f55b9-df80-4262-a855-26c4111a9a43 | None                 |
    >   | b034be04-e850-4663-9896-9ca760212e5e | None        | IPv4      | 0.0.0.0/0 |            | ingress   | 6f1da941-0dcd-4f72-8f1d-3c00001030aa | None                 |
    >   +--------------------------------------+-------------+-----------+-----------+------------+-----------+--------------------------------------+----------------------+

    #
    # Are we looking in the right place ?
    #
    # A clue ..
    # https://github.com/kubernetes-sigs/cluster-api-provider-openstack/blob/main/docs/book/src/clusteropenstack/configuration.md#restrict-access-to-the-api-server
    #
    #   If you locked out yourself or the CAPO management cluster, you can easily clear the allowed_cidrs field on OpenStack via:
    #   >  openstack loadbalancer listener unset --allowed-cidrs <listener ID>
    #

# -----------------------------------------------------
# Check the loadbalancer listener.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        loadbalancer list

    >   +--------------------------------------+---------------------------------------------------------------------+----------------------------------+--------------+---------------------+------------------+----------+
    >   | id                                   | name                                                                | project_id                       | vip_address  | provisioning_status | operating_status | provider |
    >   +--------------------------------------+---------------------------------------------------------------------+----------------------------------+--------------+---------------------+------------------+----------+
    >   | 7bf0e534-d801-4db0-8124-d49fb6bc99a9 | k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi | e918a13fed2648758175a15fac083569 | 192.168.3.98 | ACTIVE              | ONLINE           | amphora  |
    >   +--------------------------------------+---------------------------------------------------------------------+----------------------------------+--------------+---------------------+------------------+----------+


    openstack \
        --os-cloud "${cloudname:?}" \
        loadbalancer listener list \
            --loadbalancer '7bf0e534-d801-4db0-8124-d49fb6bc99a9'

    >   +--------------------------------------+--------------------------------------+--------------------------------------------------------------------------+----------------------------------+----------+---------------+----------------+
    >   | id                                   | default_pool_id                      | name                                                                     | project_id                       | protocol | protocol_port | admin_state_up |
    >   +--------------------------------------+--------------------------------------+--------------------------------------------------------------------------+----------------------------------+----------+---------------+----------------+
    >   | fb5d5ae8-2b3e-4cc2-a8af-62edd83eeeb7 | 8cd24a29-406d-4f92-a204-4ebcc7919c7e | k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi-6443 | e918a13fed2648758175a15fac083569 | TCP      |          6443 | True           |
    >   +--------------------------------------+--------------------------------------+--------------------------------------------------------------------------+----------------------------------+----------+---------------+----------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        loadbalancer listener show \
            'fb5d5ae8-2b3e-4cc2-a8af-62edd83eeeb7'

    >   +-----------------------------+--------------------------------------------------------------------------+
    >   | Field                       | Value                                                                    |
    >   +-----------------------------+--------------------------------------------------------------------------+
    >   | admin_state_up              | True                                                                     |
    >   | connection_limit            | -1                                                                       |
    >   | created_at                  | 2023-08-14T16:58:29                                                      |
    >   | default_pool_id             | 8cd24a29-406d-4f92-a204-4ebcc7919c7e                                     |
    >   | default_tls_container_ref   | None                                                                     |
    >   | description                 |                                                                          |
    >   | id                          | fb5d5ae8-2b3e-4cc2-a8af-62edd83eeeb7                                     |
    >   | insert_headers              | None                                                                     |
    >   | l7policies                  |                                                                          |
    >   | loadbalancers               | 7bf0e534-d801-4db0-8124-d49fb6bc99a9                                     |
    >   | name                        | k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi-6443 |
    >   | operating_status            | ONLINE                                                                   |
    >   | project_id                  | e918a13fed2648758175a15fac083569                                         |
    >   | protocol                    | TCP                                                                      |
    >   | protocol_port               | 6443                                                                     |
    >   | provisioning_status         | ACTIVE                                                                   |
    >   | sni_container_refs          | []                                                                       |
    >   | timeout_client_data         | 50000                                                                    |
    >   | timeout_member_connect      | 5000                                                                     |
    >   | timeout_member_data         | 50000                                                                    |
    >   | timeout_tcp_inspect         | 0                                                                        |
    >   | updated_at                  | 2023-08-14T18:50:09                                                      |
    >   | client_ca_tls_container_ref | None                                                                     |
    >   | client_authentication       | NONE                                                                     |
    >   | client_crl_container_ref    | None                                                                     |
    >   | allowed_cidrs               | 128.232.226.165/32                                                       |
    >   |                             | 128.232.227.20/32                                                        |
    >   |                             | 192.168.3.0/24                                                           |
    >   |                             | 90.155.51.57/32                                                          |
    >   | tls_ciphers                 | None                                                                     |
    >   | tls_versions                | None                                                                     |
    >   | alpn_protocols              | None                                                                     |
    >   | tags                        |                                                                          |
    >   +-----------------------------+--------------------------------------------------------------------------+

    #
    # Yay .. looks like it worked.
    #

    >   +-----------------------------+--------------------------------------------------------------------------+
    >   | Field                       | Value                                                                    |
    >   +-----------------------------+--------------------------------------------------------------------------+
    >   | ........                    | ........                                                                 |
    >   | allowed_cidrs               | 128.232.226.165/32                                                       |
    >   |                             | 128.232.227.20/32                                                        |
    >   |                             | 192.168.3.0/24                                                           |
    >   |                             | 90.155.51.57/32                                                          |
    >   | ........                    | ........                                                                 |
    >   +-----------------------------+--------------------------------------------------------------------------+

    #
    # So how do we test this ?
    #


# -----------------------------------------------------
# Check access from our client container.
#[root@ansibler]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   HTTP/2 403
    >   audit-id: 1ac64e41-8ee6-47ce-b6d0-ef2b6274ac5a
    >   cache-control: no-cache, private
    >   content-type: application/json
    >   x-content-type-options: nosniff
    >   x-kubernetes-pf-flowschema-uid: 4f343dcf-f463-44e2-99b6-ee46746fab5e
    >   x-kubernetes-pf-prioritylevel-uid: 06219864-b0fc-4741-8468-0eb7a62cd5b3
    >   content-length: 218
    >   date: Tue, 15 Aug 2023 02:13:10 GMT


# -----------------------------------------------------
# -----------------------------------------------------
# Check access from our bootstrap node.
#[user@bootstrap]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   HTTP/2 403
    >   audit-id: 8257dad3-00c2-44eb-ad72-ba9f2abdf87d
    >   cache-control: no-cache, private
    >   content-type: application/json
    >   x-content-type-options: nosniff
    >   x-kubernetes-pf-flowschema-uid: 4f343dcf-f463-44e2-99b6-ee46746fab5e
    >   x-kubernetes-pf-prioritylevel-uid: 06219864-b0fc-4741-8468-0eb7a62cd5b3
    >   content-length: 218
    >   date: Tue, 15 Aug 2023 02:14:02 GMT


# -----------------------------------------------------
# -----------------------------------------------------
# Create a DigitalOcean node to test access.
#[user@desktop]

    >   ....
    >   ....

    ssh root@2a03:b0c0:3:d0::1c29:6001

        curl \
            --head \
            --insecure \
            'https://128.232.226.67:6443/'

    >   curl: (28) Failed to connect to 128.232.226.67 port 6443 after 130365 ms: Couldn't connect to server


# -----------------------------------------------------
# -----------------------------------------------------
# Add the DigitalOcean node to the list of allowed addresses.
#[root@bootstrap]

    cat > /tmp/cluster-access-patch.yml << EOF
spec:
  apiServerLoadBalancer:
    allowedCidrs:
    - 128.232.227.20/32
    - 90.155.51.57/32
    - 164.92.185.112/32
EOF

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        patch OpenStackCluster \
            "${workclustername:?}" \
            --type merge \
            --patch-file '/tmp/cluster-access-patch.yml'

    >   openstackcluster.infrastructure.cluster.x-k8s.io/iris-gaia-blue-20230814-work patched


# -----------------------------------------------------
# -----------------------------------------------------
# Try to access the API from the DigitalOcean node.
#[user@DigitalOcean]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   HTTP/2 403
    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Remove all the allowed addresses.
#[root@bootstrap]

    cat > /tmp/cluster-access-patch.yml << EOF
spec:
  apiServerLoadBalancer:
    allowedCidrs: null
EOF

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        patch OpenStackCluster \
            "${workclustername:?}" \
            --type merge \
            --patch-file '/tmp/cluster-access-patch.yml'

    >   openstackcluster.infrastructure.cluster.x-k8s.io/iris-gaia-blue-20230814-work patched

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "id": "7bf0e534-d801-4db0-8124-d49fb6bc99a9",
    >     "internalIP": "192.168.3.98",
    >     "ip": "128.232.226.67",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi"
    >   }

    #
    # Back to no rules.
    #


# -----------------------------------------------------
# Try to access the API from the DigitalOcean node.
#[user@DigitalOcean]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   HTTP/2 403
    >   ....
    >   ....


# -----------------------------------------------------
# Try to access the API from our client container.
#[root@ansibler]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   HTTP/2 403
    >   ....
    >   ....


# -----------------------------------------------------
# Try to access the API from our bootstrap node.
#[user@bootstrap]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   HTTP/2 403
    >   ....
    >   ....


# -----------------------------------------------------
# Add our client container and bootstrap node.
#[root@bootstrap]

    cat > /tmp/cluster-access-patch.yml << EOF
spec:
  apiServerLoadBalancer:
    allowedCidrs:
    - 128.232.227.20/32
    - 90.155.51.57/32
EOF

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        patch OpenStackCluster \
            "${workclustername:?}" \
            --type merge \
            --patch-file '/tmp/cluster-access-patch.yml'

    >   openstackcluster.infrastructure.cluster.x-k8s.io/iris-gaia-blue-20230814-work patched


# -----------------------------------------------------
# -----------------------------------------------------
# Try to access the API from our client container.
#[root@ansibler]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   HTTP/2 403
    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Try to access the API from our bootstrap node.
#[user@bootstrap]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   HTTP/2 403
    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Try to access the API from the DigitalOcean node.
#[user@DigitalOcean]

    curl \
        --head \
        --insecure \
        'https://128.232.226.67:6443/'

    >   curl: (28) Failed to connect to 128.232.226.67 port 6443 after 131340 ms: Couldn't connect to server


# -----------------------------------------------------
# -----------------------------------------------------
# Create an Ansible task to update the lodabalancer.
#[user@desktop]

    gedit "${AGLAIS_CODE:?}/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml" &

    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Remove all the allowed addresses.
#[root@bootstrap]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "allowedCIDRs": [
    >       "128.232.226.165/32",
    >       "128.232.227.20/32",
    >       "192.168.3.0/24",
    >       "90.155.51.57/32"
    >     ],
    >     "id": "7bf0e534-d801-4db0-8124-d49fb6bc99a9",
    >     "internalIP": "192.168.3.98",
    >     "ip": "128.232.226.67",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi"
    >   }


    cat > /tmp/cluster-access-patch.yml << EOF
spec:
  apiServerLoadBalancer:
    allowedCidrs: null
EOF

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        patch OpenStackCluster \
            "${workclustername:?}" \
            --type merge \
            --patch-file '/tmp/cluster-access-patch.yml'

    >   openstackcluster.infrastructure.cluster.x-k8s.io/iris-gaia-blue-20230814-work patched

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "id": "7bf0e534-d801-4db0-8124-d49fb6bc99a9",
    >     "internalIP": "192.168.3.98",
    >     "ip": "128.232.226.67",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230814-work-kubeapi"
    >   }

    #
    # Back to no rules.
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Try applying the new Ansible task.
#[root@ansibler]

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml'

    >   TASK [Update our loadbalancer] ************************
    >   fatal: [bootstrap]: FAILED! => {
    >       "ansible_facts": {
    >           "discovered_interpreter_python": "/usr/bin/python3"
    >           },
    >       "changed": false,
    >       "msg": "
    >           Failed to import the required Python library (kubernetes) on iris-gaia-blue-20230814-bootstrap-node's Python /usr/bin/python3.
    >           Please read the module documentation and install it in the appropriate location.
    >           If the required library is installed, but Ansible is using the wrong Python interpreter, please consult the documentation on ansible_python_interpreter
    >           "
    >       }


# -----------------------------------------------------
# Install the Ansible Galaxy `kubernetes.core` module.
#[root@ansibler]

    ansible-galaxy collection install kubernetes.core

    >   Starting galaxy collection install process
    >   Process install dependency map
    >   Starting collection install process
    >   Downloading https://galaxy.ansible.com/download/kubernetes-core-2.4.0.tar.gz to /root/.ansible/tmp/ansible-local-2694uy8mav19/tmpg3e7__i1/kubernetes-core-2.4.0-0ytuuson
    >   Installing 'kubernetes.core:2.4.0' to '/root/.ansible/collections/ansible_collections/kubernetes/core'
    >   kubernetes.core:2.4.0 was installed successfully


# -----------------------------------------------------
# Try applying the new Ansible task.
#[root@ansibler]

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml'

    >   TASK [Update our loadbalancer] ************************
    >   fatal: [bootstrap]: FAILED! => {
    >       "ansible_facts": {
    >           "discovered_interpreter_python": "/usr/bin/python3"
    >           },
    >       "changed": false,
    >       "msg": "
    >           Failed to import the required Python library (kubernetes) on iris-gaia-blue-20230814-bootstrap-node's Python /usr/bin/python3.
    >           Please read the module documentation and install it in the appropriate location.
    >           If the required library is installed, but Ansible is using the wrong Python interpreter, please consult the documentation on ansible_python_interpreter
    >           "
    >       }


# -----------------------------------------------------
# Install the Python kubernetes module.
#[root@ansibler]

    pip install kubernetes

    >   ....
    >   ....
    >   Successfully installed
    >       cachetools-5.3.1
    >       certifi-2023.7.22
    >       google-auth-2.22.0
    >       kubernetes-27.2.0
    >       oauthlib-3.2.2
    >       pyasn1-0.5.0
    >       pyasn1-modules-0.3.0
    >       requests-oauthlib-1.3.1
    >       rsa-4.9
    >       websocket-client-1.6.1


# -----------------------------------------------------
# Try applying the new Ansible task.
#[root@ansibler]

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml'

    >   TASK [Update our loadbalancer] ************************
    >   fatal: [bootstrap]: FAILED! => {
    >       "ansible_facts": {
    >           "discovered_interpreter_python": "/usr/bin/python3"
    >           },
    >       "changed": false,
    >       "msg": "
    >           Failed to import the required Python library (kubernetes) on iris-gaia-blue-20230814-bootstrap-node's Python /usr/bin/python3.
    >           Please read the module documentation and install it in the appropriate location.
    >           If the required library is installed, but Ansible is using the wrong Python interpreter, please consult the documentation on ansible_python_interpreter
    >           "
    >       }


# -----------------------------------------------------
# Install the Python kubernetes module on our bootstrap node.
#[root@ansibler]

    ssh bootstrap \
        '
        pip install kubernetes
        '


    >   ....
    >   ....
    >   Successfully installed
    >       cachetools-5.3.1
    >       certifi-2023.7.22
    >       google-auth-2.22.0
    >       kubernetes-27.2.0
    >       oauthlib-3.2.2
    >       pyasn1-0.5.0
    >       pyasn1-modules-0.3.0
    >       requests-oauthlib-1.3.1
    >       rsa-4.9
    >       websocket-client-1.6.1


# -----------------------------------------------------
# Try applying the new Ansible task.
#[root@ansibler]

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml'

    >   ....
    >   ....
    >   TASK [Update our loadbalancer] ************************
    >   An exception occurred during task execution.
    >   To see the full traceback, use -vvv.
    >   The error was:
    >       ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException:
    >           Could not create API client:
    >               Invalid kube-config file.
    >               No configuration found.
    >   fatal: [bootstrap]: FAILED! => {
    >       "ansible_facts": {
    >           "discovered_interpreter_python": "/usr/bin/python3"
    >           },
    >       "changed": false,
    >       "msg": "Could not create API client: Invalid kube-config file. No configuration found."
    >       }


# -----------------------------------------------------
# -----------------------------------------------------
# Fix the Ansible task, adding the kube-config file.
#[user@desktop]

    gedit "${AGLAIS_CODE:?}/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml" &

    +   kubeconfig: "{{ aglais.kubernetes.cluster.kind.conf }}"


# -----------------------------------------------------
# -----------------------------------------------------
# Try applying the new Ansible task.
#[root@ansibler]

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml'

    >   TASK [Update our loadbalancer] ************************
    >   fatal: [bootstrap]: FAILED! => {
    >       "ansible_facts": {
    >           "discovered_interpreter_python": "/usr/bin/python3"
    >           },
    >       "changed": false,
    >       "msg": "Failed to find exact match for v1.OpenStackCluster by [kind, name, singularName, shortNames]"
    >       }


# -----------------------------------------------------
# -----------------------------------------------------
# Fix the Ansible task, adding the resource version.
#[user@desktop]

    gedit "${AGLAIS_CODE:?}/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml" &

        kind: "OpenStackCluster"
    +   version: "infrastructure.cluster.x-k8s.io/v1alpha6"
        name: "{{ aglais.kubernetes.cluster.work.name }}"


# -----------------------------------------------------
# -----------------------------------------------------
# Try applying the new Ansible task.
#[root@ansibler]

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml'

    >   ....
    >   ....
    >   [WARNING]: resource 'kind=OpenStackCluster,name=iris-gaia-blue-20230814-work' was not found but will not be created as 'state' parameter has been set to 'patched'


# -----------------------------------------------------
# -----------------------------------------------------
# Check what just happened.
#[root@ansibler]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            "${workclustername:?}"

    >   NAME                           CLUSTER                        READY   NETWORK                                SUBNET                                 BASTION IP   AGE
    >   iris-gaia-blue-20230814-work   iris-gaia-blue-20230814-work   true    be3043ab-84b7-4d50-a762-3620ab6f9e28   bdfdb7a3-3476-4cca-ae30-946e5144c326                11h


# -----------------------------------------------------
# -----------------------------------------------------
# Tweak the Ansible task, adding the namespace and setting the status to 'present'
#[user@desktop]

    gedit "${AGLAIS_CODE:?}/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml" &

        - name: "Update our loadbalancer"
          kubernetes.core.k8s:
    ~       state: present
            kind: "OpenStackCluster"
    +       api_version: "infrastructure.cluster.x-k8s.io/v1alpha6"
    +       namespace: "default"
            name: "{{ aglais.kubernetes.cluster.work.name }}"
            merge_type: "merge"
            kubeconfig: "{{ aglais.kubernetes.cluster.kind.conf }}"
            definition:
              spec:
                apiServerLoadBalancer:
                  allowedCidrs:
                  - "{{ aglais.openstack.servers.bootstrap.float.external }}/32"
                  - "{{ aglais.builder.ipv4 }}/32"


# -----------------------------------------------------
# -----------------------------------------------------
# Try applying the new Ansible task.
#[root@ansibler]

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml'

    >   ....
    >   ....
    >   TASK [Update our loadbalancer] ************************
    >   changed: [bootstrap]


# -----------------------------------------------------
# -----------------------------------------------------
# Check what just happened.
#[root@ansibler]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   The connection to the server 127.0.0.1:35039 was refused - did you specify the right host or port?

    #
    # OK, we broke it.
    # ... but why did it break the KinD cluster ?
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Delete and deploy everything.
#[root@ansibler]

    /deployments/openstack/bin/delete-all.sh \
        "${cloudname:?}"

    ansible-playbook \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/00-create-all.yml'

    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Modify the Ansible task to use a shell command.
#[user@desktop]

    gedit "${AGLAIS_CODE:?}/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml" &

    +
    +   - name: "Create our patch"
    +     ansible.builtin.template:
    +       src:  "templates/cluster-access-patch.j2"
    +       dest: "/tmp/cluster-access-patch.yml"
    +       mode: 'u=rw,g=rw,o=r'
    +
    +   - name: "Apply our patch"
    +     ansible.builtin.shell: |
    +       kubectl \
    +           --kubeconfig "{{ aglais.kubernetes.cluster.kind.conf }}" \
    +           patch OpenStackCluster \
    +               "{{ aglais.kubernetes.cluster.work.name }}" \
    +               --type merge \
    +               --patch-file '/tmp/cluster-access-patch.yml'
    +

# -----------------------------------------------------
# -----------------------------------------------------
# Check the initial state.
#[root@ansibler]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "id": "61bfb0aa-908e-41e1-82d5-7be1af5d9324",
    >     "internalIP": "192.168.3.140",
    >     "ip": "128.232.226.142",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230815-work-kubeapi"
    >   }


# -----------------------------------------------------
# -----------------------------------------------------
# Try applying the new Ansible task.
#[root@ansibler]

    ansible-playbook \
        -vvv \
        --inventory 'bootstrap,' \
        '/deployments/cluster-api/bootstrap/ansible/26-secure-work-cluster.yml'

    >   ....
    >   ....
    >   TASK [Show the allowed addresses] *********************
    >   ok: [bootstrap] => {
    >       "msg": "Allowed [90.155.51.57, 128.232.226.106]"
    >   }
    >   
    >   TASK [Show the target cluster name] *******************
    >   ok: [bootstrap] => {
    >       "msg": "Target [iris-gaia-blue-20230815-work]"
    >   }
    >   
    >   TASK [Create our patch] *******************************
    >   changed: [bootstrap]
    >   
    >   TASK [Apply our patch] ********************************
    >   changed: [bootstrap]


# -----------------------------------------------------
# -----------------------------------------------------
# Check what just happened.
#[root@ansibler]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "id": "61bfb0aa-908e-41e1-82d5-7be1af5d9324",
    >     "internalIP": "192.168.3.140",
    >     "ip": "128.232.226.142",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230815-work-kubeapi"
    >   }


# -----------------------------------------------------
# Check that the spec was changed.
#[root@ansibler]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.spec'

    >   {
    >     "allowAllInClusterTraffic": true,
    >     "apiServerLoadBalancer": {
    >       "allowedCidrs": [
    >         "128.232.226.106/32",
    >         "90.155.51.57/32"
    >       ],
    >       "enabled": true
    >     },
    >     "apiServerPort": 6443,
    >     "cloudName": "openstack",
    >     "controlPlaneEndpoint": {
    >       "host": "128.232.226.142",
    >       "port": 6443
    >     },
    >     "controlPlaneOmitAvailabilityZone": true,
    >     "disableAPIServerFloatingIP": false,
    >     "dnsNameservers": [
    >       "131.111.8.42"
    >     ],
    >     "externalNetworkId": "57add367-d205-4030-a929-d75617a7c63e",
    >     "identityRef": {
    >       "kind": "Secret",
    >       "name": "iris-gaia-blue-20230815-work-cloud-credentials"
    >     },
    >     "managedSecurityGroups": true,
    >     "network": {},
    >     "nodeCidr": "192.168.3.0/24",
    >     "subnet": {}
    >   }

    #
    # The patch has been applied to the spec, but the change
    # hasn't been applied to the loadbalancer state.
    #


# -----------------------------------------------------
# Apply the patch ourselves.
#[root@bootstrap]

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "id": "61bfb0aa-908e-41e1-82d5-7be1af5d9324",
    >     "internalIP": "192.168.3.140",
    >     "ip": "128.232.226.142",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230815-work-kubeapi"
    >   }


    cat > /tmp/cluster-access-patch.yml << EOF
spec:
  apiServerLoadBalancer:
    allowedCidrs:
    - 128.232.227.20
    - 90.155.51.57
EOF

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        patch OpenStackCluster \
            "${workclustername:?}" \
            --type merge \
            --patch-file '/tmp/cluster-access-patch.yml'

    >   openstackcluster.infrastructure.cluster.x-k8s.io/iris-gaia-blue-20230815-work patched

    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.spec.apiServerLoadBalancer'

    >   {
    >     "allowedCidrs": [
    >       "128.232.227.20",
    >       "90.155.51.57"
    >     ],
    >     "enabled": true
    >   }


    kubectl \
        --kubeconfig "${kindclusterconf:?}" \
        get OpenStackCluster \
            --output json \
            "${workclustername:?}" \
    | jq '.status.network.apiServerLoadBalancer'

    >   {
    >     "allowedCIDRs": [
    >       "128.232.226.54/32",
    >       "128.232.227.20/32",
    >       "192.168.3.0/24",
    >       "90.155.51.57/32"
    >     ],
    >     "id": "61bfb0aa-908e-41e1-82d5-7be1af5d9324",
    >     "internalIP": "192.168.3.140",
    >     "ip": "128.232.226.142",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-blue-20230815-work-kubeapi"
    >   }


