#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Try to find out more about the limits on concurrent users.
        Based on a clean deployment using 20220613-01-blue-deploy.txt.

    Result:

        Work in progress ...

        TODO move from quick to complex test sets
        TODO move from 4 to 8 concurrent users


# -----------------------------------------------------
# Create our benchmark script.
#[root@ansibler]

    cat > /tmp/run-benchmark.py << 'EOF'
#!/bin/python3
import sys
from aglais_benchmark import AglaisBenchmarker

try:

    opts = [opt for opt in sys.argv[1:] if opt.startswith("-")]
    args = [arg for arg in sys.argv[1:] if not arg.startswith("-")]

    endpoint = args[0]
    testconfig = args[1]
    userlist = args[2]
    usercount = int(args[3])
    delaystart = int(args[4])
    delaynotebook = int(args[5])

except IndexError:

    raise SystemExit(f"Usage: {sys.argv[0]} <Zepelin endpoint> <test config> <list of users> <number of users>")

print(
"""
{{
\"config\": {{
    \"endpoint\":   \"{}\",
    \"testconfig\": \"{}\",
    \"userlist\":   \"{}\",
    \"usercount\":  \"{}\",
    \"delaystart\":  \"{}\",
    \"delaynotebook\":  \"{}\"
    }},
\"output\": {{
""".format(
        endpoint,
        testconfig,
        userlist,
        usercount,
        delaystart,
        delaynotebook
        )
    )

print(
    "---start---"
    )
AglaisBenchmarker(
    testconfig,
    userlist,
    "/tmp/",
    endpoint
    ).run(
        concurrent=True,
        users=usercount,
        delay_start=delaystart,
        delay_notebook=delaynotebook
        )
print(
    "---end---"
    )
print(
"""
    }
}
"""
    )
EOF

    chmod 'a+x' /tmp/run-benchmark.py


# -----------------------------------------------------
# Create our filter function.
# https://github.com/wfau/aglais/issues/602
#[root@ansibler]

    filter-results()
        {
        local testname=${1:?'testname required'}
        sed "
            /^--*start--*/,/^--*end--*/ {
                /^--*start/,/^--* Test Result/ {
                    /Test Result/ ! {
                        d
                        }
                    /Test Result/ {
                        s/^.*Test Result: \[\(.*\)\].*$/'testcode': '\1',/
                        a \"threads\":
                        }
                    }
                s/\"/'/g
                s/'\(-\{0,1\}[0-9.]\{1,\}\)'/\1/g
                s/:[[:space:]]*\([a-zA-Z]\{1,\}\)\([,}]\)/:'\1'\2/g
                s/:[[:space:]]*\([,}]\),/: ''\1/g
                s/'/\"/g
                }
            /^--*end--*/ {
                d
                }
            " \
            "/tmp/results/${testname:?}.txt" \
        | tee "/tmp/results/${testname:?}.json" \
        | jq  '
              .output.threads[] | keys as $x | [ $x[] as $y | {name: $y, value: .[$y].result, time: .[$y].time.elapsed , start: .[$y].time.start, finish: .[$y].time.finish } ]
              '
        }


# -----------------------------------------------------
# Create our test-loop function.
#[root@ansibler]

    test-loop()
        {
        local loopcount=${1:?'loopcount required'}
        local usercount=${2:?'usercount required'}

        rm -f /tmp/results/*

        echo "["

        local comma=''
        for i in $(seq 0 $((loopcount - 1)))
        do
            echo "${comma}" ; comma=','

            testname="multi-user-$(printf "%02d" ${usercount})-$(printf "%02d" ${i})"

cat << EOF
    {
    "iteration": ${i},
    "testname": "${testname}",
    "threads":
EOF

            /tmp/run-benchmark.py \
                "${endpoint:?}" \
                "${testconfig:?}" \
                "${testusers:?}" \
                "${usercount:?}" \
                "${delaystart:?}" \
                "${delaynotebook:?}" \
            > "/tmp/results/${testname:?}.txt"

            filter-results "${testname:?}"

            echo "}"

        done

        echo "]"

        }


# -----------------------------------------------------
# Test with 1 user, 1 loop.
#[root@ansibler]

    test-loop 1 1 \
    | tee /tmp/test-loop.json

    jq '.' /tmp/test-loop.json

--START--
[
  {
    "iteration": 0,
    "testname": "multi-user-01-00",
    "threads": [
      {
        "name": "GaiaDMPSetup",
        "value": "PASS",
        "time": 36.04,
        "start": "2022-06-14T12:02:17.073449",
        "finish": "2022-06-14T12:02:53.115954"
      },
      {
        "name": "Library_Validation.json",
        "value": "PASS",
        "time": 10.14,
        "start": "2022-06-14T12:04:19.243331",
        "finish": "2022-06-14T12:04:29.385640"
      },
      {
        "name": "Mean_proper_motions_over_the_sky",
        "value": "PASS",
        "time": 65.06,
        "start": "2022-06-14T12:02:54.117116",
        "finish": "2022-06-14T12:03:59.174176"
      },
      {
        "name": "Source_counts_over_the_sky.json",
        "value": "PASS",
        "time": 18.07,
        "start": "2022-06-14T12:04:00.175377",
        "finish": "2022-06-14T12:04:18.241466"
      }
    ]
  }
]
--END--


    grep 'Result:' /tmp/results/*.txt

--START--
------------ Test Result: [PASS] ------------
--END--


# -----------------------------------------------------
# Test with 2 users, 1 loop.
#[root@ansibler]

    test-loop 2 1 \
    | tee /tmp/test-loop.json

    jq '.' /tmp/test-loop.json


--START--
[

    {
    "iteration": 0,
    "testname": "multi-user-01-00",
    "threads":
[
  {
    "name": "GaiaDMPSetup",
    "value": "PASS",
    "time": 36.63,
    "start": "2022-06-14T12:06:46.929067",
    "finish": "2022-06-14T12:07:23.560850"
  },
  {
    "name": "Library_Validation.json",
    "value": "PASS",
    "time": 9.68,
    "start": "2022-06-14T12:08:53.924361",
    "finish": "2022-06-14T12:09:03.607976"
  },
  {
    "name": "Mean_proper_motions_over_the_sky",
    "value": "PASS",
    "time": 65.66,
    "start": "2022-06-14T12:07:24.561381",
    "finish": "2022-06-14T12:08:30.217678"
  },
  {
    "name": "Source_counts_over_the_sky.json",
    "value": "PASS",
    "time": 21.70,
    "start": "2022-06-14T12:08:31.218326",
    "finish": "2022-06-14T12:08:52.923187"
  }
]
}
,
    {
    "iteration": 1,
    "testname": "multi-user-01-01",
    "threads":
parse error: Invalid numeric literal at line 15, column 638
}
]
parse error: Unmatched '}' at line 43, column 1
--END--


    grep 'Result:' /tmp/results/*.txt

--START--
/tmp/results/multi-user-01-00.txt:------------ Test Result: [PASS] ------------
/tmp/results/multi-user-01-01.txt:------------ Test Result: [FAIL] ------------
--END--

    #
    # Failing the second test is back.
    # Go figure.
    #


# -----------------------------------------------------
# Test with 3 users, 1 loop.
#[root@ansibler]

    test-loop 3 1 \
    | tee /tmp/test-loop.json

    jq '.' /tmp/test-loop.json

--START--
[

    {
    "iteration": 0,
    "testname": "multi-user-01-00",
    "threads":
[
  {
    "name": "GaiaDMPSetup",
    "value": "PASS",
    "time": 34.87,
    "start": "2022-06-14T12:16:20.059583",
    "finish": "2022-06-14T12:16:54.933593"
  },
  {
    "name": "Library_Validation.json",
    "value": "PASS",
    "time": 10.20,
    "start": "2022-06-14T12:18:31.505472",
    "finish": "2022-06-14T12:18:41.706929"
  },
  {
    "name": "Mean_proper_motions_over_the_sky",
    "value": "PASS",
    "time": 72.21,
    "start": "2022-06-14T12:16:55.934349",
    "finish": "2022-06-14T12:18:08.149132"
  },
  {
    "name": "Source_counts_over_the_sky.json",
    "value": "PASS",
    "time": 21.35,
    "start": "2022-06-14T12:18:09.150417",
    "finish": "2022-06-14T12:18:30.503974"
  }
]
}
,
    {
    "iteration": 1,
    "testname": "multi-user-01-01",
    "threads":
parse error: Invalid numeric literal at line 15, column 7462
}
,
    {
    "iteration": 2,
    "testname": "multi-user-01-02",
    "threads":
parse error: Invalid numeric literal at line 15, column 638
}
]
parse error: Unmatched '}' at line 43, column 1
--END--



    grep 'Result:' /tmp/results/*.txt

--START--
/tmp/results/multi-user-01-00.txt:------------ Test Result: [PASS] ------------
/tmp/results/multi-user-01-01.txt:------------ Test Result: [ERROR] ------------
/tmp/results/multi-user-01-02.txt:------------ Test Result: [FAIL] ------------
--END--

    #
    # What is the difference between an ERROR and a FAIL ?
    #

    vi /tmp/results/multi-user-01-01.txt


--START--
....
Test started [Multi User]
Test completed! (83.97 seconds)
------------ Test Result: [ERROR] ------------
    [
        {
        'GaiaDMPSetup': {
            'result': 'ERROR',
            'outputs': {
                'valid': True
                },
            'time': {
                'result': 'FAST',
                'elapsed': '33.45',
                'expected': '45.00',
                'percent': '-25.67',
                'start': '2022-06-14T12:18:44.237768',
                'finish': '2022-06-14T12:19:17.685659'
                },
            'logs': '
                org.apache.zeppelin.interpreter.InterpreterException: java.io.IOException:
                    Interpreter Process creation is time out in 30 seconds
                    You can increase timeout threshold via setting zeppelin.interpreter.connect.timeout of this interpreter.
                    Interpreter download command:
                        /etc/alternatives/jre/bin/java
                            -Dfile.encoding=UTF-8
                            -Dlog4j.configuration=file:///home/fedora/zeppelin/conf/log4j.properties
                            -Dlog4j.configurationFile=file:///home/fedora/zeppelin/conf/log4j2.properties
                            -Dzeppelin.log.file=/home/fedora/zeppelin/logs/zeppelin-interpreter-spark-Carclop-Carclop-fedora-iris-gaia-blue-20220613-zeppelin.log
                            -cp :/home/fedora/zeppelin/interpreter/spark/*
                                :/home/fedora/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.0.jar
                                :/home/fedora/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar
                                :/opt/hadoop/etc/hadoop org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader
                            10.10.2.210 35643
                            spark
                            /home/fedora/zeppelin/local-repo/spark

                    [INFO] Interpreter launch command:
                        /opt/spark/bin/spark-submit
                            --class org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer
                            --driver-class-path
                                :/home/fedora/zeppelin/local-repo/spark/*
                                :/home/fedora/zeppelin/interpreter/spark/*
                                :/home/fedora/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.0.jar
                                :/home/fedora/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar
                                :/opt/hadoop/etc/hadoop
                            --driver-java-options
                                -Dfile.encoding=UTF-8
                                -Dlog4j.configuration=file:///home/fedora/zeppelin/conf/log4j.properties
                                -Dlog4j.configurationFile=file:///home/fedora/zeppelin/conf/log4j2.properties
                                -Dzeppelin.log.file=/home/fedora/zeppelin/logs/zeppelin-interpreter-spark-Carclop-Carclop-fedora-iris-gaia-blue-20220613-zeppelin.log
                            --proxy-user Carclop
                            --conf spark.yarn.dist.archives=/opt/spark/R/lib/sparkr.zip#sparkr
                            --conf spark.submit.deployMode=client
                            --conf spark.webui.yarn.useProxy=false
                            --conf spark.yarn.isPython=true
                            --conf spark.app.name=spark-Carclop
                            --conf spark.master=yarn
                            /home/fedora/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar
                                10.10.2.210 35643
                                spark-Carclop :

                    SLF4J: Class path contains multiple SLF4J bindings.
                    SLF4J: Found binding in [jar:file:/home/fedora/zeppelin-0.10.0-bin-all/interpreter/spark/spark-interpreter-0.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
                    SLF4J: Found binding in [jar:file:/opt/spark-3.1.2-bin-hadoop3.2/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
                    SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
                    SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

                        at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:129)
                        at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getFormType(RemoteInterpreter.java:271)
                        at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:440)
                        at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:71)
                        at org.apache.zeppelin.scheduler.Job.run(Job.java:172)
                        at org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)
                        at org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:182)
                        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
                        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
                        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
                        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
                        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
                        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
                        at java.lang.Thread.run(Thread.java:748)

                    Caused by: java.io.IOException: Interpreter Process creation is time out in 30 seconds
                        You can increase timeout threshold via setting zeppelin.interpreter.connect.timeout of this interpreter.
                        Interpreter download command: ....
                        [INFO] Interpreter launch command: ....

                    SLF4J: Class path contains multiple SLF4J bindings.
                    SLF4J: Found binding in [jar:file:/home/fedora/zeppelin-0.10.0-bin-all/interpreter/spark/spark-interpreter-0.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
                    SLF4J: Found binding in [jar:file:/opt/spark-3.1.2-bin-hadoop3.2/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
                    SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
                    SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

                        at org.apache.zeppelin.interpreter.remote.ExecRemoteInterpreterProcess.start(ExecRemoteInterpreterProcess.java:93)
                        at org.apache.zeppelin.interpreter.ManagedInterpreterGroup.getOrCreateInterpreterProcess(ManagedInterpreterGroup.java:68)
                        at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getOrCreateInterpreterProcess(RemoteInterpreter.java:104)
                        at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.internal_create(RemoteInterpreter.java:154)
                        at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:126)
                        ... 13 more
                '
            },
        'Mean_proper_motions_over_the_sky': {
            'result': 'ERROR',
            'outputs': {
                'valid': True
                },
            'time': {
                'result': 'FAST',
                'elapsed': '29.76',
                'expected': '55.00',
                'percent': '-45.89',
                'start': '2022-06-14T12:19:18.687135',
                'finish': '2022-06-14T12:19:48.447845'
                },
            'logs': '
                Fail to execute line 13: df = spark.sql(query).cache()
                ....
                pyspark.sql.utils.AnalysisException: Table or view not found: gaia_source; line 1 pos 121;
                \'Aggregate [\'hpx_id], [\'floor((\'source_id / 140737488355328)) AS hpx_id#0, count(1) AS n#1L, \'AVG(\'pmra) AS avg_pmra#2, \'AVG(\'pmdec) AS avg_pmdec#3]
                +- \'UnresolvedRelation [gaia_source], [], false
                '
            },
        'Source_counts_over_the_sky.json': {
            'result': 'ERROR',
            'outputs': {
                'valid': True
                },
            'time': {
                'result': 'FAST',
                'elapsed': '5.74',
                'expected': '22.00',
                'percent': '-73.90',
                'start': '2022-06-14T12:19:49.448736',
                'finish': '2022-06-14T12:19:55.190901'
                },
            'logs': '
                Fail to execute line 21: df = spark.sql("SELECT FLOOR(source_id / %d"%(divisor) + ") AS hpx_id, COUNT(*) AS n FROM gaia_source GROUP BY hpx_id")
                ....
                pyspark.sql.utils.AnalysisException: Table or view not found: gaia_source; line 1 pos 72;
                \'Aggregate [\'hpx_id], [\'FLOOR((\'source_id / 140737488355328)) AS hpx_id#5, count(1) AS n#6L]
                +- \'UnresolvedRelation [gaia_source], [], false
                '
            },
        'Library_Validation.json': {
            'result': 'PASS',
            'outputs': {
                'valid': True
                },
            'time': {
                'result': 'FAST',
                'elapsed': '10.99',
                'expected': '60.00',
                'percent': '-81.68',
                'start': '2022-06-14T12:19:56.191334',
                'finish': '2022-06-14T12:20:07.180597'
                },
            'logs': ''
            }
        }
    ]
....
--END--

    #
    # I'm guessing that GaiaDMPSetup ran first, got half way through creating the schema and failed.
    # This left the top level schema partially defined, so the test in the subsequent notebooks skipped the schema creation.
    #


    vi /tmp/results/multi-user-01-02.txt


--START--
....
Test started [Multi User]
Test completed! (56.67 seconds)
------------ Test Result: [FAIL] ------------
    [
        {
        'GaiaDMPSetup': {
            'result': 'FAIL',
            'outputs': {
                'valid': True
                },
            'time': {
                'result': 'FAST',
                'elapsed': '4.61',
                'expected': '45.00',
                'percent': '-89.76',
                'start': '2022-06-14T12:20:08.716961',
                'finish': '2022-06-14T12:20:13.325401'
                },
            'logs': ''
            },
        'Mean_proper_motions_over_the_sky': {
            'result': 'ERROR',
            'outputs': {
                'valid': True
                },
            'time': {
                'result': 'FAST',
                'elapsed': '30.62',
                'expected': '55.00',
                'percent': '-44.33',
                'start': '2022-06-14T12:20:14.326399',
                'finish': '2022-06-14T12:20:44.947081'
                },
            'logs': '
                Fail to execute line 13: df = spark.sql(query).cache()
                ....
                pyspark.sql.utils.AnalysisException: Table or view not found: gaia_source; line 1 pos 121;
                \'Aggregate [\'hpx_id], [\'floor((\'source_id / 140737488355328)) AS hpx_id#0, count(1) AS n#1L, \'AVG(\'pmra) AS avg_pmra#2, \'AVG(\'pmdec) AS avg_pmdec#3]
                +- \'UnresolvedRelation [gaia_source], [], false
                '
            },
        'Source_counts_over_the_sky.json': {
            'result': 'ERROR',
            'outputs': {
                'valid': True
                },
            'time': {
                'result': 'FAST',
                'elapsed': '5.66',
                'expected': '22.00',
                'percent': '-74.25',
                'start': '2022-06-14T12:20:45.948445',
                'finish': '2022-06-14T12:20:51.613161'
                },
            'logs': '
                Fail to execute line 21: df = spark.sql("SELECT FLOOR(source_id / %d"%(divisor) + ") AS hpx_id, COUNT(*) AS n FROM gaia_source GROUP BY hpx_id")
                ....
                pyspark.sql.utils.AnalysisException: Table or view not found: gaia_source; line 1 pos 72;
                \'Aggregate [\'hpx_id], [\'FLOOR((\'source_id / 140737488355328)) AS hpx_id#5, count(1) AS n#6L]
                +- \'UnresolvedRelation [gaia_source], [], false
                '
            },
        'Library_Validation.json': {
            'result': 'PASS',
            'outputs': {
                'valid': True
                },
            'time': {
                'result': 'FAST',
                'elapsed': '11.76',
                'expected': '60.00',
                'percent': '-80.41',
                'start': '2022-06-14T12:20:52.614339',
                'finish': '2022-06-14T12:21:04.370259'
                },
            'logs': ''
            }
        }
    ]
....
--END--

    #
    # In this one, GaiaDMPSetup failed (no details).
    # This left the top level schema partially defined, so the test in the subsequent notebooks skipped the schema creation.
    #


# -----------------------------------------------------
# Test again with 3 users, 1 loop.
#[root@ansibler]

    test-loop 3 1 \
    | tee /tmp/test-loop.json

    jq '.' /tmp/test-loop.json

    grep 'Result:' /tmp/results/*.txt

--START--
/tmp/results/multi-user-01-00.txt:------------ Test Result: [PASS] ------------
/tmp/results/multi-user-01-01.txt:------------ Test Result: [ERROR] ------------
/tmp/results/multi-user-01-02.txt:------------ Test Result: [ERROR] ------------
--END--

    #
    # Slightly different results.
    # One pass and two errors ..
    #


# -----------------------------------------------------
# Test again with 3 users, 1 loop.
#[root@ansibler]

    test-loop 3 1 \
    | tee /tmp/test-loop.json

    jq '.' /tmp/test-loop.json

    grep 'Result:' /tmp/results/*.txt

--START--
/tmp/results/multi-user-01-00.txt:------------ Test Result: [PASS] ------------
/tmp/results/multi-user-01-01.txt:------------ Test Result: [ERROR] ------------
/tmp/results/multi-user-01-02.txt:------------ Test Result: [FAIL] ------------
--END--

    #
    # Slightly different results.
    # A pass an error and a fail ..
    #

    #
    # A guess ... this started after I had killed a test run using Ctrl-C.
    # Perhaps it has left a mis-configured interpreter active ?
    # See what we can find out via the REST API.
    #


# -----------------------------------------------------
# Get the user login details.
#[root@ansibler]

    less /tmp/results/multi-user-01-01.txt

--START--
{
"config": {
    "endpoint":   "http://zeppelin:8080",
    "testconfig": "/deployments/zeppelin/test/config/quick.json",
    "userlist":   "/tmp/testusers-02.json",
    "usercount":  "1",
    "delaystart":  "1",
    "delaynotebook":  "1"
    },
....
....
--END--


    jq '.users[].shirouser | {name, pass}' /tmp/testusers-02.json

--START--
{
  "name": "Hamar",
  "pass": "bu2hohmohthiesuNg1deiy5IeshaeD"
}
{
  "name": "Carclop",
  "pass": "vae4thae4kae9phohb8eefohBaf4Ee"
}
{
  "name": "Halda",
  "pass": "ohcho9oechai1caiQuieNgeey2ush7"
}
{
  "name": "Jaden",
  "pass": "oMeivie5uingo6kai1eisaiK2ciawo"
}
{
  "name": "Mavaca",
  "pass": "xa9Dohhei8aihahkauMaxah8Ahjiey"
}
{
  "name": "Franilley",
  "pass": "eiz4ik3meen4queeyei4Eedaec1ahv"
}
{
  "name": "Masonania",
  "pass": "booGee2ohthae4Chiingu8ziu5eech"
}
{
  "name": "Webbbron",
  "pass": "ahchohk1neiTah1eiyaiwaekohwaiN"
}
{
  "name": "Granwaler",
  "pass": "Su1ie7akaethae6eic0ien5wiChaeC"
}
--END--


# -----------------------------------------------------
# Select the username and password for the second test user.
#[root@ansibler]

    # Note - JSON array is zero indexed, but AglaisBenchmarker skips the first entry.
    # So use [2] to get the second test user.

    jq '.users[2].shirouser | {name, pass}' /tmp/testusers-02.json

--START--
{
  "name": "Halda",
  "pass": "ohcho9oechai1caiQuieNgeey2ush7"
}
--END--


    testername=$(
        jq -r '.users[2].shirouser.name' /tmp/testusers-02.json
        )
    testerpass=$(
        jq -r '.users[2].shirouser.pass' /tmp/testusers-02.json
        )


# -----------------------------------------------------
# Login to Zeppelin as the test user.
#[root@ansibler]

    source '/deployments/zeppelin/bin/zeppelin-rest-tools.sh'

    zeppelinurl='http://zeppelin:8080'
    zepcookies=/tmp/${testername:?}.cookies

    zeplogin "${testername:?}" "${testerpass:?}" \
    | jq '.'

--START--
{
  "status": "OK",
  "message": "",
  "body": {
    "principal": "Halda",
    "ticket": "5d168ff0-a9cd-48e9-9b04-064219d8f4a9",
    "roles": "[\"user\"]"
  }
}
--END--


# -----------------------------------------------------
# List the registered interpreters.
#[root@ansibler]

    curl \
        --silent \
        --cookie "${zepcookies:?}" \
        "${zeppelinurl:?}/api/interpreter" \
    | tee /tmp/interpreter-list.json \
    | jq '.'

--START--
{
  "status": "OK",
  "message": "",
  "body": {
    "python": {
      "id": "python",
      "name": "python",
      "group": "python",
      "properties": {
        ....
        },
      "status": "READY",
      "interpreterGroup": [
        ....
        ],
      "dependencies": [],
      "option": {
        "remote": true,
        "port": -1,
        "isExistingProcess": false,
        "setPermission": false,
        "isUserImpersonate": false
      }
    },
    "spark": {
      "id": "spark",
      "name": "spark",
      "group": "spark",
      "properties": {
        ....
        },
      "status": "READY",
      "interpreterGroup": [
        ....
        ],
      "dependencies": [],
      "option": {
        "remote": true,
        "port": -1,
        "isExistingProcess": false,
        "setPermission": false,
        "isUserImpersonate": false
      }
    },
    "sh": {
      "id": "sh",
      "name": "sh",
      "group": "sh",
      "properties": {
        ....
        },
      "status": "READY",
      "interpreterGroup": [
        ....
        ],
      "dependencies": [],
      "option": {
        "remote": true,
        "port": -1,
        "isExistingProcess": false,
        "setPermission": false,
        "isUserImpersonate": false
      }
    },
    "md": {
      "id": "md",
      "name": "md",
      "group": "md",
      "properties": {
        ....
        },
      "status": "READY",
      "interpreterGroup": [
        ....
        ],
      "dependencies": [],
      "option": {
        "remote": true,
        "port": -1,
        "isExistingProcess": false,
        "setPermission": false,
        "isUserImpersonate": false
      }
    }
  }
}
--END--

    #
    # These interpreters all have 'isUserImpersonate' set to 'false'.
    # Should they ?
    #

    #
    # According to the Zeppelin documentation, restarting an interpreter is done on a per notebook basis.
    # https://zeppelin.apache.org/docs/0.10.0/usage/rest_api/interpreter.html#restart-an-interpreter

    PUT
    ${zeppelinurl:?}/api/interpreter/setting/restart/[interpreter ID]

        {
        "noteId": "2AVQJVC8N"
        }

    #
    # .. but if the tests deleted the notebooks after each test run,
    # then we won't have an interpreter attached to a notebook.
    #
    # Is the interpreter per user account or per notebook ?
    # Interpreter settings page says:
    # http://zeppelin:8080/#/interpreter
    #
    # spark:
    #   The interpreter will be instantiated [per user] in [isolated] process.
    #
    # Checked the UI, we do have one notebook in /tmp.
    # name  : 4XM670LBGE.json
    # ident : 2H6GREYK3
    #


Run the test to confirm errors
Restart the interpreter
Run the test to confirm errors

# -----------------------------------------------------
# Test baseline with 3 users, 1 loop.
#[root@ansibler]

    test-loop 3 1 \
    | tee /tmp/test-loop.json

    jq '.' /tmp/test-loop.json

    grep 'Result:' /tmp/results/*.txt

