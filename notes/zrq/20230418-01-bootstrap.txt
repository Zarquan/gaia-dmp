#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2023, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Initial bootstrap K8s cluster from nothing.

    Result:

        Work in progress ...

# -----------------------------------------------------
# Check which platform is live.
#[user@desktop]

    ssh fedora@live.gaia-dmp.uk \
        '
        date
        hostname
        '

    >   Tue 18 Apr 03:16:17 UTC 2023
    >   iris-gaia-green-20230308-zeppelin


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    #
    # Live is green, selecting red for the deployment.
    #

    source "${HOME:?}/aglais.env"

    agcolour=red

    clientname=ansibler-${agcolour}
    cloudname=iris-gaia-${agcolour}

    podman run \
        --rm \
        --tty \
        --interactive \
        --name     "${clientname:?}" \
        --hostname "${clientname:?}" \
        --env "cloudname=${cloudname:?}" \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK:?}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.07.25 \
        bash

    >   ....
    >   ....


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

    >   real    2m10.041s
    >   user    0m59.945s
    >   sys     0m6.730s

    >   real    3m1.384s
    >   user    1m19.402s
    >   sys     0m8.767s


# -----------------------------------------------------
# Add YAML editor role to our client container.
# TODO Add this to the Ansible client.
# https://github.com/wfau/atolmis/issues/30
#
#[root@ansibler]

    ansible-galaxy install kwoodson.yedit

    >   Starting galaxy role install process
    >   - downloading role 'yedit', owned by kwoodson
    >   - downloading role from https://github.com/kwoodson/ansible-role-yedit/archive/master.tar.gz
    >   - extracting kwoodson.yedit to /root/.ansible/roles/kwoodson.yedit
    >   - kwoodson.yedit (master) was installed successfully


# -----------------------------------------------------
# Create our deployment settings.
#[root@ansibler]

    deployname=${cloudname:?}-$(date '+%Y%m%d')
    deploydate=$(date '+%Y%m%dT%H%M%S')

    statusyml='/opt/aglais/aglais-status.yml'
    if [ ! -e "$(dirname ${statusyml})" ]
    then
        mkdir "$(dirname ${statusyml})"
    fi
    rm -f "${statusyml}"
    touch "${statusyml}"

    yq eval \
        --inplace \
        "
        .aglais.deployment.type = \"cluster-api\"   |
        .aglais.deployment.name = \"${deployname}\" |
        .aglais.deployment.date = \"${deploydate}\" |
        .aglais.openstack.cloud.name = \"${cloudname}\"
        " "${statusyml}"


    cat /opt/aglais/aglais-status.yml

    >   aglais:
    >     deployment:
    >       type: cluster-api
    >       name: iris-gaia-red-20230418
    >       date: 20230418T050727
    >     openstack:
    >       cloud:
    >         name: iris-gaia-red

    >   aglais:
    >     deployment:
    >       type: cluster-api
    >       name: iris-gaia-red-admin-20230418
    >       date: 20230418T124218
    >     openstack:
    >       cloud:
    >         name: iris-gaia-red-admin


# -----------------------------------------------------
# Create our bootstrap components.
#[root@ansibler]

    inventory=/deployments/cluster-api/bootstrap/ansible/config/inventory.yml

    ansible-playbook \
        --inventory "${inventory:?}" \
        '/deployments/cluster-api/bootstrap/ansible/01-create-keypair.yml'

    ansible-playbook \
        --inventory "${inventory:?}" \
        '/deployments/cluster-api/bootstrap/ansible/02-create-network.yml'

    ansible-playbook \
        --inventory "${inventory:?}" \
        '/deployments/cluster-api/bootstrap/ansible/03-create-bootstrap.yml'

    ansible-playbook \
        --inventory "${inventory:?}" \
        '/deployments/cluster-api/bootstrap/ansible/04-local-config.yml'

    >   ....
    >   ....
    >   PLAY RECAP ****************************************************************************************************************************
    >   localhost                  : ok=2    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   ....
    >   ....
    >   PLAY RECAP ****************************************************************************************************************************
    >   localhost                  : ok=4    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   ....
    >   ....
    >   PLAY RECAP ****************************************************************************************************************************
    >   localhost                  : ok=7    changed=6    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   ....
    >   ....
    >   PLAY RECAP ****************************************************************************************************************************
    >   localhost                  : ok=4    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


# -----------------------------------------------------
# Check our local config.
#[root@ansibler]

    cat /opt/aglais/aglais-status.yml

    >   aglais:
    >     deployment:
    >       date: 20230418T050727
    >       name: iris-gaia-red-20230418
    >       type: cluster-api
    >     openstack:
    >       cloud:
    >         name: iris-gaia-red
    >       keypairs:
    >         team:
    >           fingerprint: 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16
    >           id: iris-gaia-red-20230418-keypair
    >           name: iris-gaia-red-20230418-keypair
    >       networks:
    >         internal:
    >           network:
    >             id: 87b6d33a-f724-4010-a041-ee9e70443c0b
    >             name: iris-gaia-red-20230418-internal-network
    >           router:
    >             id: d77c986f-39fa-4a58-b538-3db0be244102
    >             name: iris-gaia-red-20230418-internal-router
    >           subnet:
    >             cidr: 10.10.0.0/16
    >             id: 3942325b-126d-41cc-93e9-d2b12dd0c5d7
    >             name: iris-gaia-red-20230418-internal-subnet
    >       servers:
    >         bootstrap:
    >           float:
    >             external: 128.232.226.91
    >             id: 7161d34f-7a5f-453f-aa6b-0c455a3fecb0
    >             internal: 10.10.2.145
    >           server:
    >             address:
    >               ipv4: 10.10.2.145
    >             flavor:
    >               name: gaia.vm.cclake.2vcpu
    >             hostname: bootstrap
    >             id: 9f1e3821-d18b-4fbf-879a-b6cb5c0257c0
    >             image:
    >               id: e5c23082-cc34-4213-ad31-ff4684657691
    >               name: Fedora-34.1.2
    >             name: iris-gaia-red-20230418-bootstrap


# -----------------------------------------------------
# SSH test.
#[root@ansibler]

    ssh bootstrap \
        '
        date
        hostname
        '

    >   Tue Apr 18 05:09:34 UTC 2023
    >   iris-gaia-red-20230418-bootstrap


# -----------------------------------------------------
# Transfer a copy of the config
#[root@ansibler]

    scp /opt/aglais/aglais-status.yml \
        bootstrap:/tmp/aglais-status.yml

    ssh bootstrap \
        '
        sudo mkdir -p /opt/aglais
        sudo mv /tmp/aglais-status.yml \
            /opt/aglais
        '

    >   aglais-status.yml           100% 1280    68.7KB/s   00:00


# -----------------------------------------------------
# -----------------------------------------------------
# Login to the bootstrap node as root.
#[user@desktop]

    podman exec \
        -it \
        ansibler-red \
            bash

        ssh bootstrap

            sudo su -

    #
    # We could prefix everything with sudo, but it gets very boring.
    #

# -----------------------------------------------------
# Install Docker.
# https://docs.docker.com/engine/install/fedora/#install-using-the-repository
#[root@bootstrap]

    dnf -y install dnf-plugins-core

    dnf config-manager \
        --add-repo \
        https://download.docker.com/linux/fedora/docker-ce.repo

    >   ....
    >   ....
    >   Adding repo from: https://download.docker.com/linux/fedora/docker-ce.repo


    dnf install \
        -y \
        docker-ce \
        docker-ce-cli \
        containerd.io \
        docker-compose-plugin

    >   ....
    >   ....
    >   Installed:
    >     ....
    >     ....
    >     docker-ce-3:20.10.17-3.fc34.x86_64


# -----------------------------------------------------
# Start the Docker service.
#[root@bootstrap]

    systemctl enable docker

    systemctl start docker

    systemctl status docker --no-pager

    >   Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.
    >   ● docker.service - Docker Application Container Engine
    >        Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)
    >        Active: active (running) since Tue 2023-04-18 05:12:01 UTC; 10ms ago
    >   TriggeredBy: ● docker.socket
    >          Docs: https://docs.docker.com
    >      Main PID: 8570 (dockerd)
    >         Tasks: 8
    >        Memory: 29.5M
    >           CPU: 216ms
    >        CGroup: /system.slice/docker.service
    >                └─8570 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
    >
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.547512429Z" level=info msg="scheme \"unix\" not regis…dule=grpc
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.547528358Z" level=info msg="ccResolverWrapper: sendin…dule=grpc
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.547548837Z" level=info msg="ClientConn switching bala…dule=grpc
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.585614719Z" level=info msg="Loading containers: start."
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.698651017Z" level=info msg="Default bridge (docker0) … address"
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.757408440Z" level=info msg="Loading containers: done."
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.784330275Z" level=info msg="Docker daemon" commit=a89…=20.10.17
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.784462516Z" level=info msg="Daemon has completed init…lization"
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap systemd[1]: Started Docker Application Container Engine.
    >   Apr 18 05:12:01 iris-gaia-red-20230418-bootstrap dockerd[8570]: time="2023-04-18T05:12:01.807185940Z" level=info msg="API listen on /run/docker.sock"


    docker --version

    >   Docker version 20.10.17, build 100c701


    docker info

    >   Client:
    >    Context:    default
    >    Debug Mode: false
    >    Plugins:
    >     app: Docker App (Docker Inc., v0.9.1-beta3)
    >     buildx: Docker Buildx (Docker Inc., v0.8.2-docker)
    >     compose: Docker Compose (Docker Inc., v2.6.0)
    >     scan: Docker Scan (Docker Inc., v0.17.0)
    >
    >   Server:
    >    Containers: 0
    >     Running: 0
    >     Paused: 0
    >     Stopped: 0
    >    Images: 0
    >    Server Version: 20.10.17
    >    Storage Driver: overlay2
    >     Backing Filesystem: extfs
    >     Supports d_type: true
    >     Native Overlay Diff: true
    >     userxattr: false
    >    Logging Driver: json-file
    >    Cgroup Driver: systemd
    >    Cgroup Version: 2
    >    Plugins:
    >     Volume: local
    >     Network: bridge host ipvlan macvlan null overlay
    >     Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
    >    Swarm: inactive
    >    Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux
    >    Default Runtime: runc
    >    Init Binary: docker-init
    >    containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1
    >    runc version: v1.1.2-0-ga916309
    >    init version: de40ad0
    >    Security Options:
    >     seccomp
    >      Profile: default
    >     cgroupns
    >    Kernel Version: 5.11.12-300.fc34.x86_64
    >    Operating System: Fedora 34 (Cloud Edition)
    >    OSType: linux
    >    Architecture: x86_64
    >    CPUs: 2
    >    Total Memory: 2.912GiB
    >    Name: iris-gaia-red-20230418-bootstrap
    >    ID: ZK4F:3UDP:2O2I:2DR5:A3P7:XCHQ:SKDB:X4DN:MJ5S:XLJO:Q6FV:JOLW
    >    Docker Root Dir: /var/lib/docker
    >    Debug Mode: false
    >    Registry: https://index.docker.io/v1/
    >    Labels:
    >    Experimental: false
    >    Insecure Registries:
    >     127.0.0.0/8
    >    Live Restore Enabled: false


# -----------------------------------------------------
# Install kubectl.
# https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#install-using-native-package-management
#[root@bootstrap]

    cat > '/etc/yum.repos.d/kubernetes.repo' << EOF
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

    dnf install -y 'kubectl'

    >   Installed:
    >     kubectl-1.27.1-0.x86_64


    kubectl version --output json

    >   {
    >     "clientVersion": {
    >       "major": "1",
    >       "minor": "27",
    >       "gitVersion": "v1.27.1",
    >       "gitCommit": "4c9411232e10168d7b050c49a1b59f6df9d7ea4b",
    >       "gitTreeState": "clean",
    >       "buildDate": "2023-04-14T13:21:19Z",
    >       "goVersion": "go1.20.3",
    >       "compiler": "gc",
    >       "platform": "linux/amd64"
    >     },
    >     "kustomizeVersion": "v5.0.1"
    >   }


    kubectl config view

    >   apiVersion: v1
    >   clusters: null
    >   contexts: null
    >   current-context: ""
    >   kind: Config
    >   preferences: {}
    >   users: null


# -----------------------------------------------------
# Install kind on the bootstrap node.
# https://kind.sigs.k8s.io/docs/user/quick-start/#installing-from-release-binaries
#[root@bootstrap]

    kindversion=0.17.0
    kindbinary=kind-${kindversion:?}
    kindtemp=/tmp/${kindbinary:?}

    curl \
        --location \
        --no-progress-meter \
        --output "${kindtemp:?}" \
        "https://kind.sigs.k8s.io/dl/v${kindversion:?}/kind-linux-amd64"

    pushd /usr/local/bin
        mv "${kindtemp:?}" .
        chown 'root:root' "${kindbinary:?}"
        chmod 'u=rwx,g=rx,o=rx' "${kindbinary:?}"
        ln -s "${kindbinary:?}" 'kind'
    popd

    ls -al /usr/local/bin/

    >   ....
    >   lrwxrwxrwx.  1 root root      11 Apr 18 05:13 kind -> kind-0.17.0
    >   -rwxr-xr-x.  1 root root 6929103 Apr 18 05:13 kind-0.17.0
    >   ....


    kind --version

    >   kind version 0.17.0


# -----------------------------------------------------
# Install Helm on the bootstrap node.
# https://helm.sh/docs/intro/install/
# https://github.com/helm/helm/releases
#[root@bootstrap]

    helmarch=linux-amd64
    helmversion=3.11.2
    helmtarfile=helm-v${helmversion}-${helmarch}.tar.gz
    helmtmpfile=/tmp/${helmtarfile:?}
    helmbinary=helm-${helmversion:?}

    curl \
        --location \
        --no-progress-meter \
        --output "${helmtmpfile:?}" \
        "https://get.helm.sh/${helmtarfile:?}"

    tar \
        --gzip \
        --extract \
        --directory /tmp \
        --file "${helmtmpfile:?}"

    pushd /usr/local/bin
        mv "/tmp/${helmarch:?}/helm" "${helmbinary:?}"
        chown 'root:root' "${helmbinary:?}"
        chmod 'u=rwx,g=rx,o=rx' "${helmbinary:?}"
        ln -s "${helmbinary:?}" 'helm'
    popd

    ls -al /usr/local/bin/

    >   ....
    >   lrwxrwxrwx.  1 root root       11 Apr 18 05:14 helm -> helm-3.11.2
    >   -rwxr-xr-x.  1 root root 46874624 Mar  8 21:17 helm-3.11.2
    >   ....


    helm version

    >   version.BuildInfo{
    >       Version:"v3.11.2",
    >       GitCommit:"912ebc1cd10d38d340f048efaf0abda047c3468e",
    >       GitTreeState:"clean",
    >       GoVersion:"go1.18.10"
    >       }


# -----------------------------------------------------
# Install clusterctl
# The clusterctl CLI tool handles the lifecycle of a Cluster-API management cluster.
# https://cluster-api-openstack.sigs.k8s.io/getting-started.html#install-clusterctl
#[root@bootstrap]

    clusterctlversion=1.4.1
    clusterctlbinary=clusterctl-${clusterctlversion:?}

    curl \
        --location \
        --no-progress-meter \
        --output "/tmp/${clusterctlbinary:?}" \
        "https://github.com/kubernetes-sigs/cluster-api/releases/download/v${clusterctlversion:?}/clusterctl-linux-amd64"

    pushd /usr/local/bin
        mv "/tmp/${clusterctlbinary:?}" "${clusterctlbinary:?}"
        chown 'root:root' "${clusterctlbinary:?}"
        chmod 'u=rwx,g=rx,o=rx' "${clusterctlbinary:?}"
        ln -s "${clusterctlbinary:?}" 'clusterctl'
    popd

    ls -al /usr/local/bin/

    >   ....
    >   lrwxrwxrwx.  1 root root       16 Apr 18 05:14 clusterctl -> clusterctl-1.4.1
    >   -rwxr-xr-x.  1 root root 68700915 Apr 18 05:14 clusterctl-1.4.1
    >   ....


    clusterctl version

    >   clusterctl version: &version.Info{
    >       Major:"1",
    >       Minor:"4",
    >       GitVersion:"v1.4.1",
    >       GitCommit:"39d87e91080088327c738c43f39e46a7f557d03b",
    >       GitTreeState:"clean",
    >       BuildDate:"2023-04-04T17:31:43Z",
    >       GoVersion:"go1.19.6",
    >       Compiler:"gc",
    >       Platform:"linux/amd64"
    >       }


# -----------------------------------------------------
# Create our initial Kind cluster.
# https://github.com/kubernetes-sigs/kind/pull/2478#issuecomment-1214656908
#[root@bootstrap]

    kind create cluster --retain

    >   Creating cluster "kind" ...
    >    ✓ Ensuring node image (kindest/node:v1.25.3) 🖼
    >    ✓ Preparing nodes 📦
    >    ✓ Writing configuration 📜
    >    ✓ Starting control-plane 🕹️
    >    ✓ Installing CNI 🔌
    >    ✓ Installing StorageClass 💾
    >   ....
    >   ....


    kubectl cluster-info --context kind-kind

    >   Kubernetes control plane is running at https://127.0.0.1:37283
    >   CoreDNS is running at https://127.0.0.1:37283/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
    >   ....
    >   ....


    kubectl get pods --all-namespaces

    >   NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE
    >   kube-system          coredns-565d847f94-45m7s                     1/1     Running   0          12s
    >   kube-system          coredns-565d847f94-tttjv                     1/1     Running   0          12s
    >   kube-system          etcd-kind-control-plane                      1/1     Running   0          25s
    >   kube-system          kindnet-hvbvx                                1/1     Running   0          13s
    >   kube-system          kube-apiserver-kind-control-plane            1/1     Running   0          25s
    >   kube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          25s
    >   kube-system          kube-proxy-42p5l                             1/1     Running   0          13s
    >   kube-system          kube-scheduler-kind-control-plane            1/1     Running   0          26s
    >   local-path-storage   local-path-provisioner-684f458cdd-z8nr4      1/1     Running   0          12s


# -----------------------------------------------------
# Initialize the Openstack management cluster
# https://cluster-api-openstack.sigs.k8s.io/getting-started.html#initialization-for-common-providers
#[root@bootstrap]

    clusterctl init --infrastructure openstack

    >   Fetching providers
    >   Installing cert-manager Version="v1.11.0"
    >   Waiting for cert-manager to be available...
    >   Installing Provider="cluster-api" Version="v1.4.1" TargetNamespace="capi-system"
    >   Installing Provider="bootstrap-kubeadm" Version="v1.4.1" TargetNamespace="capi-kubeadm-bootstrap-system"
    >   Installing Provider="control-plane-kubeadm" Version="v1.4.1" TargetNamespace="capi-kubeadm-control-plane-system"
    >   Installing Provider="infrastructure-openstack" Version="v0.7.1" TargetNamespace="capo-system"
    >   ....
    >   ....


    kubectl get pods --all-namespaces

    >   NAMESPACE                           NAME                                                             READY   STATUS    RESTARTS   AGE
    >   capi-kubeadm-bootstrap-system       capi-kubeadm-bootstrap-controller-manager-8654485994-kdnxz       1/1     Running   0          26s
    >   capi-kubeadm-control-plane-system   capi-kubeadm-control-plane-controller-manager-5d9d9494d5-8dv7h   1/1     Running   0          25s
    >   capi-system                         capi-controller-manager-746b4f5db4-nl2nz                         1/1     Running   0          27s
    >   capo-system                         capo-controller-manager-775d744795-tt9vh                         1/1     Running   0          22s
    >   cert-manager                        cert-manager-99bb69456-gg529                                     1/1     Running   0          50s
    >   cert-manager                        cert-manager-cainjector-ffb4747bb-ntvcv                          1/1     Running   0          50s
    >   cert-manager                        cert-manager-webhook-545bd5d7d8-kjggj                            1/1     Running   0          50s
    >   kube-system                         coredns-565d847f94-45m7s                                         1/1     Running   0          105s
    >   kube-system                         coredns-565d847f94-tttjv                                         1/1     Running   0          105s
    >   kube-system                         etcd-kind-control-plane                                          1/1     Running   0          118s
    >   kube-system                         kindnet-hvbvx                                                    1/1     Running   0          106s
    >   kube-system                         kube-apiserver-kind-control-plane                                1/1     Running   0          118s
    >   kube-system                         kube-controller-manager-kind-control-plane                       1/1     Running   0          118s
    >   kube-system                         kube-proxy-42p5l                                                 1/1     Running   0          106s
    >   kube-system                         kube-scheduler-kind-control-plane                                1/1     Running   0          119s
    >   local-path-storage                  local-path-provisioner-684f458cdd-z8nr4                          1/1     Running   0          105s


# -----------------------------------------------------
# -----------------------------------------------------
# List the available VM flavors and images.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        flavor list

    >   +--------------------------------------+-----------------------------+--------+------+-----------+-------+-----------+
    >   | ID                                   | Name                        |    RAM | Disk | Ephemeral | VCPUs | Is Public |
    >   +--------------------------------------+-----------------------------+--------+------+-----------+-------+-----------+
    >   | ....                                 | ....                        |   .... | .... |      .... |  .... | ....      |
    >   | 2e5dc624-1d3b-4da7-8107-cc2dd4cb5073 | vm.v1.large                 |  32768 |   60 |         0 |     8 | True      |
    >   | 6793b213-5efa-4b51-96bf-1340ff066499 | vm.v1.xsmall                |   2048 |   20 |         0 |     1 | True      |
    >   | 698a8d46-eceb-4c55-91ff-38286bf9eabb | vm.v1.tiny                  |   1024 |   10 |         0 |     1 | True      |
    >   | 6b56d6e9-5397-4543-87fb-e0c0b6d47961 | vm.v1.small                 |  16384 |   20 |         0 |     4 | True      |
    >   | ....                                 | ....                        |   .... | .... |      .... |  .... | ....      |
    >   +--------------------------------------+-----------------------------+--------+------+-----------+-------+-----------+


    #
    # The ubuntu-2004-kube images are hidden with 'community' visibility.
    # https://wiki.openstack.org/wiki/Glance-v2-community-image-visibility-design
    #
    # We have uploaded our own copy of the ubuntu-2004-kube image.
    #

    openstack \
        --os-cloud "${cloudname:?}" \
        image list \
            --shared

    >   +--------------------------------------+-----------------------------------+--------+
    >   | ID                                   | Name                              | Status |
    >   +--------------------------------------+-----------------------------------+--------+
    >   | 686c415b-c5a6-419e-8c46-4732498582e8 | gaia-dmp-ubuntu-2004-kube-v1.25.4 | active |
    >   +--------------------------------------+-----------------------------------+--------+


    openstack \
        --os-cloud "${cloudname:?}" \
        availability zone list \
            --compute

    >   +-----------+-------------+
    >   | Zone Name | Zone Status |
    >   +-----------+-------------+
    >   | nova      | available   |
    >   +-----------+-------------+


    #
    # There is more than one external network, so we would have to filter to select the right one.
    openstack \
        --os-cloud "${cloudname:?}" \
        network list \
            --external

    >   +--------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
    >   | ID                                   | Name          | Subnets                                                                                                                                                |
    >   +--------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
    >   | 410920fb-5714-4447-b26a-e7b06092fc62 | cephfs        | 5699fb5d-8316-4b88-b889-b05c8a1ec975                                                                                                                   |
    >   | 57add367-d205-4030-a929-d75617a7c63e | CUDN-Internet | 1847b14d-b974-4f78-959d-44d18d4485b8, 3fcaa5a5-ba8e-49a9-bf94-d87fbb0afc42, 5f1388b3-a0c7-463e-bb58-5532c38e4b40, a79eb610-eca3-4ee8-aaf1-88f4fef5a4e7 |
    >   +--------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        keypair list

    >   +----------------------------------+-------------------------------------------------+------+
    >   | Name                             | Fingerprint                                     | Type |
    >   +----------------------------------+-------------------------------------------------+------+
    >   | iris-gaia-blue-20230209-keypair  | 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16 | ssh  |
    >   | iris-gaia-green-20230203-keypair | 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16 | ssh  |
    >   | iris-gaia-red-20230418-keypair   | 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16 | ssh  |
    >   +----------------------------------+-------------------------------------------------+------+


# -----------------------------------------------------
# Extract the settings we need.
#[root@ansibler]

    nodenodeflavor=vm.v1.large
    ctrlnodeflavor=vm.v1.small

    keypair=$(
        yq '.aglais.openstack.keypairs.team.name' /opt/aglais/aglais-status.yml
        )

    externalnet=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            network list \
                --external \
                --format json \
        | jq -r ".[] | select(.Name == \"CUDN-Internet\") | .ID"
        )


# -----------------------------------------------------
# Transfer the Openstack settings to our bootstrap node.
#[root@ansibler]

    cat > /tmp/openstack-settings.env << EOF
export OPENSTACK_CLOUD=${cloudname:?}
export OPENSTACK_SSH_KEY_NAME=${keypair:?}
export OPENSTACK_EXTERNAL_NETWORK_ID=${externalnet:?}

export OPENSTACK_NODE_MACHINE_FLAVOR=${nodenodeflavor}
export OPENSTACK_CONTROL_PLANE_MACHINE_FLAVOR=${ctrlnodeflavor}

export KUBERNETES_VERSION=1.25.4
export OPENSTACK_IMAGE_NAME=gaia-dmp-ubuntu-2004-kube-v1.25.4

export OPENSTACK_FAILURE_DOMAIN=nova

#
# Use the Cambridge DNS servers.
# https://www.dns.cam.ac.uk/servers/rec.html
# export OPENSTACK_DNS_NAMESERVERS=131.111.8.42,131.111.12.20
# Only use one, using two addresses caused an error.
export OPENSTACK_DNS_NAMESERVERS=131.111.8.42

EOF

    scp \
        /tmp/openstack-settings.env \
        bootstrap:/tmp/openstack-settings.env

    ssh bootstrap \
        '
        sudo mkdir -p \
            /etc/aglais
        sudo install \
            /tmp/openstack-settings.env \
            /etc/aglais/openstack-settings.env
        '


# -----------------------------------------------------
# Transfer a copy of our clouds.yaml file.
#[root@ansibler]

    scp \
        /etc/openstack/clouds.yaml \
        bootstrap:/tmp/openstack-clouds.yaml

    ssh bootstrap \
        '
        sudo mkdir -p \
            /etc/aglais
        sudo install \
            /tmp/openstack-clouds.yaml \
            /etc/aglais/openstack-clouds.yaml
        '


# -----------------------------------------------------
# -----------------------------------------------------
# Install yq on the bootstrap node.
#[root@bootstrap]

    yqversion=4.33.3
    yqbinary=yq-${yqversion:?}

    curl \
        --location \
        --no-progress-meter \
        --output "/tmp/${yqbinary:?}" \
        "https://github.com/mikefarah/yq/releases/download/v${yqversion}/yq_linux_amd64"

    pushd /usr/local/bin
        mv "/tmp/${yqbinary:?}" "${yqbinary:?}"
        chown 'root:root' "${yqbinary:?}"
        chmod 'u=rwx,g=rx,o=rx' "${yqbinary:?}"
        ln -s "${yqbinary:?}" 'yq'
    popd

    ls -al /usr/local/bin/

    >   ....
    >   lrwxrwxrwx.  1 root root        9 Apr 18 05:22 yq -> yq-4.33.3
    >   -rwxr-xr-x.  1 root root  8839168 Apr 18 05:22 yq-4.33.3
    >   ....


    yq --version

    >   yq (https://github.com/mikefarah/yq/) version v4.33.3


# -----------------------------------------------------
# Edit our clouds.yaml file to disable TLS certificate checks.
# https://docs.openstack.org/os-client-config/latest/user/configuration.html#ssl-settings
#[root@bootstrap]

    vi /etc/aglais/openstack-clouds.yaml

          iris-gaia-red-admin:
            auth:
              auth_url: https://arcus.openstack.hpc.cam.ac.uk:5000
              ....
              ....
            region_name: "RegionOne"
            interface: "public"
            identity_api_version: 3
            auth_type: "v3applicationcredential"
       +    verify: false


# -----------------------------------------------------
# Load our Openstack settings.
#[root@bootstrap]

    source /etc/aglais/openstack-settings.env

cat << EOF
OPENSTACK_CLOUD [${OPENSTACK_CLOUD}]
OPENSTACK_IMAGE_NAME [${OPENSTACK_IMAGE_NAME}]
EOF

    >   OPENSTACK_CLOUD [iris-gaia-red-admin]
    >   OPENSTACK_IMAGE_NAME [gaia-dmp-ubuntu-2004-kube-v1.25.4]


# -----------------------------------------------------
# Use the script provided by cluster-api-provider-openstack to parse our clouds.yaml file.
# https://cluster-api-openstack.sigs.k8s.io/clusteropenstack/configuration.html#generate-credentials
# https://github.com/kubernetes-sigs/cluster-api-provider-openstack/blob/main/docs/book/src/clusteropenstack/configuration.md#generate-credentials
#[root@bootstrap]

    curl \
        --location \
        --no-progress-meter \
        --output '/tmp/env.rc' \
        'https://raw.githubusercontent.com/kubernetes-sigs/cluster-api-provider-openstack/master/templates/env.rc'

    source '/tmp/env.rc' '/etc/aglais/openstack-clouds.yaml' "${OPENSTACK_CLOUD:?}"

cat << EOF
OPENSTACK_CLOUD_YAML_B64   [${OPENSTACK_CLOUD_YAML_B64}]
OPENSTACK_CLOUD_CACERT_B64 [${OPENSTACK_CLOUD_CACERT_B64}]
OPENSTACK_CLOUD_PROVIDER_CONF_B64 [${OPENSTACK_CLOUD_PROVIDER_CONF_B64}]
EOF

    >   OPENSTACK_CLOUD_YAML_B64   [Y2xvdWRz....YWxzZQo=]
    >   OPENSTACK_CLOUD_CACERT_B64 [Cg==]
    >   OPENSTACK_CLOUD_PROVIDER_CONF_B64 [W0dsb2Jh....dTJ2Igo=]


# -----------------------------------------------------
# Generate our external cluster config.
# https://cluster-api.sigs.k8s.io/clusterctl/commands/generate-cluster.html
# https://cluster-api-openstack.sigs.k8s.io/getting-started.html#generating-the-cluster-configuration
#[root@bootstrap]

    CLUSTER_NAME=brown-toad

    clusterctl generate cluster \
        "${CLUSTER_NAME:?}" \
        --flavor external-cloud-provider \
        --kubernetes-version "${KUBERNETES_VERSION:?}" \
        --control-plane-machine-count 3 \
        --worker-machine-count 3 \
    | tee "/tmp/${CLUSTER_NAME:?}.yaml"


    >   apiVersion: v1
    >   data:
    >     cacert: Cg==
    >     clouds.yaml: Y2xvdWRz....mYWxzZQo=
    >   kind: Secret
    >   metadata:
    >     labels:
    >       clusterctl.cluster.x-k8s.io/move: "true"
    >     name: brown-toad-cloud-config
    >     namespace: default
    >   ....
    >   ....
    >   apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >   kind: OpenStackMachineTemplate
    >   metadata:
    >     name: brown-toad-md-0
    >     namespace: default
    >   spec:
    >     template:
    >       spec:
    >         cloudName: iris-gaia-red-admin
    >         flavor: vm.v1.large
    >         identityRef:
    >           kind: Secret
    >           name: brown-toad-cloud-config
    >         image: gaia-dmp-ubuntu-2004-kube-v1.25.4
    >         sshKeyName: iris-gaia-red-20230414-keypair


# -----------------------------------------------------
# Apply the cluster config.
# https://cluster-api.sigs.k8s.io/user/quick-start.html#apply-the-workload-cluster
#[root@bootstrap]

    kubectl apply \
        -f "/tmp/${CLUSTER_NAME:?}.yaml"

    >   secret/brown-toad-cloud-config created
    >   kubeadmconfigtemplate.bootstrap.cluster.x-k8s.io/brown-toad-md-0 created
    >   cluster.cluster.x-k8s.io/brown-toad created
    >   machinedeployment.cluster.x-k8s.io/brown-toad-md-0 created
    >   kubeadmcontrolplane.controlplane.cluster.x-k8s.io/brown-toad-control-plane created
    >   openstackcluster.infrastructure.cluster.x-k8s.io/brown-toad created
    >   openstackmachinetemplate.infrastructure.cluster.x-k8s.io/brown-toad-control-plane created
    >   openstackmachinetemplate.infrastructure.cluster.x-k8s.io/brown-toad-md-0 created


    kubectl get cluster

    >   NAME         PHASE          AGE   VERSION
    >   brown-toad   Provisioning   10s


    clusterctl describe cluster 'green-frog'

    >   ....
    >   ....


    kubectl \
        --namespace capo-system \
        logs \
        -l control-plane=capo-controller-manager \
        -c manager \
        --follow

    #
    # First run showed a problem with the ssh key pair name.

    >   ....
    >   E0418 05:34:06.257858       1 controller.go:326] "
    >       Reconciler error"
    >           err="
    >               create OpenStack instance: error creating Openstack instance:
    >                   Bad request with: [POST https://arcus.openstack.hpc.cam.ac.uk:8774/v2.1/servers],
    >           error message: {
    >               \"badRequest\": {
    >                   \"code\": 400,
    >                   \"message\": \"Invalid key_name provided.\"
    >                   }
    >               }"
    >           controller="openstackmachine"
    >           controllerGroup="infrastructure.cluster.x-k8s.io"
    >           controllerKind="OpenStackMachine"
    >           OpenStackMachine="default/brown-toad-control-plane-8pfjd"
    >           namespace="default"
    >           name="brown-toad-control-plane-8pfjd"
    >           reconcileID=a30b081b-79e0-46f8-9c53-57d4da9a6985
    >   ....

    #
    # Our cloud name doesn't match our key name.

    >   ....
    >   ....
    >   ....
    >   ....
    >   apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >   kind: OpenStackMachineTemplate
    >   ....
    >   spec:
    >     template:
    >       spec:
    >         cloudName: iris-gaia-red-admin
    >         ....
    >         sshKeyName: iris-gaia-red-20230414-keypair


