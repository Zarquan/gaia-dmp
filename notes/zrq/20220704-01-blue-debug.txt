#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Diagnosing the cause of the failures trying to process the GDR3 data.


    Result:

        Work in progress ...

# -----------------------------------------------------

    Notes on the deployment are on a branch in Stelios's fork.
    https://github.com/stvoutsin/aglais/tree/feature/20220624-deploy

    Not merged yet, but nothing blocking it.

    Deployment notes are here:
    https://github.com/stvoutsin/aglais/blob/feature/20220624-deploy/notes/stv/20220627-blue-deploy-01.txt

    Deployment configuration is here:
    https://github.com/stvoutsin/aglais/blob/feature/20220624-deploy/deployments/hadoop-yarn/ansible/config/zeppelin-54.86-spark-12.26.43.yml

        zeppelinflavor: 'gaia.vm.cclake.54vcpu'
        masterflavor:   'gaia.vm.cclake.2vcpu'
        workerflavor:   'gaia.vm.cclake.26vcpu'
        monitorflavor:  'gaia.vm.cclake.2vcpu'

    These correspnd to Openstack flavors

        openstack \
            --os-cloud "${cloudname:?}" \
            flavor list

        +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
        | ID                                   | Name                  |   RAM | Disk | Ephemeral | VCPUs | Is Public |
        +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+
        | 56c420d5-abea-41da-9863-f5bc08b08430 | gaia.vm.cclake.54vcpu | 88064 |   20 |       380 |    54 | False     |
        | 0997c60d-3460-432a-a7fc-78d2cd466b4c | gaia.vm.cclake.26vcpu | 44032 |   20 |       180 |    26 | False     |
        | ef01ce36-283f-4df3-a039-1b47504de078 | gaia.vm.cclake.12vcpu | 21504 |   20 |        80 |    12 | False     |
        | a1b2789c-761a-4843-8ea8-603a9209dec8 | gaia.vm.cclake.6vcpu  |  9216 |   20 |        24 |     6 | False     |
        | 80e0721d-db0f-407f-a2bf-fe6641312204 | gaia.vm.cclake.4vcpu  |  6144 |   22 |         0 |     4 | False     |
        | df5133ea-1bfb-45fd-ba39-71fc820abcb1 | gaia.vm.cclake.2vcpu  |  3072 |   14 |         0 |     2 | False     |
        | 166497c3-a0bb-4276-bee3-e56932e6f3e4 | gaia.vm.cclake.1vcpu  |  1024 |    8 |         0 |     1 | False     |
        +--------------------------------------+-----------------------+-------+------+-----------+-------+-----------+

        gaia.vm.cclake.54vcpu

             54 cores
            86G memory
            20G disc
           380G disc

        gaia.vm.cclake.26vcpu

             26 cores
            43G memory
            20G disc
           180G disc


    Documentation for the spread sheet.
    https://www.c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/

    Settings used for the spread sheet used in the deployment - check with Stelios.
    Using local copy of the sperad sheet ..

        Settings in the spread sheet:

            Master Memory	        86
            Master Cores            54
            Number of Worker Nodes	12
            Memory Per Worker Node (GB)	43
            Cores Per Worker Node	26

        Defaults in the spread sheet:

            Memory Overhead Coefficient	        0.1
            Executor Memory Upper Bound (GB)    64
            Executor Core Upper Bound	        5
            OS Reserved Cores	                1
            OS Reserved Memory (GB)	            1
            Parallelism Per Core	            2

            Available Master Memory	            85
            Available Master Cores	            53
            Available Worker Memory	            42
            Available Worker Cores	            25

        Results from the spread sheet

            Executors per node 5

            spark.executor.instances            60
            spark.yarn.executor.memoryOverhead	1024
            spark.executor.memory               7
            spark.yarn.driver.memoryOverhead    9216
            spark.driver.memory                 57.6
            spark.executor.cores                5
            spark.driver.cores                  5
            spark.default.parallelism           600

    Section of the configuration that sets the resource limts is here
    https://github.com/stvoutsin/aglais/blob/feature/20220624-deploy/deployments/hadoop-yarn/ansible/config/zeppelin-54.86-spark-12.26.43.yml#L51-L92

            # Calculated using Cheatsheet.xlsx              //
            spark.driver.memory                 57344m      // < 57.6G = 58982M
            spark.driver.memoryOverhead           9216      // = 9216
            spark.driver.cores                       5      // = 5
            spark.driver.maxResultSize          40960m
            spark.executor.memory                6144m      // < 7168
            spark.executor.memoryOverhead         1024      // = 1024
            spark.executor.cores                     4      // < 5
            #spark.executor.instances               30      // < 60
            spark.default.parallelism              576      // < 600
            #spark.sql.shuffle.partitions          300
            # YARN Application Master settings
            spark.yarn.am.memory                 2048m
            spark.yarn.am.cores                      1
            spark.dynamicAllocation.enabled          true
            spark.shuffle.service.enabled            true
            spark.dynamicAllocation.minExecutors      1
             # spark.executor.instances from Cheatsheet
            spark.dynamicAllocation.maxExecutors     72     // > 60
             # maxExecutors / 2
            spark.dynamicAllocation.initialExecutors          15
            spark.dynamicAllocation.cachedExecutorIdleTimeout 60s
            spark.dynamicAllocation.executorIdleTimeout       60s
            spark.sql.execution.arrow.pyspark.enabled         true


    The configuration settings are placed in {{sphome}}/conf/spark-defaults.conf by this Ansible task
    https://github.com/stvoutsin/aglais/blob/bb6b8dfae00d0355e932b44634377322822fe583/deployments/hadoop-yarn/ansible/22-config-spark-master.yml#L51-L63








