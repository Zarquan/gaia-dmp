#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2024, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#
# AIMetrics: []
#

    Target:

        Create a deployment on Arcus red to test fixes from Somerville.

    Result:

        Work in progress ...

# -----------------------------------------------------
# Check the live service.
#[user@desktop]

    ssh fedora@live.gaia-dmp.uk \
        '
        date
        hostname
        '

    >   Wed 10 Jan 12:05:45 UTC 2024
    >   iris-gaia-green-20231027-zeppelin


# -----------------------------------------------------
# Delete and create everything on red.
#[user@desktop]

    source "${HOME}/aglais.env"

    agclient red

        export cloudsite='cambridge-arcus'

        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

        ansible-playbook \
            --inventory 'bootstrap,' \
            '/deployments/cluster-api/bootstrap/ansible/00-create-all.yml'

    >   ....
    >   ....
    >   PLAY RECAP ******************************************************************************************************************************
    >   bootstrap                  : ok=57   changed=44   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   localhost                  : ok=35   changed=26   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


# -----------------------------------------------------
# Check the status.
#[root@ansibler]

    yq '.' /opt/aglais/aglais-status.yml

    >   aglais:
    >     ansibler:
    >       external:
    >         ipv4: 90.155.51.57
    >     deployment:
    >       date: 20240110
    >       name: iris-gaia-red-20240110
    >       type: cluster-api
    >     kubernetes:
    >       cluster:
    >         kind:
    >           conf: /opt/aglais/iris-gaia-red-20240110-kind.yml
    >           name: iris-gaia-red-20240110-kind
    >         work:
    >           conf: /opt/aglais/iris-gaia-red-20240110-work.yml
    >           name: iris-gaia-red-20240110-work
    >       version: 1.26.7
    >     openstack:
    >       cloud:
    >         name: iris-gaia-red
    >         site: cambridge-arcus
    >       keypair:
    >         fingerprint: 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16
    >         id: iris-gaia-red-20240110-keypair
    >         name: iris-gaia-red-20240110-keypair
    >       networks:
    >         bootstrap:
    >           network:
    >             id: 50f2cebc-8a01-4b8c-8478-40acca699062
    >             name: iris-gaia-red-20240110-bootstrap-network
    >           router:
    >             id: d73d5aee-1eb2-4b0e-a6ec-52aadff8d444
    >             name: iris-gaia-red-20240110-bootstrap-network-router
    >           subnet:
    >             cidr: 10.10.0.0/16
    >             id: 21214504-c9b9-4bad-812c-75926b0ce344
    >             name: iris-gaia-red-20240110-bootstrap-network-subnet
    >         external:
    >           network:
    >             id: 57add367-d205-4030-a929-d75617a7c63e
    >             name: CUDN-Internet
    >       project:
    >         id: 0dd8cc5ee5a7455c8748cc06d04c93c3,
    >         name: iris-gaia-red
    >       servers:
    >         bootstrap:
    >           float:
    >             external: 128.232.226.227
    >             id: 7bf88bdd-2c7b-4b7f-b4bb-f20f876b3fac
    >             internal: 10.10.2.9
    >           server:
    >             address:
    >               ipv4: 10.10.2.9
    >             flavor:
    >               name: gaia.vm.cclake.2vcpu
    >             hostname: bootstrap
    >             id: 7608a7e7-fa1a-4379-94a7-668c82688dd1
    >             image:
    >               id: 8b608db9-a74c-4de2-ac04-8eddb3041f39
    >               name: gaia-dmp-fedora-cloud-38-1.6
    >             name: iris-gaia-red-20240110-bootstrap-node
    >       user:
    >         id: 5fa0c97a6dd14e01a3c7d91dad5c6b17,
    >         name: dmorris_gaia


# -----------------------------------------------------
# Login to our bootstrap node.
#[root@ansibler]

    ssh bootstrap

        source loadconfig


# -----------------------------------------------------
# Check the work cluster status.
#[root@ansibler]

    clusterctl \
        --kubeconfig "${kindclusterconf:?}" \
        describe cluster \
            "${workclustername:?}"

    >   NAME                                                                            READY  SEVERITY  REASON                                                                   SINCE  MESSAGE
    >   Cluster/iris-gaia-red-20240110-work                                             False  Error     InstanceCreateFailed @ /iris-gaia-red-20240110-work-control-plane-hq5pd  105s   1 of 2 completed
    >   ├─ClusterInfrastructure - OpenStackCluster/iris-gaia-red-20240110-work
    >   ├─ControlPlane - KubeadmControlPlane/iris-gaia-red-20240110-work-control-plane  False  Error     InstanceCreateFailed @ /iris-gaia-red-20240110-work-control-plane-hq5pd  105s   1 of 2 completed
    >   │ └─Machine/iris-gaia-red-20240110-work-control-plane-hq5pd                     False  Error     InstanceCreateFailed                                                     2m5s   1 of 2 completed
    >   └─Workers
    >     └─MachineDeployment/iris-gaia-red-20240110-work-md-0                          False  Warning   WaitingForAvailableMachines                                              84m    Minimum availability requires 2 replicas, current 0 available
    >       └─3 Machines...                                                             False  Info      WaitingForBootstrapData                                                  83m    See iris-gaia-red-20240110-work-md-0-nqmgq-5gn8z, iris-gaia-red-20240110-work-md-0-nqmgq-cmk6r, ...

    >   NAME                                                                            READY  SEVERITY  REASON                                                                   SINCE  MESSAGE
    >   Cluster/iris-gaia-red-20240110-work                                             False  Error     InstanceCreateFailed @ /iris-gaia-red-20240110-work-control-plane-rpwjf  105s   1 of 2 completed
    >   ├─ClusterInfrastructure - OpenStackCluster/iris-gaia-red-20240110-work
    >   ├─ControlPlane - KubeadmControlPlane/iris-gaia-red-20240110-work-control-plane  False  Error     InstanceCreateFailed @ /iris-gaia-red-20240110-work-control-plane-rpwjf  105s   1 of 2 completed
    >   │ └─Machine/iris-gaia-red-20240110-work-control-plane-rpwjf                     False  Error     InstanceCreateFailed                                                     2m5s   1 of 2 completed
    >   └─Workers
    >     └─MachineDeployment/iris-gaia-red-20240110-work-md-0                          False  Warning   WaitingForAvailableMachines                                              3m39s  Minimum availability requires 2 replicas, current 0 available
    >       └─3 Machines...                                                             False  Info      WaitingForBootstrapData                                                  2m7s   See iris-gaia-red-20240110-work-md-0-gczh9-4j7q9, iris-gaia-red-20240110-work-md-0-gczh9-l9dfv, ...


# -----------------------------------------------------
# Check the load balancer status.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        loadbalancer list

    >   +--------------------------------------+--------------------------------------------------------------------+----------------------------------+---------------+---------------------+------------------+----------+
    >   | id                                   | name                                                               | project_id                       | vip_address   | provisioning_status | operating_status | provider |
    >   +--------------------------------------+--------------------------------------------------------------------+----------------------------------+---------------+---------------------+------------------+----------+
    >   | aab801d7-31e7-4030-94ff-e55bc9abf30f | k8s-clusterapi-cluster-default-iris-gaia-red-20240110-work-kubeapi | 0dd8cc5ee5a7455c8748cc06d04c93c3 | 192.168.3.223 | ACTIVE              | ONLINE           | amphora  |
    >   +--------------------------------------+--------------------------------------------------------------------+----------------------------------+---------------+---------------------+------------------+----------+


    balancerid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            loadbalancer list \
                --format json \
        | jq -r '.[0].id'
        )

    openstack \
        --os-cloud "${cloudname:?}" \
        loadbalancer show \
            --format json \
            "${balancerid}" \
    | jq '.'

    >   {
    >     "admin_state_up": true,
    >     "availability_zone": null,
    >     "created_at": "2024-01-10T17:11:53",
    >     "description": "Created by cluster-api-provider-openstack cluster default-iris-gaia-red-20240110-work",
    >     "flavor_id": null,
    >     "id": "aab801d7-31e7-4030-94ff-e55bc9abf30f",
    >     "listeners": "7899cc8a-cbda-4397-b908-14613b472d2d",
    >     "name": "k8s-clusterapi-cluster-default-iris-gaia-red-20240110-work-kubeapi",
    >     "operating_status": "ONLINE",
    >     "pools": "f5705c1b-986f-4dfc-9269-0d637222e410",
    >     "project_id": "0dd8cc5ee5a7455c8748cc06d04c93c3",
    >     "provider": "amphora",
    >     "provisioning_status": "ACTIVE",
    >     "updated_at": "2024-01-10T17:14:13",
    >     "vip_address": "192.168.3.223",
    >     "vip_network_id": "65e94d61-b214-4223-9542-6f19840c094e",
    >     "vip_port_id": "0242790a-a6f0-43be-9b18-02b21bb44bc8",
    >     "vip_qos_policy_id": null,
    >     "vip_subnet_id": "afaea83c-b901-46c1-9651-d88d9dc32f24",
    >     "tags": ""
    >   }


# -----------------------------------------------------
# Grab a dump of the logs from all the Pods.
#[root@ansibler]

    ssh bootstrap

        source loadconfig

        mkdir /tmp/logs

        for podnamespace in $(
            kubectl \
                --kubeconfig "${kindclusterconf:?}" \
                get pods \
                    --output json \
                    --all-namespaces \
            | jq -r '.items[].metadata | {namespace, name} | tojson'
            )
        do
            echo ""
            echo "----"

            namespace=$(echo ${podnamespace} | jq -r '.namespace')
            name=$(echo  ${podnamespace} | jq -r '.name')

            echo "Space   [${namespace}]"
            echo "Name    [${name}]"

            kubectl \
                --kubeconfig "${kindclusterconf:?}" \
                logs \
                    --namespace "${namespace:?}"  \
                    "${name:?}" \
            > "/tmp/logs/${name:?}.log"

        done

    >   ----
    >   Space   [capi-kubeadm-bootstrap-system]
    >   Name    [capi-kubeadm-bootstrap-controller-manager-55d5767547-pkfhn]
    >   
    >   ----
    >   Space   [capi-kubeadm-control-plane-system]
    >   Name    [capi-kubeadm-control-plane-controller-manager-85fd48fb9b-fgwr6]
    >   
    >   ----
    >   Space   [capi-system]
    >   Name    [capi-controller-manager-7cb6bcd4db-5r7dc]
    >   
    >   ----
    >   Space   [capo-system]
    >   Name    [capo-controller-manager-544cb69b9d-hkfrf]
    >   
    >   ----
    >   Space   [cert-manager]
    >   Name    [cert-manager-66d9545484-w2v7c]
    >   
    >   ----
    >   Space   [cert-manager]
    >   Name    [cert-manager-cainjector-7d8b6bd6fb-2mp2c]
    >   
    >   ----
    >   Space   [cert-manager]
    >   Name    [cert-manager-webhook-669b96dcfd-m2str]
    >   
    >   ----
    >   Space   [default]
    >   Name    [cluster-api-addon-provider-66cc76bbbf-5nzlp]
    >   
    >   ----
    >   Space   [default]
    >   Name    [iris-gaia-red-20240110-work-autoscaler-5b76977f89-vd74l]
    >   
    >   ----
    >   Space   [kube-system]
    >   Name    [coredns-5d78c9869d-6xvt4]
    >   
    >   ----
    >   Space   [kube-system]
    >   Name    [coredns-5d78c9869d-mr586]
    >   
    >   ----
    >   Space   [kube-system]
    >   Name    [etcd-iris-gaia-red-20240110-kind-control-plane]
    >   
    >   ----
    >   Space   [kube-system]
    >   Name    [kindnet-sb8zc]
    >   
    >   ----
    >   Space   [kube-system]
    >   Name    [kube-apiserver-iris-gaia-red-20240110-kind-control-plane]
    >   
    >   ----
    >   Space   [kube-system]
    >   Name    [kube-controller-manager-iris-gaia-red-20240110-kind-control-plane]
    >   
    >   ----
    >   Space   [kube-system]
    >   Name    [kube-proxy-dfl7v]
    >   
    >   ----
    >   Space   [kube-system]
    >   Name    [kube-scheduler-iris-gaia-red-20240110-kind-control-plane]
    >   
    >   ----
    >   Space   [local-path-storage]
    >   Name    [local-path-provisioner-6bc4bddd6b-qgxzn]


# -----------------------------------------------------
# Fold the logs into an archive.
#[user@bootstrap]

    pushd /tmp

        tar -cvzf 20240109-arcus-red-logs.tar.gz logs

    >   logs/local-path-provisioner-6bc4bddd6b-qgxzn.log
    >   logs/kube-scheduler-iris-gaia-red-20240110-kind-control-plane.log
    >   logs/kube-proxy-dfl7v.log
    >   logs/kube-controller-manager-iris-gaia-red-20240110-kind-control-plane.log
    >   logs/kube-apiserver-iris-gaia-red-20240110-kind-control-plane.log
    >   logs/kindnet-sb8zc.log
    >   logs/etcd-iris-gaia-red-20240110-kind-control-plane.log
    >   logs/coredns-5d78c9869d-mr586.log
    >   logs/coredns-5d78c9869d-6xvt4.log
    >   logs/iris-gaia-red-20240110-work-autoscaler-5b76977f89-vd74l.log
    >   logs/cluster-api-addon-provider-66cc76bbbf-5nzlp.log
    >   logs/cert-manager-webhook-669b96dcfd-m2str.log
    >   logs/cert-manager-cainjector-7d8b6bd6fb-2mp2c.log
    >   logs/cert-manager-66d9545484-w2v7c.log
    >   logs/capo-controller-manager-544cb69b9d-hkfrf.log
    >   logs/capi-controller-manager-7cb6bcd4db-5r7dc.log
    >   logs/capi-kubeadm-control-plane-controller-manager-85fd48fb9b-fgwr6.log
    >   logs/capi-kubeadm-bootstrap-controller-manager-55d5767547-pkfhn.log


# -----------------------------------------------------
# -----------------------------------------------------
# Copy the logs from our bootstrap node to our client container.
#[root@ansibler]

    scp bootstrap:/tmp/20240109-arcus-red-logs.tar.gz .

    >   20240109-arcus-red-logs.tar.gz      100%   65KB 754.8KB/s   00:00


# -----------------------------------------------------
# -----------------------------------------------------
# Transfer the logs from our client container to our desktop.
#[user@desktop]

    podman ps

    >   CONTAINER ID  IMAGE                                              COMMAND     CREATED         STATUS             PORTS                   NAMES
    >   ca4d06c64ddb  ghcr.io/wfau/atolmis/kubernetes-client:2023.06.15  bash        19 minutes ago  Up 19 minutes ago  0.0.0.0:8001->8001/tcp  ansibler-red


    pushd /var/local/backups
        pushd aglais/2024

            mkdir 20240109
            pushd 20240109

                podman cp ansibler-red:/20240109-arcus-red-logs.tar.gz .

                tar -xvzf 20240109-arcus-red-logs.tar.gz

    >   logs/local-path-provisioner-6bc4bddd6b-qgxzn.log
    >   logs/kube-scheduler-iris-gaia-red-20240110-kind-control-plane.log
    >   logs/kube-proxy-dfl7v.log
    >   logs/kube-controller-manager-iris-gaia-red-20240110-kind-control-plane.log
    >   logs/kube-apiserver-iris-gaia-red-20240110-kind-control-plane.log
    >   logs/kindnet-sb8zc.log
    >   logs/etcd-iris-gaia-red-20240110-kind-control-plane.log
    >   logs/coredns-5d78c9869d-mr586.log
    >   logs/coredns-5d78c9869d-6xvt4.log
    >   logs/iris-gaia-red-20240110-work-autoscaler-5b76977f89-vd74l.log
    >   logs/cluster-api-addon-provider-66cc76bbbf-5nzlp.log
    >   logs/cert-manager-webhook-669b96dcfd-m2str.log
    >   logs/cert-manager-cainjector-7d8b6bd6fb-2mp2c.log
    >   logs/cert-manager-66d9545484-w2v7c.log
    >   logs/capo-controller-manager-544cb69b9d-hkfrf.log
    >   logs/capi-controller-manager-7cb6bcd4db-5r7dc.log
    >   logs/capi-kubeadm-control-plane-controller-manager-85fd48fb9b-fgwr6.log
    >   logs/capi-kubeadm-bootstrap-controller-manager-55d5767547-pkfhn.log

    #
    # Search through the logs manually.
    #
    # Found it.
    # .. no image with the Name gaia-dmp-ubuntu-2204-kube-v1.26.7 ..
    #

    >   ....
    >   E0110 17:13:20.510803       1 controller.go:329] "Reconciler error" err="create OpenStack instance: error getting image ID: no image with the Name gaia-dmp-ubuntu-2204-kube-v1.26.7 could be found" controller="openstackmachine" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackMachine" OpenStackMachine="default/iris-gaia-red-20240110-work-control-plane-0df2b698-9lr9s" namespace="default" name="iris-gaia-red-20240110-work-control-plane-0df2b698-9lr9s" reconcileID="eb1daed3-b3f2-4506-aca3-439db9ff2fef"
    >   ....


# -----------------------------------------------------
# Out of interest, is that message available at the deployment level ?
#[root@ansibler]

    ssh bootstrap

        source loadconfig

        kubectl \
            --kubeconfig "${kindclusterconf:?}" \
            get deployments \
                --all-namespaces

    >   NAMESPACE                           NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
    >   capi-kubeadm-bootstrap-system       capi-kubeadm-bootstrap-controller-manager       1/1     1            1           45m
    >   capi-kubeadm-control-plane-system   capi-kubeadm-control-plane-controller-manager   1/1     1            1           45m
    >   capi-system                         capi-controller-manager                         1/1     1            1           45m
    >   capo-system                         capo-controller-manager                         1/1     1            1           45m
    >   cert-manager                        cert-manager                                    1/1     1            1           45m
    >   cert-manager                        cert-manager-cainjector                         1/1     1            1           45m
    >   cert-manager                        cert-manager-webhook                            1/1     1            1           45m
    >   default                             cluster-api-addon-provider                      1/1     1            1           44m
    >   default                             iris-gaia-red-20240110-work-autoscaler          0/1     1            0           42m
    >   kube-system                         coredns                                         2/2     2            2           45m
    >   local-path-storage                  local-path-provisioner                          1/1     1            1           45m


        kubectl \
            --kubeconfig "${kindclusterconf:?}" \
            logs \
                --namespace capo-system \
                deployment/capo-controller-manager

    >   E0110 17:54:54.817802       1 controller.go:329] "Reconciler error" err="create OpenStack instance: error getting image ID: no image with the Name gaia-dmp-ubuntu-2204-kube-v1.26.7 could be found" controller="openstackmachine" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackMachine" OpenStackMachine="default/iris-gaia-red-20240110-work-control-plane-0df2b698-pmsb8" namespace="default" name="iris-gaia-red-20240110-work-control-plane-0df2b698-pmsb8" reconcileID="e4ad2113-480c-41c6-b378-60a3c14c06f6"

    #
    # So we need to transfer our image from arcus-blue to arcus-red.
    #

# -----------------------------------------------------
# Check the available images.
#[root@ansibler]

    openstack \
        --os-cloud 'iris-gaia-red' \
        image list

    >   +--------------------------------------+------------------------------------------------+--------+
    >   | ID                                   | Name                                           | Status |
    >   +--------------------------------------+------------------------------------------------+--------+
    >   | ....                                 | ....                                           | ...... |
    >   | 8b608db9-a74c-4de2-ac04-8eddb3041f39 | gaia-dmp-fedora-cloud-38-1.6                   | active |
    >   | 686c415b-c5a6-419e-8c46-4732498582e8 | gaia-dmp-ubuntu-2004-kube-v1.25.4              | active |
    >   | 306ca9c7-a274-4bd5-be62-430aed249cd0 | gaia-dmp-ubuntu-2204-cloudimg                  | active |
    >   | ....                                 | ....                                           | ...... |
    >   +--------------------------------------+------------------------------------------------+--------+


    openstack \
        --os-cloud 'iris-gaia-blue' \
        image list

    >   +--------------------------------------+------------------------------------------------+--------+
    >   | ID                                   | Name                                           | Status |
    >   +--------------------------------------+------------------------------------------------+--------+
    >   | ....                                 | ....                                           | ...... |
    >   | 0d32b1a9-c034-47ef-88d6-ad1a9ba0b91c | gaia-dmp-fedora-cloud-38-1.6                   | active |
    >   | f1791002-0968-4392-adbc-84b207573b15 | gaia-dmp-ubuntu-2204-cloudimg                  | active |
    >   | bf75588c-3286-4cba-8224-8ac590876bec | gaia-dmp-ubuntu-2204-kube-v1.26.7              | active |
    >   | ....                                 | ....                                           | ...... |
    >   +--------------------------------------+------------------------------------------------+--------+

    #
    # Download from blue and upload to red ..
    #

