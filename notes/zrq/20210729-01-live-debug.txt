#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#


    #
    # New deployment, from tagged versoion.
    # Passes the single user tests.
    #
    # Nigel tries to use it, and it locks up.
    # Running the setup notebook, stalls at the first pyspark cell.
    # Status [RUNNING][0%]
    #
    # Stuck waitinig for 3hrs.
    #

    #
    # Worker01 logs show data from last night.
    #

    >   ....
    >   2021-07-29 02:29:42,298 INFO storage.BlockManager: Found block rdd_339_2046 locally
    >   2021-07-29 02:29:42,298 INFO columnar.InMemoryTableScanExec: Predicate isnotnull(random_index#39L) generates partition filter: ((random_index.count#7306 - random_index.nullCount#7305) > 0)
    >   2021-07-29 02:29:42,298 INFO columnar.InMemoryTableScanExec: Predicate (prediction#5646 = 0.0) generates partition filter: ((prediction.lowerBound#7464 <= 0.0) && (0.0 <= prediction.upperBound#7463))
    >   2021-07-29 02:29:42,299 INFO storage.BlockManager: Found block rdd_339_2030 locally
    >   2021-07-29 02:29:42,299 INFO columnar.InMemoryTableScanExec: Predicate isnotnull(random_index#39L) generates partition filter: ((random_index.count#7306 - random_index.nullCount#7305) > 0)
    >   2021-07-29 02:29:42,299 INFO columnar.InMemoryTableScanExec: Predicate (prediction#5646 = 0.0) generates partition filter: ((prediction.lowerBound#7464 <= 0.0) && (0.0 <= prediction.upperBound#7463))
    >   2021-07-29 02:29:42,299 INFO executor.Executor: Finished task 2046.0 in stage 113.0 (TID 199235). 1988 bytes result sent to driver
    >   2021-07-29 02:29:42,300 INFO executor.Executor: Finished task 2030.0 in stage 113.0 (TID 199234). 1955 bytes result sent to driver
    >   ....

    #
    # Zeppelin logs show it in a waiting loop.
    #

    >    ....
    >    INFO [2021-07-29 11:15:31,877] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Application report for application_1627517522169_0002 (state: ACCEPTED)
    >    INFO [2021-07-29 11:15:32,878] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Application report for application_1627517522169_0002 (state: ACCEPTED)
    >    INFO [2021-07-29 11:15:33,879] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Application report for application_1627517522169_0002 (state: ACCEPTED)
    >    INFO [2021-07-29 11:15:34,880] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Application report for application_1627517522169_0002 (state: ACCEPTED)
    >    ....

    #
    # Guess - is it waiting to free up resources held by RandomForest test ran last night ?
    #

    #
    # Test environment from last night is still active.
    # Try re-running the tests.
    #

# -----------------------------------------------------
# Run the HealpixSourceCounts notebook again.
#[user@desktop]

    notebook=2FKJ25GVF

    zepnbclear ${notebook}

    zepnbexecute ${notebook}

    zepnbstatus ${notebook}

    zepnbparatime ${notebook}

    zepnbtotaltime ${notebook}

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "/AglaisPublicExamples/Source counts over the sky",
    >       "id": "2FKJ25GVF",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {
    >         "md:shared_process": [],
    >         "sh:shared_process": [],
    >         "spark:gaiauser:": []
    >       },
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {}
    >     }
    >   }

    >   {
    >     "title": null,
    >     "result": "SUCCESS",
    >     "time": "0:0:0"
    >   }
    >   {
    >     "title": "Set the resolution level and define the query",
    >     "result": "SUCCESS",
    >     "time": "0:0:0"
    >   }
    >   {
    >     "title": "Plot up the results",
    >     "result": "SUCCESS",
    >     "time": "0:0:34"
    >   }
    >   {
    >     "title": "Further reading and resources",
    >     "result": "SUCCESS",
    >     "time": "0:0:0"
    >   }

    >   0:0:34


# -----------------------------------------------------
# Run the MeanProperMotions notebook again.
#[user@desktop]

    notebook=2G748GZSW

    zepnbclear ${notebook}

    zepnbexecute ${notebook}

    zepnbstatus ${notebook}

    zepnbparatime ${notebook}

    zepnbtotaltime ${notebook}


    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "AglaisPublicExamples/Mean proper motions over the sky",
    >       "id": "2G748GZSW",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {
    >         "md:shared_process": [],
    >         "sh:shared_process": [],
    >         "spark:gaiauser:": []
    >       },
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {}
    >     }
    >   }

    >   {
    >     "title": "Set HEALPix resolution",
    >     "result": "SUCCESS",
    >     "time": "0:0:0"
    >   }
    >   {
    >     "title": "Define a data frame by SQL query",
    >     "result": "SUCCESS",
    >     "time": "0:0:0"
    >   }
    >   {
    >     "title": "Mean RA proper motion plot",
    >     "result": "SUCCESS",
    >     "time": "0:1:29"
    >   }
    >   {
    >     "title": "Mean Dec proper motion plot",
    >     "result": "SUCCESS",
    >     "time": "0:0:1"
    >   }
    >   {
    >     "title": "Further reading and resources",
    >     "result": "SUCCESS",
    >     "time": "0:0:0"
    >   }

    >   0:1:31


# -----------------------------------------------------
# Run the RandomForest notebook again.
#[user@desktop]

    notebook=2G5NU6HTK

    zepnbclear ${notebook}

    zepnbexecute ${notebook}

    zepnbstatus ${notebook}

    zepnbparatime ${notebook}

    zepnbtotaltime ${notebook}



    >   ....
    >   ....




# -----------------------------------------------------
# -----------------------------------------------------
# Tunnel connection to the Spark and Grafana interfaces.
#[root@ansibler]

    ssh -f -N \
        -o 'ServerAliveInterval=20' \
        -L '3000:monitor:3000'  \
        -L '8088:master01:8088' \
        fedora@zeppelin


# -----------------------------------------------------
# -----------------------------------------------------
# Login via Firefox
#[user@desktop]

    firefox --new-window "http://localhost:8088/" &

    # Entry point for Hadoop cluster
    http://localhost:8088/cluster

    # Two applications.

    # My application, started last night at [Thu Jul 29 01:57:18 +0100 2021] is lited as [RUNNING]

        http://localhost:8088/cluster/app/application_1627517522169_0001

        http://master01:8088/proxy/application_1627517522169_0001
        http://localhost:8088/proxy/application_1627517522169_0001

            # Lots of info about the running jobs

    # Nigel's application started today at [Thu Jul 29 09:04:52 +0100 2021] is listed as [ACCEPTED]

        http://localhost:8088/cluster/app/application_1627517522169_0002

            [Thu Jul 29 08:04:52 +0000 2021]
                Application is Activated, waiting for resources to be assigned for AM.
                Details :
                    AM Partition = <DEFAULT_PARTITION> ;
                    Partition Resource = <memory:172032, vCores:52> ;
                    Queue's Absolute capacity = 100.0 % ;
                    Queue's Absolute used capacity = 95.91239 % ;
                    Queue's Absolute max capacity = 100.0 % ;
                    Queue's capacity (absolute resource) = <memory:172032, vCores:52> ;
                    Queue's used capacity (absolute resource) = <memory:165000, vCores:12> ;
                    Queue's max capacity (absolute resource) = <memory:172032, vCores:52> ;


        http://master01:8088/proxy/application_1627517522169_0002
        http://localhost:8088/proxy/application_1627517522169_0002

            # Redirects back to the application page



    # It looks like my test application reserved all the resorces and hasn't given them up.
    # Leaving nothing for Nigel's application to use.

    # Looking at the Spark job details
    # Executors were added at 00:57:30 and have been sitting idle waiting for work since then.
    # http://localhost:8088/proxy/application_1627517522169_0001/jobs/job/?id=79


    http://localhost:8088/proxy/application_1627517522169_0001/jobs/job/?id=79



# -----------------------------------------------------
# -----------------------------------------------------
# Tail the worker logs that is hosting the application master
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh worker02 \
                    "
                    lastapp=\$(
                        ls -1 /var/hadoop/logs/userlogs | tail -n 1
                        )

                    lastcont=\$(
                        ls -1 "/var/hadoop/logs/userlogs/\${lastapp}" | tail -n 1
                        )

                    tail -f /var/hadoop/logs/userlogs/\${lastapp}/\${lastcont}/stderr
                    "
            '


