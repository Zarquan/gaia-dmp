#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#


    Target:

        Test the latest version of the Atolmis client.
        New deployment on iris-gaia-green cloud.

    Result:

        Deployment works, with caveats ...
        (*) if SELinux is disabled on the host
        (*) if the host has the latest version of Fedora
        Not ready for use on desktop until we fix these issues


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.03.19 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudbase='arcus'
    cloudname='iris-gaia-green'
    configname='zeppelin-26.43-spark-6.26.43'


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}" \

    >   real    4m3.077s
    >   user    1m40.678s
    >   sys     0m9.470s


# -----------------------------------------------------
# Create everything, using the new config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
        | tee /tmp/create-all.log

    >   ....
    >   ....
    >
    >   PLAY [Install our public ssh keys] ..
    >   ERROR! Unexpected Exception, this is probably a bug: can't start new thread
    >   the full traceback was:
    >
    >   Traceback (most recent call last):
    >     File "/usr/bin/ansible-playbook", line 128, in <module>
    >       exit_code = cli.run()
    >     File "/usr/lib/python3.10/site-packages/ansible/cli/playbook.py", line 137, in run
    >       results = pbex.run()
    >     File "/usr/lib/python3.10/site-packages/ansible/executor/playbook_executor.py", line 190, in run
    >       result = self._tqm.run(play=play)
    >     File "/usr/lib/python3.10/site-packages/ansible/executor/task_queue_manager.py", line 297, in run
    >       strategy = strategy_loader.get(new_play.strategy, self)
    >     File "/usr/lib/python3.10/site-packages/ansible/plugins/loader.py", line 807, in get
    >       return self.get_with_context(name, *args, **kwargs).object
    >     File "/usr/lib/python3.10/site-packages/ansible/plugins/loader.py", line 853, in get_with_context
    >       obj.__init__(instance, *args, **kwargs)
    >     File "/usr/lib/python3.10/site-packages/ansible/plugins/strategy/__init__.py", line 233, in __init__
    >       self._results_thread.start()
    >     File "/usr/lib64/python3.10/threading.py", line 928, in start
    >       _start_new_thread(self._bootstrap, ())
    >   RuntimeError: can't start new thread


    #
    # OK, got to be joking.
    # How can anything this bad get shipped !!
    #

    #
    # OK, is this the same issue with 'crun' from inside a container ?
    # Try launch the build from tyrosine instead ...
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Checkout a copy on Tyrosine
#[user@tyrosine]

    cat > "${HOME:?}/aglais.env" << 'EOF'
source "${HOME:?}/projects.env"
AGLAIS_REPO='git@github.com:Zarquan/aglais.git'
AGLAIS_HOME="${PROJECTS_ROOT:?}/WFAU/aglais"
AGLAIS_CODE="${AGLAIS_HOME:?}/github-zrq"
EOF


    source "${HOME:?}/aglais.env"
    mkdir -p "${AGLAIS_HOME}"
    pushd "${AGLAIS_HOME}"

        git clone "${AGLAIS_REPO:?}" "$(basename ${AGLAIS_CODE:?})"

    popd

    >   Cloning into 'github-zrq'...
    >   remote: Enumerating objects: 10958, done.
    >   remote: Counting objects: 100% (4376/4376), done.
    >   remote: Compressing objects: 100% (2287/2287), done.
    >   remote: Total 10958 (delta 2551), reused 3514 (delta 1937), pack-reused 6582
    >   Receiving objects: 100% (10958/10958), 4.32 MiB | 5.43 MiB/s, done.
    >   Resolving deltas: 100% (6277/6277), done.


    pushd "${AGLAIS_CODE}"

        git checkout 20220211-zrq-infra-ops

    popd

# -----------------------------------------------------
# Create a container to work with.
#[user@tyrosine]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.03.19 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudbase='arcus'
    cloudname='iris-gaia-green'
    configname='zeppelin-26.43-spark-6.26.43'


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}" \

    >   real    1m4.861s
    >   user    0m36.589s
    >   sys     0m3.134s


# -----------------------------------------------------
# Create everything, using the new config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
        | tee /tmp/create-all.log

    >   ....
    >   PLAY [Install our public ssh keys] ..
    >
    >   TASK [Create our Openstack key pair] ..
    >   changed: [localhost]
    >   ....

        #
        # So, yes. The "can't start new thread" probably was caused by the 'crun' issue.
        # Running a recent container on an older platform causes [getaddrinfo() thread failed to start].
        # Isn't this what containerization was supposed to prevent ?
        #

        #
        # Still doesn't work though.
        # We get a different error - something wrong with ssh access.
        #

    >   ....
    >   TASK [Deploy [/etc/hosts] file to our gateway node] ..
    >   fatal: [zeppelin]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: Warning: Permanently added '128.232.222.142' (ED25519) to the list of known hosts.\r\nfedora@128.232.222.142: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).", "unreachable": true}
    >   ....

# -----------------------------------------------------
# Try ssh connection from inside the container.
#[root@ansibler]

    ssh -v fedora@128.232.222.142

    >   ....
    >   debug1: pubkey_prepare: ssh_get_authentication_socket: Permission denied
    >   ....

    #
    # Suspect this is something to do with the ssh agent.
    # We are trying to connect our container via a remote agent connection.
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Try ssh connection from outside the container.
#[user@tyrosine]

    echo ${SSH_AUTH_SOCK}

    >   /tmp/ssh-XXXXNVEDk5/agent.159215


    ls -al "${SSH_AUTH_SOCK}"

    >   srwxr-xr-x. 1 Zarquan Zarquan 0 Mar 19 17:51 /tmp/ssh-XXXXNVEDk5/agent.159215


    ssh fedora@128.232.222.142 \
        '
        date
        hostname
        '

    >   Sat 19 Mar 23:52:53 UTC 2022
    >   iris-gaia-green-20220319-zeppelin



# -----------------------------------------------------
# -----------------------------------------------------
# Try ssh connection from inside the container.
#[user@tyrosine]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.03.19 \
        bash


    ssh fedora@128.232.222.142 \
        '
        date
        hostname
        '

    >   fedora@128.232.222.142: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).


    ssh -v fedora@128.232.222.142 \
        '
        date
        hostname
        '

    >   ....
    >   debug1: pubkey_prepare: ssh_get_authentication_socket: Permission denied
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Disable SELinux on the host.
#[user@tyrosine]

    sudo setenforce Permissive


# -----------------------------------------------------
# -----------------------------------------------------
# Try ssh connection from inside the container.
#[root@ansibler]

    ssh fedora@128.232.222.142 \
        '
        date
        hostname
        '

    >   Sun Mar 20 00:08:18 UTC 2022
    >   iris-gaia-green-20220319-zeppelin

    #
    # The problem is SELinux on the host denying access to the ssh-agent socket from inside the container.
    # We could chase the SELinux permissions ..
    # ... later.
    #


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudbase='arcus'
    cloudname='iris-gaia-green'
    configname='zeppelin-26.43-spark-6.26.43'


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

    >   real    2m48.613s
    >   user    1m21.113s
    >   sys     0m7.105s


# -----------------------------------------------------
# Create everything, using the new config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
        | tee /tmp/create-all.log

    >   ....
    >   ....
    >   ....
    >   ....
    >   Share [GEDR3-11932]
    >
    >   ---- ---- ----
    >   File [cephfs-mount.sh]
    >   Path [/deployments/hadoop-yarn/bin]
    >   Tree [/deployments]
    >   ---- ---- ----
    >   Inventory  [/deployments/hadoop-yarn/ansible/config/zeppelin-26.43-spark-6.26.43.yml]
    >   Cloud name [iris-gaia-data]
    >   Share name [aglais-data-gaia-edr3-11932]
    >   Mount path [/data/gaia/GEDR3_11932]
    >   Mount host [zeppelin:masters:workers]
    >   Mount mode [ro]
    >   ---- ---- ----
    >
    >   Target [iris-gaia-data][aglais-data-gaia-edr3-11932]
    >   Found  [5b1ff330-22f6-4bc7-bc03-529a55726c72]
    >   ----
    >   Ceph path [/volumes/_nogroup/1b80478c-e419-44d2-ac19-762543d385a4]
    >   Ceph size [540]
    >   ----
    >   Ceph node [10.4.200.9:6789]
    >   Ceph node [10.4.200.13:6789]
    >   Ceph node [10.4.200.17:6789]
    >   /deployments/hadoop-yarn/bin/cephfs-mount.sh: line 144: accessrule: parameter null or not set
    >   ----
    >   Ceph user []
    >   Ceph key  []
    >
    >   /deployments/hadoop-yarn/bin/cephfs-mount.sh: line 168: cephuser: parameter null or not set
    >   /deployments/hadoop-yarn/ansible /
    >   [WARNING]:  * Failed to parse /deployments/hadoop-
    >   yarn/ansible/config/zeppelin-26.43-spark-6.26.43.yml with auto plugin: no root
    >   'plugin' key found, '/deployments/hadoop-
    >   yarn/ansible/config/zeppelin-26.43-spark-6.26.43.yml' is not a valid YAML
    >   inventory plugin config file
    >   [WARNING]:  * Failed to parse /deployments/hadoop-
    >   yarn/ansible/config/zeppelin-26.43-spark-6.26.43.yml with yaml plugin: Invalid
    >   extra vars data supplied. '@/tmp/ceph-mount-vars.yml' could not be made into a
    >   dictionary
    >   [WARNING]:  * Failed to parse /deployments/hadoop-
    >   yarn/ansible/config/zeppelin-26.43-spark-6.26.43.yml with ini plugin: Invalid
    >   extra vars data supplied. '@/tmp/ceph-mount-vars.yml' could not be made into a
    >   dictionary
    >   [WARNING]: Unable to parse /deployments/hadoop-
    >   yarn/ansible/config/zeppelin-26.43-spark-6.26.43.yml as an inventory source
    >   [WARNING]: No inventory was parsed, only implicit localhost is available
    >   ERROR! Invalid extra vars data supplied. '@/tmp/ceph-mount-vars.yml' could not be made into a dictionary
    >   usage: ansible-playbook [-h] [--version] [-v] [--private-key PRIVATE_KEY_FILE]
    >                           [-u REMOTE_USER] [-c CONNECTION] [-T TIMEOUT]
    >                           [--ssh-common-args SSH_COMMON_ARGS]
    >                           [--sftp-extra-args SFTP_EXTRA_ARGS]
    >                           [--scp-extra-args SCP_EXTRA_ARGS]
    >                           [--ssh-extra-args SSH_EXTRA_ARGS]
    >                           [-k | --connection-password-file CONNECTION_PASSWORD_FILE]
    >   ....

# -----------------------------------------------------
# -----------------------------------------------------
# Manually stepping through the commands in cephfs-mount.sh.
#[root@ansibler]

    export OS_SHARE_API_VERSION=2.46

    sharename=aglais-data-gaia-dr2-6514
    sharecloud=iris-gaia-data

    sharefile="/tmp/${sharename:?}-share.json"
    accessfile="/tmp/${sharename:?}-access.json"

# -----------------------------------------------------
# Identify the Manila share.
#[root@ansibler]

    echo "Target [${sharecloud}][${sharename}]"

    shareid=$(
        openstack \
            --os-cloud "${sharecloud:?}" \
            share list \
                --format json \
        | jq -r '.[] | select( .Name == "'${sharename:?}'") | .ID'
        )

    echo "Found  [${shareid}]"

    >   Target [iris-gaia-data][aglais-data-gaia-dr2-6514]
    >   Found  [1e1ed68a-e5fe-47a3-a663-7096231a9324]


# -----------------------------------------------------
# Get details of the Ceph export location.
#[root@ansibler]

    openstack \
        --os-cloud "${sharecloud:?}" \
        share show \
            --format json \
            "${shareid:?}" \
    | jq '.' \
    > "${sharefile:?}"

    locations=$(
        jq '.export_locations' "${sharefile:?}"
        )

    cephnodes=$(
        echo "${locations:?}" |
        sed '
            s/^.*path = \([^\\]*\).*$/\1/
            s/^\(.*\):\(\/.*\)$/\1/
            s/,/ /g
            '
            )

    cephpath=$(
        echo "${locations:?}" |
        sed '
            s/^.*path = \([^\\]*\).*$/\1/
            s/^\(.*\):\(\/.*\)$/\2/
            '
            )

    cephsize=$(
        jq '.size' "${sharefile:?}"
        )

    echo "----"
    echo "Ceph path [${cephpath}]"
    echo "Ceph size [${cephsize}]"

    echo "----"
    for cephnode in ${cephnodes}
    do
        echo "Ceph node [${cephnode}]"
    done

    >   ----
    >   Ceph path [/volumes/_nogroup/d6ce1262-7f83-4079-b364-befc1f166142]
    >   Ceph size [512]
    >   ----
    >   Ceph node [10.4.200.9:6789]
    >   Ceph node [10.4.200.13:6789]
    >   Ceph node [10.4.200.17:6789]


# -----------------------------------------------------
# Get details of the access rule.
#[root@ansibler]

    accessrule=$(
        openstack \
            --os-cloud "${sharecloud:?}" \
            share access list \
                --format json \
                "${shareid:?}" \
        | jq -r '.[] | select(.access_level == "'${mountmode:?}'") | .id'
        )

    openstack \
        --os-cloud "${sharecloud:?}" \
        share access show \
            --format json \
            "${accessrule:?}" \
    | jq '.' \
    > "${accessfile:?}"

    cephuser=$(
        jq -r '.access_to' "${accessfile:?}"
        )

    cephkey=$(
        jq -r '.access_key' "${accessfile:?}"
        )

    echo "----"
    echo "Ceph user [${cephuser}]"
    echo "Ceph key  [${cephkey}]"
    echo ""

    >   bash: accessrule: parameter null or not set
    >   ----
    >   Ceph user []
    >   Ceph key  []


# -----------------------------------------------------
# Get details of the access rule.
#[root@ansibler]

    openstack \
        --os-cloud "${sharecloud:?}" \
        share access list \
            --format json \
            "${shareid:?}"

    >   [
    >     {
    >       "ID": "c632721c-9744-4452-b8d9-73d9eb7eab78",
    >       "Access Type": "cephx",
    >       "Access To": "aglais-data-gaia-dr2-6514-rw",
    >       "Access Level": "rw",
    >       "State": "active",
    >       "Access Key": "AQBk99JhySPHFhAAREKtKW4CcCfhW40kf7wwtA==",
    >       "Created At": "2022-01-03T13:17:24.000000",
    >       "Updated At": "2022-01-03T13:17:24.000000"
    >     },
    >     {
    >       "ID": "d240ee4d-1c3d-4372-857b-2aa489e766f6",
    >       "Access Type": "cephx",
    >       "Access To": "aglais-data-gaia-dr2-6514-ro",
    >       "Access Level": "ro",
    >       "State": "active",
    >       "Access Key": "AQBh99JhHzrGAhAAGvetAfIssJzlfU7+dMhxYA==",
    >       "Created At": "2022-01-03T13:17:20.000000",
    >       "Updated At": "2022-01-03T13:17:21.000000"
    >     }
    >   ]

    #
    # This seems to work, ... but the element names don't match the JSON path select.
    #

    openstack \
        --os-cloud "${sharecloud:?}" \
        share access list \
            --format json \
            "${shareid:?}" \
    | jq -r '.[] | select(.access_level == "'${mountmode:?}'") | .id'

    >   -

    #
    # The element we are checking used to be called 'access_level', but now is called 'Access Level'.
    # The element we are selecting used to be called 'id', but now is called ''ID.
    #
    # WHAT MUPPET THOUGHT THIS WAS A GOOD IDEA !?
    #

    # Update the jq select statement with the new names, and it workd.

    openstack \
        --os-cloud "${sharecloud:?}" \
        share access list \
            --format json \
            "${shareid:?}" \
    | jq -r '.[] | select(."Access Level" == "'${mountmode:?}'") | .ID'

    >   d240ee4d-1c3d-4372-857b-2aa489e766f6

    # BUT, the changes only apply to one command.
    # The 'share access list' command outputs the 'new' style.

    openstack \
        --os-cloud "${sharecloud:?}" \
        share access list \
            --format json \
            "${shareid:?}"

    >   [
    >     {
    >       "ID": "c632721c-9744-4452-b8d9-73d9eb7eab78",
    >       "Access Type": "cephx",
    >       "Access To": "aglais-data-gaia-dr2-6514-rw",
    >       "Access Level": "rw",
    >       "State": "active",
    >       "Access Key": "AQBk99JhySPHFhAAREKtKW4CcCfhW40kf7wwtA==",
    >       "Created At": "2022-01-03T13:17:24.000000",
    >       "Updated At": "2022-01-03T13:17:24.000000"
    >     },
    >     {
    >       "ID": "d240ee4d-1c3d-4372-857b-2aa489e766f6",
    >       "Access Type": "cephx",
    >       "Access To": "aglais-data-gaia-dr2-6514-ro",
    >       "Access Level": "ro",
    >       "State": "active",
    >       "Access Key": "AQBh99JhHzrGAhAAGvetAfIssJzlfU7+dMhxYA==",
    >       "Created At": "2022-01-03T13:17:20.000000",
    >       "Updated At": "2022-01-03T13:17:21.000000"
    >     }
    >   ]


    # But the 'share access show' command still outputs the 'old' style.

    openstack \
        --os-cloud "${sharecloud:?}" \
        share access show \
            --format json \
            'c632721c-9744-4452-b8d9-73d9eb7eab78'

    >   {
    >     "id": "c632721c-9744-4452-b8d9-73d9eb7eab78",
    >     "share_id": "1e1ed68a-e5fe-47a3-a663-7096231a9324",
    >     "access_level": "rw",
    >     "access_to": "aglais-data-gaia-dr2-6514-rw",
    >     "access_type": "cephx",
    >     "state": "active",
    >     "access_key": "AQBk99JhySPHFhAAREKtKW4CcCfhW40kf7wwtA==",
    >     "created_at": "2022-01-03T13:17:24.000000",
    >     "updated_at": "2022-01-03T13:17:24.000000",
    >     "properties": ""
    >   }

    #
    # Seriously - WHAT MUPPET THOUGHT THIS WAS A GOOD IDEA !?
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Create a container to work with.
#[user@tyrosine]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.03.19 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudbase='arcus'
    cloudname='iris-gaia-green'
    configname='zeppelin-26.43-spark-6.26.43'


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

    >   real    3m58.806s
    >   user    1m48.790s
    >   sys     0m9.396s


# -----------------------------------------------------
# Create everything, using the new config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
        | tee /tmp/create-all.log

    >   real    43m19.085s
    >   user    16m7.896s
    >   sys     3m55.434s


# -----------------------------------------------------
# Quick test with one user.
#[root@ansibler]

    numusers=1
    testlevel=quick

    concurrent=True
    testdate=$(date '+%Y%m%d-%H%M%S')

    time \
        /deployments/hadoop-yarn/bin/restart-zeppelin.sh

    time \
        /deployments/hadoop-yarn/bin/run-tests.sh \
            "${cloudname:?}"  \
            "${configname:?}" \
            "${testlevel:?}"  \
	        "${concurrent:?}" \
	        "${numusers:?}"  \
        | tee "/tmp/test-${testlevel:?}-${testdate:?}.log"

    >   real    3m56.916s
    >   user    2m11.428s
    >   sys     0m11.461s


    sed "
        1,3 d
        s/\"/#/g
        s/'\(-\{0,1\}[0-9.]\{1,\}\)'/\1/g
        s/:[[:space:]]*\([a-zA-Z]\{1,\}\)\([,}]\)/:'\1'\2/g
        s/:[[:space:]]*\([,}]\),/: ''\1/g
        s/'/\"/g
        " \
        '/tmp/test-result.json' \
    | jq '.' \
    | tee /tmp/test-${testlevel:?}-${testdate:?}.json

    #
    # Please fix the output to be real JSON !!
    #

    >   [
    >     {
    >       "SetUp": {
    >         "result": "PASS",
    >         "outputs": {
    >           "valid": "True"
    >         },
    >         "time": {
    >           "result": "FAST",
    >           "elapsed": 43.45,
    >           "expected": 45.00,
    >           "percent": -3.45,
    >           "start": "2022-03-20T02:56:06.569751",
    >           "finish": "2022-03-20T02:56:50.016222"
    >         },
    >         "logs": ""
    >       },
    >       "Mean_proper_motions_over_the_sky": {
    >         "result": "PASS",
    >         "outputs": {
    >           "valid": "True"
    >         },
    >         "time": {
    >           "result": "FAST",
    >           "elapsed": 48.94,
    >           "expected": 55.00,
    >           "percent": -11.02,
    >           "start": "2022-03-20T02:56:50.016645",
    >           "finish": "2022-03-20T02:57:38.956885"
    >         },
    >         "logs": ""
    >       },
    >       "Source_counts_over_the_sky.json": {
    >         "result": "PASS",
    >         "outputs": {
    >           "valid": "True"
    >         },
    >         "time": {
    >           "result": "FAST",
    >           "elapsed": 17.18,
    >           "expected": 22.00,
    >           "percent": -21.90,
    >           "start": "2022-03-20T02:57:38.961045",
    >           "finish": "2022-03-20T02:57:56.143088"
    >         },
    >         "logs": ""
    >       },
    >       "Library_Validation.json": {
    >         "result": "ERROR",
    >         "outputs": {
    >           "valid": "True"
    >         },
    >         "time": {
    >           "result": "FAST",
    >           "elapsed": 8.04,
    >           "expected": 60.00,
    >           "percent": -86.60,
    >           "start": "2022-03-20T02:57:56.144580",
    >           "finish": "2022-03-20T02:58:04.181636"
    >         },
    >         "logs": "Fail to execute line 2: assert spark.conf.get(#spark.sql.execution.arrow.pyspark.enabled#) == \"true\"\nTraceback (most recent call last):\n  File #/tmp/1647744999253-0/zeppelin_python.py#, line 158, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File #<stdin>#, line 2, in <module>\nAssertionError"
    >       }
    >     }
    >   ]

    #
    # OK, this is because the test library has been updated to expect Apache Arrow to be installed,
    # but the merge to actually include Apache Arrow has not been included yet.
    # In which case, we shouldn't have accepted the change to Aglais that moved to a new version of the tests
    # until the changes the tests were checking for had been accepted in Aglais itself.
    # Bad change management.
    #


# -----------------------------------------------------
# Check DNS tools work.
#[root@ansibler]

    dig "${cloudname:?}.duckdns.org"

    >   ;; ANSWER SECTION:
    >   iris-gaia-green.duckdns.org. 60	IN	A	128.232.222.221


