#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2023, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Initial bootstrap K8s cluster from nothing.

    Result:

        Failed to associate floating IP 128.232.226.227 with loadbalancer vip_port_id, port not found.

    References:

# -----------------------------------------------------
# Check which platform is live.
#[user@desktop]

    ssh fedora@live.gaia-dmp.uk \
        '
        date
        hostname
        '

    >   Fri 14 Apr 15:33:12 UTC 2023
    >   iris-gaia-green-20230308-zeppelin


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    #
    # Live is green, selecting red for the deployment.
    #

    source "${HOME:?}/aglais.env"

    agcolour=red

    clientname=ansibler-${agcolour}
    cloudname=iris-gaia-${agcolour}

    podman run \
        --rm \
        --tty \
        --interactive \
        --name     "${clientname:?}" \
        --hostname "${clientname:?}" \
        --env "cloudname=${cloudname:?}" \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK:?}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.07.25 \
        bash

    >   ....
    >   ....


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

    >   real    3m11.633s
    >   user    1m23.681s
    >   sys     0m8.970s


# -----------------------------------------------------
# Add YAML editor role to our client container.
#[root@ansibler]

    ansible-galaxy install kwoodson.yedit

    >   Starting galaxy role install process
    >   - downloading role 'yedit', owned by kwoodson
    >   - downloading role from https://github.com/kwoodson/ansible-role-yedit/archive/master.tar.gz
    >   - extracting kwoodson.yedit to /root/.ansible/roles/kwoodson.yedit
    >   - kwoodson.yedit (master) was installed successfully


# -----------------------------------------------------
# Create our deployment settings.
#[root@ansibler]

    deployname=${cloudname:?}-$(date '+%Y%m%d')
    deploydate=$(date '+%Y%m%dT%H%M%S')

    statusyml='/opt/aglais/aglais-status.yml'
    if [ ! -e "$(dirname ${statusyml})" ]
    then
        mkdir "$(dirname ${statusyml})"
    fi
    rm -f "${statusyml}"
    touch "${statusyml}"

    yq eval \
        --inplace \
        "
        .aglais.deployment.type = \"cluster-api\"   |
        .aglais.deployment.name = \"${deployname}\" |
        .aglais.deployment.date = \"${deploydate}\" |
        .aglais.openstack.cloud.name = \"${cloudname}\"
        " "${statusyml}"


    cat /opt/aglais/aglais-status.yml

    >   aglais:
    >     deployment:
    >       type: cluster-api
    >       name: iris-gaia-red-20230414
    >       date: 20230414T153958
    >     openstack:
    >       cloud:
    >         name: iris-gaia-red


# -----------------------------------------------------
# Create our bootstrap components.
#[root@ansibler]

    inventory=/deployments/cluster-api/bootstrap/ansible/config/inventory.yml

    ansible-playbook \
        --inventory "${inventory:?}" \
        '/deployments/cluster-api/bootstrap/ansible/01-create-keypair.yml'

    ansible-playbook \
        --inventory "${inventory:?}" \
        '/deployments/cluster-api/bootstrap/ansible/02-create-network.yml'

    ansible-playbook \
        --inventory "${inventory:?}" \
        '/deployments/cluster-api/bootstrap/ansible/03-create-bootstrap.yml'

    ansible-playbook \
        --inventory "${inventory:?}" \
        '/deployments/cluster-api/bootstrap/ansible/04-local-config.yml'

    >   ....
    >   ....
    >   PLAY RECAP ********************************************************************************************************************************
    >   localhost                  : ok=2    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   ....
    >   ....
    >   PLAY RECAP ********************************************************************************************************************************
    >   localhost                  : ok=4    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   ....
    >   ....
    >   PLAY RECAP ********************************************************************************************************************************
    >   localhost                  : ok=7    changed=6    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   ....
    >   ....
    >   PLAY RECAP ********************************************************************************************************************************
    >   localhost                  : ok=4    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


# -----------------------------------------------------
# Check our local config.
#[root@ansibler]

    cat /opt/aglais/aglais-status.yml

    >   aglais:
    >     deployment:
    >       date: 20230414T153958
    >       name: iris-gaia-red-20230414
    >       type: cluster-api
    >     openstack:
    >       cloud:
    >         name: iris-gaia-red
    >       keypairs:
    >         team:
    >           fingerprint: 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16
    >           id: iris-gaia-red-20230414-keypair
    >           name: iris-gaia-red-20230414-keypair
    >       networks:
    >         internal:
    >           network:
    >             id: 9b3c1b17-e4ab-4fdd-b028-512a82cb25b4
    >             name: iris-gaia-red-20230414-internal-network
    >           router:
    >             id: bf881db4-5a4c-41ba-8f94-6d960caa47f0
    >             name: iris-gaia-red-20230414-internal-router
    >           subnet:
    >             cidr: 10.10.0.0/16
    >             id: 91d30420-8b92-43c5-b07f-cc91f11cdf93
    >             name: iris-gaia-red-20230414-internal-subnet
    >       servers:
    >         bootstrap:
    >           float:
    >             external: 128.232.226.169
    >             id: dbd87329-d3b8-4f36-b212-6a33a1c88074
    >             internal: 10.10.2.69
    >           server:
    >             address:
    >               ipv4: 10.10.2.69
    >             flavor:
    >               name: gaia.vm.cclake.2vcpu
    >             hostname: bootstrap
    >             id: 288921e8-59f4-4159-a051-6ac8c7db711f
    >             image:
    >               id: e5c23082-cc34-4213-ad31-ff4684657691
    >               name: Fedora-34.1.2
    >             name: iris-gaia-red-20230414-bootstrap


# -----------------------------------------------------
# SSH test.
#[root@ansibler]

    ssh bootstrap \
        '
        date
        hostname
        '

    >   Fri Apr 14 15:44:28 UTC 2023
    >   iris-gaia-red-20230414-bootstrap


# -----------------------------------------------------
# Transfer a copy of the config
#[root@ansibler]

    scp /opt/aglais/aglais-status.yml \
        bootstrap:/tmp/aglais-status.yml

    ssh bootstrap \
        '
        sudo mkdir -p /opt/aglais
        sudo mv /tmp/aglais-status.yml \
            /opt/aglais
        '


# -----------------------------------------------------
# -----------------------------------------------------
# Login to the bootstrap node as root.
#[user@desktop]

    podman exec \
        -it \
        ansibler-red \
            bash

        ssh bootstrap

            sudo su -

    #
    # We could prefix everything with sudo, but it gets very boring.
    #

# -----------------------------------------------------
# Install Docker.
# https://docs.docker.com/engine/install/fedora/#install-using-the-repository
#[root@bootstrap]

    dnf -y install dnf-plugins-core

    dnf config-manager \
        --add-repo \
        https://download.docker.com/linux/fedora/docker-ce.repo

    >   ....
    >   ....
    >   Adding repo from: https://download.docker.com/linux/fedora/docker-ce.repo


    dnf install \
        -y \
        docker-ce \
        docker-ce-cli \
        containerd.io \
        docker-compose-plugin

    >   ....
    >   ....
    >   Installed:
    >     ....
    >     ....
    >     docker-ce-3:20.10.17-3.fc34.x86_64


# -----------------------------------------------------
# Start the Docker service.
#[root@bootstrap]

    systemctl enable docker

    systemctl start docker

    systemctl status docker --no-pager

    >   ● docker.service - Docker Application Container Engine
    >        Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)
    >        Active: active (running) since Fri 2023-04-14 15:50:37 UTC; 1min 31s ago
    >   TriggeredBy: ● docker.socket
    >          Docs: https://docs.docker.com
    >      Main PID: 8625 (dockerd)
    >         Tasks: 8
    >        Memory: 29.2M
    >           CPU: 203ms
    >        CGroup: /system.slice/docker.service
    >                └─8625 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
    >
    >   Apr 14 15:50:36 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:36.961417567Z" level=info msg="scheme \"unix…le=grpc
    >   Apr 14 15:50:36 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:36.961437725Z" level=info msg="ccResolverWra…le=grpc
    >   Apr 14 15:50:36 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:36.961446937Z" level=info msg="ClientConn sw…le=grpc
    >   Apr 14 15:50:36 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:36.981912236Z" level=info msg="Loading conta…start."
    >   Apr 14 15:50:37 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:37.098094233Z" level=info msg="Default bridg…ddress"
    >   Apr 14 15:50:37 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:37.155880578Z" level=info msg="Loading conta… done."
    >   Apr 14 15:50:37 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:37.184992173Z" level=info msg="Docker daemon…0.10.17
    >   Apr 14 15:50:37 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:37.185520483Z" level=info msg="Daemon has co…zation"
    >   Apr 14 15:50:37 iris-gaia-red-20230414-bootstrap systemd[1]: Started Docker Application Container Engine.
    >   Apr 14 15:50:37 iris-gaia-red-20230414-bootstrap dockerd[8625]: time="2023-04-14T15:50:37.207960535Z" level=info msg="API listen on…r.sock"
    >   Hint: Some lines were ellipsized, use -l to show in full.


    docker --version

    >   Docker version 20.10.17, build 100c701


    docker info

    >   Client:
    >    Context:    default
    >    Debug Mode: false
    >    Plugins:
    >     app: Docker App (Docker Inc., v0.9.1-beta3)
    >     buildx: Docker Buildx (Docker Inc., v0.8.2-docker)
    >     compose: Docker Compose (Docker Inc., v2.6.0)
    >     scan: Docker Scan (Docker Inc., v0.17.0)
    >
    >   Server:
    >    Containers: 0
    >     Running: 0
    >     Paused: 0
    >     Stopped: 0
    >    Images: 0
    >    Server Version: 20.10.17
    >    Storage Driver: overlay2
    >     Backing Filesystem: extfs
    >     Supports d_type: true
    >     Native Overlay Diff: true
    >     userxattr: false
    >    Logging Driver: json-file
    >    Cgroup Driver: systemd
    >    Cgroup Version: 2
    >    Plugins:
    >     Volume: local
    >     Network: bridge host ipvlan macvlan null overlay
    >     Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
    >    Swarm: inactive
    >    Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux
    >    Default Runtime: runc
    >    Init Binary: docker-init
    >    containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1
    >    runc version: v1.1.2-0-ga916309
    >    init version: de40ad0
    >    Security Options:
    >     seccomp
    >      Profile: default
    >     cgroupns
    >    Kernel Version: 5.11.12-300.fc34.x86_64
    >    Operating System: Fedora 34 (Cloud Edition)
    >    OSType: linux
    >    Architecture: x86_64
    >    CPUs: 2
    >    Total Memory: 2.912GiB
    >    Name: iris-gaia-red-20230414-bootstrap
    >    ID: OT56:OUPK:TNGO:T4OZ:ILTB:NM7W:4HTE:ZFYI:INMH:A2MP:ALZG:TS4F
    >    Docker Root Dir: /var/lib/docker
    >    Debug Mode: false
    >    Registry: https://index.docker.io/v1/
    >    Labels:
    >    Experimental: false
    >    Insecure Registries:
    >     127.0.0.0/8
    >    Live Restore Enabled: false


# -----------------------------------------------------
# Install kubectl.
# https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#install-using-native-package-management
#[root@bootstrap]

    cat > '/etc/yum.repos.d/kubernetes.repo' << EOF
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

    dnf install -y 'kubectl'

    >   Installed:
    >     kubectl-1.27.0-0.x86_64


    kubectl version --output json

    >   {
    >     "clientVersion": {
    >       "major": "1",
    >       "minor": "27",
    >       "gitVersion": "v1.27.0",
    >       "gitCommit": "1b4df30b3cdfeaba6024e81e559a6cd09a089d65",
    >       "gitTreeState": "clean",
    >       "buildDate": "2023-04-11T17:10:18Z",
    >       "goVersion": "go1.20.3",
    >       "compiler": "gc",
    >       "platform": "linux/amd64"
    >     },
    >     "kustomizeVersion": "v5.0.1"
    >   }
    >   The connection to the server localhost:8080 was refused - did you specify the right host or port?


    kubectl config view

    >   apiVersion: v1
    >   clusters: null
    >   contexts: null
    >   current-context: ""
    >   kind: Config
    >   preferences: {}
    >   users: null


# -----------------------------------------------------
# Install kind on the bootstrap node.
# https://kind.sigs.k8s.io/docs/user/quick-start/#installing-from-release-binaries
#[root@bootstrap]

    kindversion=0.17.0
    kindbinary=kind-${kindversion:?}
    kindtemp=/tmp/${kindbinary:?}

    curl \
        --location \
        --no-progress-meter \
        --output "${kindtemp:?}" \
        "https://kind.sigs.k8s.io/dl/v${kindversion:?}/kind-linux-amd64"

    pushd /usr/local/bin
        mv "${kindtemp:?}" .
        chown 'root:root' "${kindbinary:?}"
        chmod 'u=rwx,g=rx,o=rx' "${kindbinary:?}"
        ln -s "${kindbinary:?}" 'kind'
    popd

    ls -al /usr/local/bin/

    >   ....
    >   lrwxrwxrwx.  1 root root      11 Apr 14 16:35 kind -> kind-0.17.0
    >   -rwxr-xr-x.  1 root root 6929103 Apr 14 16:35 kind-0.17.0
    >   ....


    kind --version

    >   kind version 0.17.0


# -----------------------------------------------------
# Install Helm on the bootstrap node.
# https://helm.sh/docs/intro/install/
# https://github.com/helm/helm/releases
#[root@bootstrap]

    helmarch=linux-amd64
    helmversion=3.11.2
    helmtarfile=helm-v${helmversion}-${helmarch}.tar.gz
    helmtmpfile=/tmp/${helmtarfile:?}
    helmbinary=helm-${helmversion:?}

    curl \
        --location \
        --no-progress-meter \
        --output "${helmtmpfile:?}" \
        "https://get.helm.sh/${helmtarfile:?}"

    tar \
        --gzip \
        --extract \
        --directory /tmp \
        --file "${helmtmpfile:?}"

    pushd /usr/local/bin
        mv "/tmp/${helmarch:?}/helm" "${helmbinary:?}"
        chown 'root:root' "${helmbinary:?}"
        chmod 'u=rwx,g=rx,o=rx' "${helmbinary:?}"
        ln -s "${helmbinary:?}" 'helm'
    popd

    ls -al /usr/local/bin/

    >   ....
    >   lrwxrwxrwx.  1 root root       11 Apr 14 16:37 helm -> helm-3.11.2
    >   -rwxr-xr-x.  1 root root 46874624 Mar  8 21:17 helm-3.11.2
    >   ....


    helm version

    >   version.BuildInfo
    >       {
    >       Version:"v3.11.2",
    >       GitCommit:"912ebc1cd10d38d340f048efaf0abda047c3468e",
    >       GitTreeState:"clean",
    >       GoVersion:"go1.18.10"
    >       }


# -----------------------------------------------------
# Install clusterctl
# The clusterctl CLI tool handles the lifecycle of a Cluster-API management cluster.
# https://cluster-api-openstack.sigs.k8s.io/getting-started.html#install-clusterctl
#[root@bootstrap]

    clusterctlversion=1.4.1
    clusterctlbinary=clusterctl-${clusterctlversion:?}

    curl \
        --location \
        --no-progress-meter \
        --output "/tmp/${clusterctlbinary:?}" \
        "https://github.com/kubernetes-sigs/cluster-api/releases/download/v${clusterctlversion:?}/clusterctl-linux-amd64"

    pushd /usr/local/bin
        mv "/tmp/${clusterctlbinary:?}" "${clusterctlbinary:?}"
        chown 'root:root' "${clusterctlbinary:?}"
        chmod 'u=rwx,g=rx,o=rx' "${clusterctlbinary:?}"
        ln -s "${clusterctlbinary:?}" 'clusterctl'
    popd

    ls -al /usr/local/bin/

    >   ....
    >   lrwxrwxrwx.  1 root root       16 Apr 14 16:44 clusterctl -> clusterctl-1.4.1
    >   -rwxr-xr-x.  1 root root 68700915 Apr 14 16:44 clusterctl-1.4.1
    >   ....


    clusterctl version

    >   clusterctl version: &version.Info
    >       {
    >       Major:"1",
    >       Minor:"4",
    >       GitVersion:"v1.4.1",
    >       GitCommit:"39d87e91080088327c738c43f39e46a7f557d03b",
    >       GitTreeState:"clean",
    >       BuildDate:"2023-04-04T17:31:43Z",
    >       GoVersion:"go1.19.6",
    >       Compiler:"gc",
    >       Platform:"linux/amd64"
    >       }


# -----------------------------------------------------
# Create our initial Kind cluster.
# https://github.com/kubernetes-sigs/kind/pull/2478#issuecomment-1214656908
#[root@bootstrap]

    kind create cluster --retain

    >   Creating cluster "kind" ...
    >    ✓ Ensuring node image (kindest/node:v1.25.3) 🖼
    >    ✓ Preparing nodes 📦
    >    ✓ Writing configuration 📜
    >    ✓ Starting control-plane 🕹️
    >    ✓ Installing CNI 🔌
    >    ✓ Installing StorageClass 💾
    >   Set kubectl context to "kind-kind"
    >   ....
    >   ....


    kubectl cluster-info --context kind-kind

    >   Kubernetes control plane is running at https://127.0.0.1:34807
    >   CoreDNS is running at https://127.0.0.1:34807/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
    >   ....


    kubectl get pods --all-namespaces

    >   NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE
    >   kube-system          coredns-565d847f94-9svb9                     1/1     Running   0          64s
    >   kube-system          coredns-565d847f94-tq89z                     1/1     Running   0          64s
    >   kube-system          etcd-kind-control-plane                      1/1     Running   0          80s
    >   kube-system          kindnet-kgv7c                                1/1     Running   0          64s
    >   kube-system          kube-apiserver-kind-control-plane            1/1     Running   0          80s
    >   kube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          80s
    >   kube-system          kube-proxy-sjt9w                             1/1     Running   0          64s
    >   kube-system          kube-scheduler-kind-control-plane            1/1     Running   0          81s
    >   local-path-storage   local-path-provisioner-684f458cdd-d8dmh      1/1     Running   0          64s


# -----------------------------------------------------
# Initialize the Openstack management cluster
# https://cluster-api-openstack.sigs.k8s.io/getting-started.html#initialization-for-common-providers
#[root@bootstrap]

    clusterctl init --infrastructure openstack

    >   Fetching providers
    >   Installing cert-manager Version="v1.11.0"
    >   Waiting for cert-manager to be available...
    >   Installing Provider="cluster-api" Version="v1.4.1" TargetNamespace="capi-system"
    >   Installing Provider="bootstrap-kubeadm" Version="v1.4.1" TargetNamespace="capi-kubeadm-bootstrap-system"
    >   Installing Provider="control-plane-kubeadm" Version="v1.4.1" TargetNamespace="capi-kubeadm-control-plane-system"
    >   Installing Provider="infrastructure-openstack" Version="v0.7.1" TargetNamespace="capo-system"
    >
    >   Your management cluster has been initialized successfully!
    >   ....
    >   ....


    kubectl get pods --all-namespaces

    >   NAMESPACE                           NAME                                                             READY   STATUS    RESTARTS   AGE
    >   capi-kubeadm-bootstrap-system       capi-kubeadm-bootstrap-controller-manager-8654485994-xkgpn       1/1     Running   0          3m11s
    >   capi-kubeadm-control-plane-system   capi-kubeadm-control-plane-controller-manager-5d9d9494d5-5mswx   1/1     Running   0          3m10s
    >   capi-system                         capi-controller-manager-746b4f5db4-qzdgj                         1/1     Running   0          3m12s
    >   capo-system                         capo-controller-manager-775d744795-zcjs4                         1/1     Running   0          3m7s
    >   cert-manager                        cert-manager-99bb69456-4ggrv                                     1/1     Running   0          3m35s
    >   cert-manager                        cert-manager-cainjector-ffb4747bb-qzc8l                          1/1     Running   0          3m35s
    >   cert-manager                        cert-manager-webhook-545bd5d7d8-xmqn2                            1/1     Running   0          3m35s
    >   kube-system                         coredns-565d847f94-9svb9                                         1/1     Running   0          4m59s
    >   kube-system                         coredns-565d847f94-tq89z                                         1/1     Running   0          4m59s
    >   kube-system                         etcd-kind-control-plane                                          1/1     Running   0          5m15s
    >   kube-system                         kindnet-kgv7c                                                    1/1     Running   0          4m59s
    >   kube-system                         kube-apiserver-kind-control-plane                                1/1     Running   0          5m15s
    >   kube-system                         kube-controller-manager-kind-control-plane                       1/1     Running   0          5m15s
    >   kube-system                         kube-proxy-sjt9w                                                 1/1     Running   0          4m59s
    >   kube-system                         kube-scheduler-kind-control-plane                                1/1     Running   0          5m16s
    >   local-path-storage                  local-path-provisioner-684f458cdd-d8dmh                          1/1     Running   0          4m59s


# -----------------------------------------------------
# -----------------------------------------------------
# List the available VM flavors and images.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        flavor list

    >   +--------------------------------------+-----------------------------+--------+------+-----------+-------+-----------+
    >   | ID                                   | Name                        |    RAM | Disk | Ephemeral | VCPUs | Is Public |
    >   +--------------------------------------+-----------------------------+--------+------+-----------+-------+-----------+
    >   | ....                                 | ....                        |   .... | .... |      .... |  .... | ....      |
    >   | 2e5dc624-1d3b-4da7-8107-cc2dd4cb5073 | vm.v1.large                 |  32768 |   60 |         0 |     8 | True      |
    >   | 698a8d46-eceb-4c55-91ff-38286bf9eabb | vm.v1.tiny                  |   1024 |   10 |         0 |     1 | True      |
    >   | 6b56d6e9-5397-4543-87fb-e0c0b6d47961 | vm.v1.small                 |  16384 |   20 |         0 |     4 | True      |
    >   | ....                                 | ....                        |   .... | .... |      .... |  .... | ....      |
    >   +--------------------------------------+-----------------------------+--------+------+-----------+-------+-----------+


    #
    # The ubuntu-2004-kube images are hidden with 'community' visibility.
    # https://wiki.openstack.org/wiki/Glance-v2-community-image-visibility-design
    #
    # We have uploaded our own copy of the ubuntu-2004-kube image.
    #

    openstack \
        --os-cloud "${cloudname:?}" \
        image list \
            --shared

    >   +--------------------------------------+-----------------------------------+--------+
    >   | ID                                   | Name                              | Status |
    >   +--------------------------------------+-----------------------------------+--------+
    >   | 686c415b-c5a6-419e-8c46-4732498582e8 | gaia-dmp-ubuntu-2004-kube-v1.25.4 | active |
    >   +--------------------------------------+-----------------------------------+--------+


    openstack \
        --os-cloud "${cloudname:?}" \
        availability zone list \
            --compute

    >   +-----------+-------------+
    >   | Zone Name | Zone Status |
    >   +-----------+-------------+
    >   | nova      | available   |
    >   +-----------+-------------+

    #
    # There is more than one external network, so we would have to filter to select the right one.
    openstack \
        --os-cloud "${cloudname:?}" \
        network list \
            --external

    >   +--------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
    >   | ID                                   | Name          | Subnets                                                                                                                                                |
    >   +--------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
    >   | 410920fb-5714-4447-b26a-e7b06092fc62 | cephfs        | 5699fb5d-8316-4b88-b889-b05c8a1ec975                                                                                                                   |
    >   | 57add367-d205-4030-a929-d75617a7c63e | CUDN-Internet | 1847b14d-b974-4f78-959d-44d18d4485b8, 3fcaa5a5-ba8e-49a9-bf94-d87fbb0afc42, 5f1388b3-a0c7-463e-bb58-5532c38e4b40, a79eb610-eca3-4ee8-aaf1-88f4fef5a4e7 |
    >   +--------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        keypair list

    >   +----------------------------------+-------------------------------------------------+------+
    >   | Name                             | Fingerprint                                     | Type |
    >   +----------------------------------+-------------------------------------------------+------+
    >   | iris-gaia-blue-20230209-keypair  | 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16 | ssh  |
    >   | iris-gaia-green-20230203-keypair | 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16 | ssh  |
    >   | iris-gaia-red-20230414-keypair   | 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16 | ssh  |
    >   +----------------------------------+-------------------------------------------------+------+


# -----------------------------------------------------
# Transfer the Openstack IDs to our bootstrap node.
#[root@ansibler]

    cat > /tmp/openstack-settings.env << 'EOF'
export OPENSTACK_CLOUD=iris-gaia-red-admin
export OPENSTACK_SSH_KEY_NAME=iris-gaia-red-20230414-keypair
export OPENSTACK_EXTERNAL_NETWORK_ID=57add367-d205-4030-a929-d75617a7c63e

export OPENSTACK_NODE_MACHINE_FLAVOR=vm.v1.large
export OPENSTACK_CONTROL_PLANE_MACHINE_FLAVOR=vm.v1.small

export KUBERNETES_VERSION=1.25.4
export OPENSTACK_IMAGE_NAME=gaia-dmp-ubuntu-2004-kube-v1.25.4

export OPENSTACK_FAILURE_DOMAIN=nova

#
# Use the Cambridge DNS servers.
# https://www.dns.cam.ac.uk/servers/rec.html
# export OPENSTACK_DNS_NAMESERVERS=131.111.8.42,131.111.12.20
# Only use one, using two addresses caused an error.
export OPENSTACK_DNS_NAMESERVERS=131.111.8.42

EOF

    scp \
        /tmp/openstack-settings.env \
        bootstrap:/tmp/openstack-settings.env

    ssh bootstrap \
        '
        sudo mkdir -p \
            /etc/aglais
        sudo install \
            /tmp/openstack-settings.env \
            /etc/aglais/openstack-settings.env
        '


# -----------------------------------------------------
# Transfer a copy of our clouds.yaml file.
#[root@ansibler]

    scp \
        /etc/openstack/clouds.yaml \
        bootstrap:/tmp/openstack-clouds.yaml

    ssh bootstrap \
        '
        sudo mkdir -p \
            /etc/aglais
        sudo install \
            /tmp/openstack-clouds.yaml \
            /etc/aglais/openstack-clouds.yaml
        '


# -----------------------------------------------------
# -----------------------------------------------------
# Install yq on the bootstrap node.
#[root@bootstrap]

    yqversion=4.33.3
    yqbinary=yq-${yqversion:?}

    curl \
        --location \
        --no-progress-meter \
        --output "/tmp/${yqbinary:?}" \
        "https://github.com/mikefarah/yq/releases/download/v${yqversion}/yq_linux_amd64"

    pushd /usr/local/bin
        mv "/tmp/${yqbinary:?}" "${yqbinary:?}"
        chown 'root:root' "${yqbinary:?}"
        chmod 'u=rwx,g=rx,o=rx' "${yqbinary:?}"
        ln -s "${yqbinary:?}" 'yq'
    popd

    ls -al /usr/local/bin/

    >   ....
    >   lrwxrwxrwx.  1 root root        9 Apr 14 17:04 yq -> yq-4.33.3
    >   -rwxr-xr-x.  1 root root  8839168 Apr 14 17:04 yq-4.33.3
    >   ....


    yq --version

    >   yq (https://github.com/mikefarah/yq/) version v4.33.3


# -----------------------------------------------------
# Edit our clouds.yaml file to disable TLS certificate checks.
# https://docs.openstack.org/os-client-config/latest/user/configuration.html#ssl-settings
#[root@bootstrap]

    vi /etc/aglais/openstack-clouds.yaml

          iris-gaia-red-admin:
            auth:
              auth_url: https://arcus.openstack.hpc.cam.ac.uk:5000
              ....
              ....
            region_name: "RegionOne"
            interface: "public"
            identity_api_version: 3
            auth_type: "v3applicationcredential"
       +    verify: false


# -----------------------------------------------------
# Load our Openstack settings.
#[root@bootstrap]

    source /etc/aglais/openstack-settings.env

cat << EOF
OPENSTACK_CLOUD [${OPENSTACK_CLOUD}]
OPENSTACK_IMAGE_NAME [${OPENSTACK_IMAGE_NAME}]
EOF

    >   OPENSTACK_CLOUD [iris-gaia-red-admin]
    >   OPENSTACK_IMAGE_NAME [gaia-dmp-ubuntu-2004-kube-v1.25.4]


# -----------------------------------------------------
# Use the script provided by cluster-api-provider-openstack to parse our clouds.yaml file.
# https://cluster-api-openstack.sigs.k8s.io/clusteropenstack/configuration.html#generate-credentials
# https://github.com/kubernetes-sigs/cluster-api-provider-openstack/blob/main/docs/book/src/clusteropenstack/configuration.md#generate-credentials
#[root@bootstrap]

    curl \
        --location \
        --no-progress-meter \
        --output '/tmp/env.rc' \
        'https://raw.githubusercontent.com/kubernetes-sigs/cluster-api-provider-openstack/master/templates/env.rc'

    source '/tmp/env.rc' '/etc/aglais/openstack-clouds.yaml' "${OPENSTACK_CLOUD:?}"

cat << EOF
OPENSTACK_CLOUD_YAML_B64   [${OPENSTACK_CLOUD_YAML_B64}]
OPENSTACK_CLOUD_CACERT_B64 [${OPENSTACK_CLOUD_CACERT_B64}]
OPENSTACK_CLOUD_PROVIDER_CONF_B64 [${OPENSTACK_CLOUD_PROVIDER_CONF_B64}]
EOF

    >   OPENSTACK_CLOUD_YAML_B64   [Y2xvdWRz....mYWxzZQo=]
    >   OPENSTACK_CLOUD_CACERT_B64 [Cg==]
    >   OPENSTACK_CLOUD_PROVIDER_CONF_B64 [W0dsb2Jh....xdTJ2Igo=]

# -----------------------------------------------------
# Generate our basic cluster config.
# https://cluster-api.sigs.k8s.io/clusterctl/commands/generate-cluster.html
# https://cluster-api-openstack.sigs.k8s.io/getting-started.html#generating-the-cluster-configuration
#[root@bootstrap]

    CLUSTER_NAME=green-frog

    clusterctl generate cluster \
        "${CLUSTER_NAME:?}" \
        --kubernetes-version "${KUBERNETES_VERSION:?}" \
        --control-plane-machine-count 3 \
        --worker-machine-count 3 \
    | tee "/tmp/${CLUSTER_NAME:?}.yaml"

    >   apiVersion: v1
    >   data:
    >     cacert: Cg==
    >     clouds.yaml: Y2xvdWRz....mYWxzZQo=
    >   kind: Secret
    >   metadata:
    >     labels:
    >       clusterctl.cluster.x-k8s.io/move: "true"
    >     name: green-frog-cloud-config
    >     namespace: default
    >   ....
    >   ....
    >   apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >   kind: OpenStackMachineTemplate
    >   metadata:
    >     name: green-frog-md-0
    >     namespace: default
    >   spec:
    >     template:
    >       spec:
    >         cloudName: iris-gaia-red-admin
    >         flavor: vm.v1.large
    >         identityRef:
    >           kind: Secret
    >           name: green-frog-cloud-config
    >         image: gaia-dmp-ubuntu-2004-kube-v1.25.4
    >         sshKeyName: iris-gaia-red-20230414-keypair


# -----------------------------------------------------
# Apply the basic cluster config.
# https://cluster-api.sigs.k8s.io/user/quick-start.html#apply-the-workload-cluster
#[root@bootstrap]

    kubectl apply \
        -f "/tmp/green-frog.yaml"

    >   secret/green-frog-cloud-config created
    >   kubeadmconfigtemplate.bootstrap.cluster.x-k8s.io/green-frog-md-0 created
    >   cluster.cluster.x-k8s.io/green-frog created
    >   machinedeployment.cluster.x-k8s.io/green-frog-md-0 created
    >   kubeadmcontrolplane.controlplane.cluster.x-k8s.io/green-frog-control-plane created
    >   openstackcluster.infrastructure.cluster.x-k8s.io/green-frog created
    >   openstackmachinetemplate.infrastructure.cluster.x-k8s.io/green-frog-control-plane created
    >   openstackmachinetemplate.infrastructure.cluster.x-k8s.io/green-frog-md-0 created


    kubectl get cluster

    >   NAME         PHASE          AGE   VERSION
    >   green-frog   Provisioning   11s


    clusterctl describe cluster 'green-frog'

    >   NAME                                                           READY  SEVERITY  REASON                           SINCE  MESSAGE
    >   Cluster/green-frog                                             False  Warning   ScalingUp                        20s    Scaling up control plane to 3 replicas (actual 0)
    >   ├─ClusterInfrastructure - OpenStackCluster/green-frog
    >   ├─ControlPlane - KubeadmControlPlane/green-frog-control-plane  False  Warning   ScalingUp                        20s    Scaling up control plane to 3 replicas (actual 0)
    >   └─Workers
    >     └─MachineDeployment/green-frog-md-0                          False  Warning   WaitingForAvailableMachines      21s    Minimum availability requires 3 replicas, current 0 available
    >       └─3 Machines...                                            False  Info      WaitingForClusterInfrastructure  20s    See green-frog-md-0-7b8fd887b6xg889c-64qpp, green-frog-md-0-7b8fd887b6xg889c-7vq9l, ...


    kubectl \
        --namespace capo-system \
        logs \
        -l control-plane=capo-controller-manager \
        -c manager \
        --follow

    >   ....
    >   ....
    >   I0414 17:11:37.931144       1 openstackcluster_controller.go:427] "Reconciling network components" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=75f5026c-1ba3-4711-82c9-9c0623025dc9 cluster="green-frog"
    >   I0414 17:11:38.400203       1 network.go:93] "Reconciling network" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=75f5026c-1ba3-4711-82c9-9c0623025dc9 cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog"
    >   I0414 17:11:38.606407       1 network.go:177] "Reconciling subnet" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=75f5026c-1ba3-4711-82c9-9c0623025dc9 cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog"
    >   I0414 17:11:38.670867       1 router.go:48] "Reconciling router" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=75f5026c-1ba3-4711-82c9-9c0623025dc9 cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog"
    >   I0414 17:11:38.938627       1 securitygroups.go:40] "Reconciling security groups" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=75f5026c-1ba3-4711-82c9-9c0623025dc9 cluster="default-green-frog"
    >   I0414 17:11:39.268434       1 loadbalancer.go:52] "Reconciling load balancer" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=75f5026c-1ba3-4711-82c9-9c0623025dc9 cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog-kubeapi"
    >   I0414 17:11:39.358764       1 loadbalancer.go:613] "Waiting for load balancer" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=75f5026c-1ba3-4711-82c9-9c0623025dc9 cluster="green-frog" id="11a1a868-277e-4025-b684-d3cdceeee2d4" targetStatus="ACTIVE"
    >   I0414 17:11:39.461896       1 recorder.go:103] "events: Failed to create floating IP : Expected HTTP response code [201 202] when accessing [POST https://arcus.openstack.hpc.cam.ac.uk:9696/v2.0/floatingips], but got 409 instead\n{\"NeutronError\": {\"type\": \"OverQuota\", \"message\": \"Quota exceeded for resources: ['floatingip'].\", \"detail\": \"\"}}" type="Warning" object={Kind:OpenStackCluster Namespace:default Name:green-frog UID:6c724fbf-589e-4dad-a4b0-7ff55981d791 APIVersion:infrastructure.cluster.x-k8s.io/v1alpha6 ResourceVersion:5158 FieldPath:} reason="Failedcreatefloatingip"
    >   E0414 17:11:39.472705       1 controller.go:326] "Reconciler error" err=<
    >   	failed to reconcile load balancer: Expected HTTP response code [201 202] when accessing [POST https://arcus.openstack.hpc.cam.ac.uk:9696/v2.0/floatingips], but got 409 instead
    >   	{"NeutronError": {"type": "OverQuota", "message": "Quota exceeded for resources: ['floatingip'].", "detail": ""}}
    >    > controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=75f5026c-1ba3-4711-82c9-9c0623025dc9

    #
    # Created lots of floating IP addresses and ran out of quota.
    #
    # Deleted al the floating IP addresses and left it running.
    # Manager created another floating IP address, but failed to connect it to a port.
    #

    >   I0414 17:22:02.670360       1 openstackcluster_controller.go:255] "Reconciling Cluster" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="green-frog"
    >   I0414 17:22:02.670908       1 openstackcluster_controller.go:427] "Reconciling network components" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="green-frog"
    >   I0414 17:22:03.186964       1 network.go:93] "Reconciling network" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog"
    >   I0414 17:22:03.331015       1 network.go:177] "Reconciling subnet" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog"
    >   I0414 17:22:03.394135       1 router.go:48] "Reconciling router" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog"
    >   I0414 17:22:03.848917       1 securitygroups.go:40] "Reconciling security groups" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="default-green-frog"
    >   I0414 17:22:04.306397       1 loadbalancer.go:52] "Reconciling load balancer" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog-kubeapi"
    >   I0414 17:22:04.382044       1 loadbalancer.go:613] "Waiting for load balancer" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="green-frog" id="11a1a868-277e-4025-b684-d3cdceeee2d4" targetStatus="ACTIVE"
    >
    >   I0414 17:22:04.563816       1 openstackmachine_controller.go:311] "Cluster infrastructure is not ready yet, requeuing machine" controller="openstackmachine" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackMachine" OpenStackMachine="default/green-frog-md-0-dxhzg" namespace="default" name="green-frog-md-0-dxhzg" reconcileID=d122b03a-c386-4e64-a84b-b61fb97c2030 openStackMachine="green-frog-md-0-dxhzg" machine="green-frog-md-0-7b8fd887b6xg889c-7vq9l" cluster="green-frog" openStackCluster="green-frog"
    >   I0414 17:22:04.824379       1 openstackmachine_controller.go:311] "Cluster infrastructure is not ready yet, requeuing machine" controller="openstackmachine" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackMachine" OpenStackMachine="default/green-frog-md-0-b59rn" namespace="default" name="green-frog-md-0-b59rn" reconcileID=d8a2c005-088d-4cf4-8a23-169cd0ceb07f openStackMachine="green-frog-md-0-b59rn" machine="green-frog-md-0-7b8fd887b6xg889c-wzmsw" cluster="green-frog" openStackCluster="green-frog"
    >   I0414 17:22:05.024330       1 openstackmachine_controller.go:311] "Cluster infrastructure is not ready yet, requeuing machine" controller="openstackmachine" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackMachine" OpenStackMachine="default/green-frog-md-0-ch7q5" namespace="default" name="green-frog-md-0-ch7q5" reconcileID=ed29dc35-f400-4238-a1fd-e9463c90fb88 openStackMachine="green-frog-md-0-ch7q5" machine="green-frog-md-0-7b8fd887b6xg889c-64qpp" cluster="green-frog" openStackCluster="green-frog"
    >
    >   I0414 17:22:06.670377       1 floatingip.go:124] "Associating floating IP" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7 cluster="green-frog" id="473c857f-6d04-4981-84fc-ec81a614b596" ip="128.232.226.113"
    >   I0414 17:22:06.670564       1 recorder.go:103] "events: Created floating IP 128.232.226.113 with id 473c857f-6d04-4981-84fc-ec81a614b596" type="Normal" object={Kind:OpenStackCluster Namespace:default Name:green-frog UID:6c724fbf-589e-4dad-a4b0-7ff55981d791 APIVersion:infrastructure.cluster.x-k8s.io/v1alpha6 ResourceVersion:5158 FieldPath:} reason="Successfulcreatefloatingip"
    >   I0414 17:22:06.836860       1 recorder.go:103] "events: Failed to associate floating IP 128.232.226.113 with port 351c250e-c560-4e4c-9f30-548ef253999c: Resource not found: [PUT https://arcus.openstack.hpc.cam.ac.uk:9696/v2.0/floatingips/473c857f-6d04-4981-84fc-ec81a614b596], error message: {\"NeutronError\": {\"type\": \"PortNotFound\", \"message\": \"Port 351c250e-c560-4e4c-9f30-548ef253999c could not be found.\", \"detail\": \"\"}}" type="Warning" object={Kind:OpenStackCluster Namespace:default Name:green-frog UID:6c724fbf-589e-4dad-a4b0-7ff55981d791 APIVersion:infrastructure.cluster.x-k8s.io/v1alpha6 ResourceVersion:5158 FieldPath:} reason="Failedassociatefloatingip"
    >
    >   E0414 17:22:06.844942       1 controller.go:326] "Reconciler error" err="failed to reconcile load balancer: Resource not found: [PUT https://arcus.openstack.hpc.cam.ac.uk:9696/v2.0/floatingips/473c857f-6d04-4981-84fc-ec81a614b596], error message: {\"NeutronError\": {\"type\": \"PortNotFound\", \"message\": \"Port 351c250e-c560-4e4c-9f30-548ef253999c could not be found.\", \"detail\": \"\"}}" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=e278e4f4-ca23-4b64-be79-7c2e446698f7
    >
    >   I0414 17:22:20.043838       1 openstackmachine_controller.go:311] "Cluster infrastructure is not ready yet, requeuing machine" controller="openstackmachine" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackMachine" OpenStackMachine="default/green-frog-md-0-dxhzg" namespace="default" name="green-frog-md-0-dxhzg" reconcileID=f6bb9f85-5326-48b2-ae75-4aa86f4f3dd0 openStackMachine="green-frog-md-0-dxhzg" machine="green-frog-md-0-7b8fd887b6xg889c-7vq9l" cluster="green-frog" openStackCluster="green-frog"

    #
    # Failing to find a port, can't associate the floating IP adress, so it stops, waits and tries again.
    # Gradually creating more floating IP addresses.
    #

# -----------------------------------------------------

    #
    # Repeat the deploy and watch the logs more closley.
    #

# -----------------------------------------------------
# Check our local config.
#[root@ansibler]

    cat /opt/aglais/aglais-status.yml

    >   aglais:
    >     deployment:
    >       date: 20230415T040135
    >       name: iris-gaia-red-20230415
    >       type: cluster-api
    >     openstack:
    >       cloud:
    >         name: iris-gaia-red
    >       keypairs:
    >         team:
    >           fingerprint: 2e:84:98:98:df:70:06:0e:4c:ed:bd:d4:d6:6b:eb:16
    >           id: iris-gaia-red-20230415-keypair
    >           name: iris-gaia-red-20230415-keypair
    >       networks:
    >         internal:
    >           network:
    >             id: 1616bf31-100b-4461-9754-0e9dad6d71ca
    >             name: iris-gaia-red-20230415-internal-network
    >           router:
    >             id: 7f1b6d68-e6bd-4165-81d6-4f8d075cebef
    >             name: iris-gaia-red-20230415-internal-router
    >           subnet:
    >             cidr: 10.10.0.0/16
    >             id: b9075723-3564-451a-9c0d-bc12dcef3238
    >             name: iris-gaia-red-20230415-internal-subnet
    >       servers:
    >         bootstrap:
    >           float:
    >             external: 128.232.227.37
    >             id: a9d85e74-c889-453d-bd36-b2f8b96b557d
    >             internal: 10.10.3.131
    >           server:
    >             address:
    >               ipv4: 10.10.3.131
    >             flavor:
    >               name: gaia.vm.cclake.2vcpu
    >             hostname: bootstrap
    >             id: a9e480fc-8818-45d0-955d-10d8278f0e7e
    >             image:
    >               id: e5c23082-cc34-4213-ad31-ff4684657691
    >               name: Fedora-34.1.2
    >             name: iris-gaia-red-20230415-bootstrap


# -----------------------------------------------------
# Generate our basic cluster config.
#[root@bootstrap]

    clusterctl generate cluster ....

    >   apiVersion: v1
    >   data:
    >     cacert: Cg==
    >     clouds.yaml: Y2xvdWRz....mYWxzZQo=
    >   kind: Secret
    >   metadata:
    >     labels:
    >       clusterctl.cluster.x-k8s.io/move: "true"
    >     name: green-frog-cloud-config
    >     namespace: default
    >   ---
    >   apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
    >   kind: KubeadmConfigTemplate
    >   metadata:
    >     name: green-frog-md-0
    >     namespace: default
    >   spec:
    >     template:
    >       spec:
    >         files:
    >         - content: W0dsb2Jh....xdTJ2Igo=
    >           encoding: base64
    >           owner: root
    >           path: /etc/kubernetes/cloud.conf
    >           permissions: "0600"
    >         - content: Cg==
    >           encoding: base64
    >           owner: root
    >           path: /etc/certs/cacert
    >           permissions: "0600"
    >         joinConfiguration:
    >           nodeRegistration:
    >             kubeletExtraArgs:
    >               cloud-config: /etc/kubernetes/cloud.conf
    >               cloud-provider: openstack
    >             name: '{{ local_hostname }}'
    >   ---
    >   apiVersion: cluster.x-k8s.io/v1beta1
    >   kind: Cluster
    >   metadata:
    >     name: green-frog
    >     namespace: default
    >   spec:
    >     clusterNetwork:
    >       pods:
    >         cidrBlocks:
    >         - 192.168.0.0/16
    >       serviceDomain: cluster.local
    >     controlPlaneRef:
    >       apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    >       kind: KubeadmControlPlane
    >       name: green-frog-control-plane
    >     infrastructureRef:
    >       apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >       kind: OpenStackCluster
    >       name: green-frog
    >   ---
    >   apiVersion: cluster.x-k8s.io/v1beta1
    >   kind: MachineDeployment
    >   metadata:
    >     name: green-frog-md-0
    >     namespace: default
    >   spec:
    >     clusterName: green-frog
    >     replicas: 3
    >     selector:
    >       matchLabels: null
    >     template:
    >       spec:
    >         bootstrap:
    >           configRef:
    >             apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
    >             kind: KubeadmConfigTemplate
    >             name: green-frog-md-0
    >         clusterName: green-frog
    >         failureDomain: nova
    >         infrastructureRef:
    >           apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >           kind: OpenStackMachineTemplate
    >           name: green-frog-md-0
    >         version: 1.25.4
    >   ---
    >   apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    >   kind: KubeadmControlPlane
    >   metadata:
    >     name: green-frog-control-plane
    >     namespace: default
    >   spec:
    >     kubeadmConfigSpec:
    >       clusterConfiguration:
    >         apiServer:
    >           extraArgs:
    >             cloud-config: /etc/kubernetes/cloud.conf
    >             cloud-provider: openstack
    >           extraVolumes:
    >           - hostPath: /etc/kubernetes/cloud.conf
    >             mountPath: /etc/kubernetes/cloud.conf
    >             name: cloud
    >             readOnly: true
    >         controllerManager:
    >           extraArgs:
    >             cloud-config: /etc/kubernetes/cloud.conf
    >             cloud-provider: openstack
    >           extraVolumes:
    >           - hostPath: /etc/kubernetes/cloud.conf
    >             mountPath: /etc/kubernetes/cloud.conf
    >             name: cloud
    >             readOnly: true
    >           - hostPath: /etc/certs/cacert
    >             mountPath: /etc/certs/cacert
    >             name: cacerts
    >             readOnly: true
    >       files:
    >       - content: W0dsb2Jh....xdTJ2Igo=
    >         encoding: base64
    >         owner: root
    >         path: /etc/kubernetes/cloud.conf
    >         permissions: "0600"
    >       - content: Cg==
    >         encoding: base64
    >         owner: root
    >         path: /etc/certs/cacert
    >         permissions: "0600"
    >       initConfiguration:
    >         nodeRegistration:
    >           kubeletExtraArgs:
    >             cloud-config: /etc/kubernetes/cloud.conf
    >             cloud-provider: openstack
    >           name: '{{ local_hostname }}'
    >       joinConfiguration:
    >         nodeRegistration:
    >           kubeletExtraArgs:
    >             cloud-config: /etc/kubernetes/cloud.conf
    >             cloud-provider: openstack
    >           name: '{{ local_hostname }}'
    >     machineTemplate:
    >       infrastructureRef:
    >         apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >         kind: OpenStackMachineTemplate
    >         name: green-frog-control-plane
    >     replicas: 3
    >     version: 1.25.4
    >   ---
    >   apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >   kind: OpenStackCluster
    >   metadata:
    >     name: green-frog
    >     namespace: default
    >   spec:
    >     apiServerLoadBalancer:
    >       enabled: true
    >     cloudName: iris-gaia-red-admin
    >     dnsNameservers:
    >     - 131.111.8.42
    >     externalNetworkId: 57add367-d205-4030-a929-d75617a7c63e
    >     identityRef:
    >       kind: Secret
    >       name: green-frog-cloud-config
    >     managedSecurityGroups: true
    >     nodeCidr: 10.6.0.0/24
    >   ---
    >   apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >   kind: OpenStackMachineTemplate
    >   metadata:
    >     name: green-frog-control-plane
    >     namespace: default
    >   spec:
    >     template:
    >       spec:
    >         cloudName: iris-gaia-red-admin
    >         flavor: vm.v1.small
    >         identityRef:
    >           kind: Secret
    >           name: green-frog-cloud-config
    >         image: gaia-dmp-ubuntu-2004-kube-v1.25.4
    >         sshKeyName: iris-gaia-red-20230414-keypair
    >   ---
    >   apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    >   kind: OpenStackMachineTemplate
    >   metadata:
    >     name: green-frog-md-0
    >     namespace: default
    >   spec:
    >     template:
    >       spec:
    >         cloudName: iris-gaia-red-admin
    >         flavor: vm.v1.large
    >         identityRef:
    >           kind: Secret
    >           name: green-frog-cloud-config
    >         image: gaia-dmp-ubuntu-2004-kube-v1.25.4
    >         sshKeyName: iris-gaia-red-20230414-keypair


# -----------------------------------------------------
# Check the logs ...
#[root@bootstrap]

    kubectl \
        --namespace capo-system \
        logs \
        -l control-plane=capo-controller-manager \
        -c manager \
        --follow

    >   ....
    >   I0415 04:25:15.558829       1 loadbalancer.go:52] "Reconciling load balancer" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" reconcileID=23312edb-29a0-4c99-9478-b26675a66c5d cluster="green-frog" name="k8s-clusterapi-cluster-default-green-frog-kubeapi"
    >   I0415 04:25:15.642154       1 loadbalancer.go:613] "Waiting for load balancer" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=23312edb-29a0-4c99-9478-b26675a66c5d cluster="green-frog" id="11a1a868-277e-4025-b684-d3cdceeee2d4" targetStatus="ACTIVE"
    >   I0415 04:25:17.503523       1 floatingip.go:124] "Associating floating IP" controller="openstackcluster" controllerGroup="infrastructure.cluster.x-k8s.io" controllerKind="OpenStackCluster" OpenStackCluster="default/green-frog" namespace="default" name="green-frog" reconcileID=23312edb-29a0-4c99-9478-b26675a66c5d cluster="green-frog" id="66115c96-fb5d-47a2-8e39-74f24138562a" ip="128.232.226.227"
    >   I0415 04:25:17.503795       1 recorder.go:103] "events: Created floating IP 128.232.226.227 with id 66115c96-fb5d-47a2-8e39-74f24138562a" type="Normal" object={Kind:OpenStackCluster Namespace:default Name:green-frog UID:a2ce5235-a90c-4bf8-b076-c4cd775cfdcf APIVersion:infrastructure.cluster.x-k8s.io/v1alpha6 ResourceVersion:3613 FieldPath:} reason="Successfulcreatefloatingip"
    >   I0415 04:25:17.669463       1 recorder.go:103] "events: Failed to associate floating IP 128.232.226.227 with port 351c250e-c560-4e4c-9f30-548ef253999c: Resource not found: [PUT https://arcus.openstack.hpc.cam.ac.uk:9696/v2.0/floatingips/66115c96-fb5d-47a2-8e39-74f24138562a], error message: {\"NeutronError\": {\"type\": \"PortNotFound\", \"message\": \"Port 351c250e-c560-4e4c-9f30-548ef253999c could not be found.\", \"detail\": \"\"}}" type="Warning" object={Kind:OpenStackCluster Namespace:default Name:green-frog UID:a2ce5235-a90c-4bf8-b076-c4cd775cfdcf APIVersion:infrastructure.cluster.x-k8s.io/v1alpha6 ResourceVersion:3613 FieldPath:} reason="Failedassociatefloatingip"
    >   ....


# -----------------------------------------------------
# Check the resources in Openstack.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        port list

    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+
    >   | ID                                   | Name | MAC Address       | Fixed IP Addresses                                                             | Status |
    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+
    >   | 12041957-1166-4172-951f-25b9fc1dcf28 |      | fa:16:3e:cb:3d:c9 | ip_address='128.232.226.68', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | 313ebc85-45d2-4359-b894-cf548af837f3 |      | fa:16:3e:1a:fc:f1 | ip_address='128.232.226.64', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | 3c01d97c-acae-468b-8b33-6bc6f08ed896 |      | fa:16:3e:69:4b:d8 | ip_address='10.10.3.131', subnet_id='b9075723-3564-451a-9c0d-bc12dcef3238'     | ACTIVE |
    >   | 3d2eeaff-7700-448f-a294-95b4d1abab82 |      | fa:16:3e:c3:4d:99 | ip_address='128.232.226.44', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | 42cfbe0a-76f3-4e87-b575-30adfe9d05c6 |      | fa:16:3e:4d:d7:87 | ip_address='10.10.0.1', subnet_id='b9075723-3564-451a-9c0d-bc12dcef3238'       | ACTIVE |
    >   | 445ad809-ef82-4cf7-8850-3a087caeb7dc |      | fa:16:3e:28:fd:b2 | ip_address='10.10.0.3', subnet_id='b9075723-3564-451a-9c0d-bc12dcef3238'       | ACTIVE |
    >   | 67cd76c1-56ab-4bcf-b6ed-a4846154939d |      | fa:16:3e:3d:24:07 | ip_address='128.232.226.227', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8' | N/A    |
    >   | 685cd0d7-baf3-4cc2-8e6b-26ad98dd6302 |      | fa:16:3e:ab:a6:37 | ip_address='10.6.0.1', subnet_id='58e796fd-4310-4c4c-ae0a-4ef96cbeaab5'        | ACTIVE |
    >   | 74f8fb82-076b-4903-8032-d6d4cbb553f4 |      | fa:16:3e:49:8e:46 | ip_address='128.232.227.34', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | 978d68e0-f13a-430b-a46a-70f534a5c19f |      | fa:16:3e:44:ba:ef | ip_address='128.232.227.37', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | b69a158a-4372-49b6-bfcd-c64b903abb5a |      | fa:16:3e:df:1a:2d | ip_address='10.6.0.3', subnet_id='58e796fd-4310-4c4c-ae0a-4ef96cbeaab5'        | ACTIVE |
    >   | dc5c39dd-06a1-46d2-90bc-ab14c807d4f6 |      | fa:16:3e:ea:86:25 | ip_address='10.10.0.2', subnet_id='b9075723-3564-451a-9c0d-bc12dcef3238'       | ACTIVE |
    >   | f6eaf970-10b4-4656-bf5c-9499f6b412b6 |      | fa:16:3e:b0:a8:bf | ip_address='10.6.0.2', subnet_id='58e796fd-4310-4c4c-ae0a-4ef96cbeaab5'        | ACTIVE |
    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+


    openstack \
        --os-cloud "${cloudname:?}" \
        router list

    >   +--------------------------------------+-------------------------------------------+--------+-------+----------------------------------+
    >   | ID                                   | Name                                      | Status | State | Project                          |
    >   +--------------------------------------+-------------------------------------------+--------+-------+----------------------------------+
    >   | 6734150c-5e4a-4033-909a-7f28d7117b2b | k8s-clusterapi-cluster-default-green-frog | ACTIVE | UP    | 0dd8cc5ee5a7455c8748cc06d04c93c3 |
    >   | 7f1b6d68-e6bd-4165-81d6-4f8d075cebef | iris-gaia-red-20230415-internal-router    | ACTIVE | UP    | 0dd8cc5ee5a7455c8748cc06d04c93c3 |
    >   +--------------------------------------+-------------------------------------------+--------+-------+----------------------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        router show \
            '6734150c-5e4a-4033-909a-7f28d7117b2b'

    >   +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
    >   | Field                   | Value                                                                                                                                                                                      |
    >   +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
    >   | admin_state_up          | UP                                                                                                                                                                                         |
    >   | availability_zone_hints |                                                                                                                                                                                            |
    >   | availability_zones      | nova                                                                                                                                                                                       |
    >   | created_at              | 2023-04-15T04:24:55Z                                                                                                                                                                       |
    >   | description             | Created by cluster-api-provider-openstack cluster default-green-frog                                                                                                                       |
    >   | external_gateway_info   | {"network_id": "57add367-d205-4030-a929-d75617a7c63e", "external_fixed_ips": [{"subnet_id": "1847b14d-b974-4f78-959d-44d18d4485b8", "ip_address": "128.232.227.59"}], "enable_snat": true} |
    >   | flavor_id               | None                                                                                                                                                                                       |
    >   | id                      | 6734150c-5e4a-4033-909a-7f28d7117b2b                                                                                                                                                       |
    >   | interfaces_info         | [{"port_id": "685cd0d7-baf3-4cc2-8e6b-26ad98dd6302", "ip_address": "10.6.0.1", "subnet_id": "58e796fd-4310-4c4c-ae0a-4ef96cbeaab5"}]                                                       |
    >   | name                    | k8s-clusterapi-cluster-default-green-frog                                                                                                                                                  |
    >   | project_id              | 0dd8cc5ee5a7455c8748cc06d04c93c3                                                                                                                                                           |
    >   | revision_number         | 9                                                                                                                                                                                          |
    >   | routes                  |                                                                                                                                                                                            |
    >   | status                  | ACTIVE                                                                                                                                                                                     |
    >   | tags                    |                                                                                                                                                                                            |
    >   | updated_at              | 2023-04-15T04:25:03Z                                                                                                                                                                       |
    >   +-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        loadbalancer list

    >   Policy does not allow this request to be performed. (HTTP 403) (Request-ID: req-0c3bdd3d-de04-46c9-8c51-cfc54c4e189c)


    openstack \
        --os-cloud "${cloudname:?}-admin" \
        loadbalancer list

    >   +--------------------------------------+---------------------------------------------------+----------------------------------+-------------+---------------------+------------------+----------+
    >   | id                                   | name                                              | project_id                       | vip_address | provisioning_status | operating_status | provider |
    >   +--------------------------------------+---------------------------------------------------+----------------------------------+-------------+---------------------+------------------+----------+
    >   | 11a1a868-277e-4025-b684-d3cdceeee2d4 | k8s-clusterapi-cluster-default-green-frog-kubeapi | 0dd8cc5ee5a7455c8748cc06d04c93c3 | 10.6.0.170  | ACTIVE              | ONLINE           | amphora  |
    >   +--------------------------------------+---------------------------------------------------+----------------------------------+-------------+---------------------+------------------+----------+


    openstack \
        --os-cloud "${cloudname:?}-admin" \
        loadbalancer show \
            '11a1a868-277e-4025-b684-d3cdceeee2d4'

    >   +---------------------+----------------------------------------------------------------------+
    >   | Field               | Value                                                                |
    >   +---------------------+----------------------------------------------------------------------+
    >   | admin_state_up      | True                                                                 |
    >   | availability_zone   | None                                                                 |
    >   | created_at          | 2023-04-13T14:14:53                                                  |
    >   | description         | Created by cluster-api-provider-openstack cluster default-green-frog |
    >   | flavor_id           | None                                                                 |
    >   | id                  | 11a1a868-277e-4025-b684-d3cdceeee2d4                                 |
    >   | listeners           | 886dc9e8-39a0-4197-a49c-f31412b2f84c                                 |
    >   | name                | k8s-clusterapi-cluster-default-green-frog-kubeapi                    |
    >   | operating_status    | ONLINE                                                               |
    >   | pools               | 551b031c-e89a-4aa5-a8b8-051f1be8a979                                 |
    >   | project_id          | 0dd8cc5ee5a7455c8748cc06d04c93c3                                     |
    >   | provider            | amphora                                                              |
    >   | provisioning_status | ACTIVE                                                               |
    >   | updated_at          | 2023-04-13T14:16:06                                                  |
    >   | vip_address         | 10.6.0.170                                                           |
    >   | vip_network_id      | ae30f196-30ef-44d1-81a3-081b8d0e571a                                 |
    >   | vip_port_id         | 351c250e-c560-4e4c-9f30-548ef253999c                                 |
    >   | vip_qos_policy_id   | None                                                                 |
    >   | vip_subnet_id       | b808096e-e564-471e-954d-c9991972a73d                                 |
    >   | tags                |                                                                      |
    >   +---------------------+----------------------------------------------------------------------+


    openstack \
        --os-cloud "${cloudname:?}-admin" \
        port list

    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+
    >   | ID                                   | Name | MAC Address       | Fixed IP Addresses                                                             | Status |
    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+
    >   | 12041957-1166-4172-951f-25b9fc1dcf28 |      | fa:16:3e:cb:3d:c9 | ip_address='128.232.226.68', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | 313ebc85-45d2-4359-b894-cf548af837f3 |      | fa:16:3e:1a:fc:f1 | ip_address='128.232.226.64', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | 3c01d97c-acae-468b-8b33-6bc6f08ed896 |      | fa:16:3e:69:4b:d8 | ip_address='10.10.3.131', subnet_id='b9075723-3564-451a-9c0d-bc12dcef3238'     | ACTIVE |
    >   | 3d2eeaff-7700-448f-a294-95b4d1abab82 |      | fa:16:3e:c3:4d:99 | ip_address='128.232.226.44', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | 42cfbe0a-76f3-4e87-b575-30adfe9d05c6 |      | fa:16:3e:4d:d7:87 | ip_address='10.10.0.1', subnet_id='b9075723-3564-451a-9c0d-bc12dcef3238'       | ACTIVE |
    >   | 445ad809-ef82-4cf7-8850-3a087caeb7dc |      | fa:16:3e:28:fd:b2 | ip_address='10.10.0.3', subnet_id='b9075723-3564-451a-9c0d-bc12dcef3238'       | ACTIVE |
    >   | 67cd76c1-56ab-4bcf-b6ed-a4846154939d |      | fa:16:3e:3d:24:07 | ip_address='128.232.226.227', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8' | N/A    |
    >   | 685cd0d7-baf3-4cc2-8e6b-26ad98dd6302 |      | fa:16:3e:ab:a6:37 | ip_address='10.6.0.1', subnet_id='58e796fd-4310-4c4c-ae0a-4ef96cbeaab5'        | ACTIVE |
    >   | 74f8fb82-076b-4903-8032-d6d4cbb553f4 |      | fa:16:3e:49:8e:46 | ip_address='128.232.227.34', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | 978d68e0-f13a-430b-a46a-70f534a5c19f |      | fa:16:3e:44:ba:ef | ip_address='128.232.227.37', subnet_id='1847b14d-b974-4f78-959d-44d18d4485b8'  | N/A    |
    >   | b69a158a-4372-49b6-bfcd-c64b903abb5a |      | fa:16:3e:df:1a:2d | ip_address='10.6.0.3', subnet_id='58e796fd-4310-4c4c-ae0a-4ef96cbeaab5'        | ACTIVE |
    >   | dc5c39dd-06a1-46d2-90bc-ab14c807d4f6 |      | fa:16:3e:ea:86:25 | ip_address='10.10.0.2', subnet_id='b9075723-3564-451a-9c0d-bc12dcef3238'       | ACTIVE |
    >   | f6eaf970-10b4-4656-bf5c-9499f6b412b6 |      | fa:16:3e:b0:a8:bf | ip_address='10.6.0.2', subnet_id='58e796fd-4310-4c4c-ae0a-4ef96cbeaab5'        | ACTIVE |
    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+


    openstack \
        --os-cloud "${cloudname:?}-admin" \
        subnet list

    >   +--------------------------------------+-------------------------------------------+--------------------------------------+--------------+
    >   | ID                                   | Name                                      | Network                              | Subnet       |
    >   +--------------------------------------+-------------------------------------------+--------------------------------------+--------------+
    >   | 5699fb5d-8316-4b88-b889-b05c8a1ec975 | cephfs                                    | 410920fb-5714-4447-b26a-e7b06092fc62 | 10.9.0.0/16  |
    >   | 58e796fd-4310-4c4c-ae0a-4ef96cbeaab5 | k8s-clusterapi-cluster-default-green-frog | b61bf731-0bb6-4a55-824b-6635252d84b7 | 10.6.0.0/24  |
    >   | b9075723-3564-451a-9c0d-bc12dcef3238 | iris-gaia-red-20230415-internal-subnet    | 1616bf31-100b-4461-9754-0e9dad6d71ca | 10.10.0.0/16 |
    >   +--------------------------------------+-------------------------------------------+--------------------------------------+--------------+


    #
    # The port in question is part of the load balancer.

    openstack \
        --os-cloud "${cloudname:?}-admin" \
        loadbalancer show \
            '11a1a868-277e-4025-b684-d3cdceeee2d4'

    >   +---------------------+----------------------------------------------------------------------+
    >   | Field               | Value                                                                |
    >   +---------------------+----------------------------------------------------------------------+
    >   | ....                | ....                                                                 |
    >   | vip_port_id         | 351c250e-c560-4e4c-9f30-548ef253999c                                 |
    >   | ....                | ....                                                                 |
    >   +---------------------+----------------------------------------------------------------------+
    >
    >       #
    >       # but the port isn't visible anywhere else
    >
    >       openstack \
    >           --os-cloud "${cloudname:?}-admin" \
    >           port list
    >
    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+
    >   | ID                                   | Name | MAC Address       | Fixed IP Addresses                                                             | Status |
    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+
    >   | ....                                 | .... | ....              | ....                                                                           |  ....  |
    >   +--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+
    >
    >
    >       #
    >       # The error occurs when Kubernetes tries to link the floating IP address to the loadbalancer.
    >
    >   ....
    >   I0415 04:25:17.503795       1 recorder.go:103] "events: Created floating IP 128.232.226.227 with id 66115c96-fb5d-47a2-8e39-74f24138562a" type="Normal" object={Kind:OpenStackCluster Namespace:default Name:green-frog UID:a2ce5235-a90c-4bf8-b076-c4cd775cfdcf APIVersion:infrastructure.cluster.x-k8s.io/v1alpha6 ResourceVersion:3613 FieldPath:} reason="Successfulcreatefloatingip"
    >   I0415 04:25:17.669463       1 recorder.go:103] "events: Failed to associate floating IP 128.232.226.227 with port 351c250e-c560-4e4c-9f30-548ef253999c: Resource not found: [PUT https://arcus.openstack.hpc.cam.ac.uk:9696/v2.0/floatingips/66115c96-fb5d-47a2-8e39-74f24138562a], error message: {\"NeutronError\": {\"type\": \"PortNotFound\", \"message\": \"Port 351c250e-c560-4e4c-9f30-548ef253999c could not be found.\", \"detail\": \"\"}}" type="Warning" object={Kind:OpenStackCluster Namespace:default Name:green-frog UID:a2ce5235-a90c-4bf8-b076-c4cd775cfdcf APIVersion:infrastructure.cluster.x-k8s.io/v1alpha6 ResourceVersion:3613 FieldPath:} reason="Failedassociatefloatingip"
    >   ....


    events: Failed to associate floating IP 128.232.226.227 with port 351c250e-c560-4e4c-9f30-548ef253999c:
    Resource not found: [
        PUT https://arcus.openstack.hpc.cam.ac.uk:9696/v2.0/floatingips/66115c96-fb5d-47a2-8e39-74f24138562a
        ],
    error message: {
        \"NeutronError\": {
            \"type\": \"PortNotFound\",
            \"message\": \"Port 351c250e-c560-4e4c-9f30-548ef253999c could not be found.\",
            \"detail\": \"\"
            }
        }"
    type="Warning"
    object={
        Kind:OpenStackCluster
        Namespace:default
        Name:green-frog UID:a2ce5235-a90c-4bf8-b076-c4cd775cfdcf
        APIVersion:infrastructure.cluster.x-k8s.io/v1alpha6
        ResourceVersion:3613
        FieldPath:
        }
    reason="Failedassociatefloatingip"

