#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#


    Target:

        Test a full deployment on the Arcus cloud ..

    Result:

        Work in progress ...


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2021.08.25 \
        bash


# -----------------------------------------------------
# Set the cloud and configuration.
#[root@ansibler]

    cloudname=iris-gaia-red

    configname=zeppelin-27.45-spark-6.27.45

# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}" \

    >   ....
    >   ....

# -----------------------------------------------------
# Create everything, using the new config.
# Using 'prod' to skip the built-in tests.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
            'prod' \
        | tee /tmp/create-all.log

    >   ....
    >   ....

    >   ....
    >   TASK [Creating CephFS fstab entry [/data/twomass/2MASSPSC]] ****************************************************************************************************
    >   fatal: [worker02]: FAILED! => {"changed": false, "msg": "Error mounting /data/twomass/2MASSPSC: mount error 22 = Invalid argument\n"}
    >   fatal: [worker01]: FAILED! => {"changed": false, "msg": "Error mounting /data/twomass/2MASSPSC: mount error 22 = Invalid argument\n"}
    >   fatal: [worker03]: FAILED! => {"changed": false, "msg": "Error mounting /data/twomass/2MASSPSC: mount error 22 = Invalid argument\n"}
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Check the cephfs network, router.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        network list

    >   +--------------------------------------+-----------------------------------------+--------------------------------------+
    >   | ID                                   | Name                                    | Subnets                              |
    >   +--------------------------------------+-----------------------------------------+--------------------------------------+
    >   | 410920fb-5714-4447-b26a-e7b06092fc62 | cephfs                                  | 5699fb5d-8316-4b88-b889-b05c8a1ec975 |
    >   | 57add367-d205-4030-a929-d75617a7c63e | CUDN-Internet                           | 3fcaa5a5-ba8e-49a9-bf94-d87fbb0afc42 |
    >   | a625dae5-3979-4583-a8ba-024126074f1e | iris-gaia-red-20220120-internal-network | 646e0318-084f-408d-9a20-5b82efaadd1c |
    >   +--------------------------------------+-----------------------------------------+--------------------------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        subnet list

    >   +--------------------------------------+----------------------------------------+--------------------------------------+--------------+
    >   | ID                                   | Name                                   | Network                              | Subnet       |
    >   +--------------------------------------+----------------------------------------+--------------------------------------+--------------+
    >   | 646e0318-084f-408d-9a20-5b82efaadd1c | iris-gaia-red-20220120-internal-subnet | a625dae5-3979-4583-a8ba-024126074f1e | 10.10.0.0/16 |
    >   +--------------------------------------+----------------------------------------+--------------------------------------+--------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        router list

    >   +--------------------------------------+----------------------------------------+--------+-------+----------------------------------+
    >   | ID                                   | Name                                   | Status | State | Project                          |
    >   +--------------------------------------+----------------------------------------+--------+-------+----------------------------------+
    >   | 4dfe5587-281f-4386-b082-05a4a6cbc2c8 | iris-gaia-red-20220120-internal-router | ACTIVE | UP    | 0dd8cc5ee5a7455c8748cc06d04c93c3 |
    >   | a346d974-4d51-4640-8185-e05dc3cbe332 | iris-gaia-red-20220120-cephfs-router   | ACTIVE | UP    | 0dd8cc5ee5a7455c8748cc06d04c93c3 |
    >   +--------------------------------------+----------------------------------------+--------+-------+----------------------------------+


# -----------------------------------------------------
# Get details for our main router.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        router show \
            --format json \
            4dfe5587-281f-4386-b082-05a4a6cbc2c8

    >   {
    >     "admin_state_up": true,
    >     "availability_zone_hints": [],
    >     "availability_zones": [
    >       "nova"
    >     ],
    >     "created_at": "2022-01-20T07:11:22Z",
    >     "description": "",
    >     "external_gateway_info": {
    >       "network_id": "57add367-d205-4030-a929-d75617a7c63e",
    >       "enable_snat": true,
    >       "external_fixed_ips": [
    >         {
    >           "subnet_id": "3fcaa5a5-ba8e-49a9-bf94-d87fbb0afc42",
    >           "ip_address": "128.232.222.25"
    >         }
    >       ]
    >     },
    >     "flavor_id": null,
    >     "id": "4dfe5587-281f-4386-b082-05a4a6cbc2c8",
    >     "interfaces_info": [
    >       {
    >         "port_id": "862adb35-47a3-4567-a902-1e2f9c529e2f",
    >         "ip_address": "10.10.0.1",
    >         "subnet_id": "646e0318-084f-408d-9a20-5b82efaadd1c"
    >       }
    >     ],
    >     "name": "iris-gaia-red-20220120-internal-router",
    >     "project_id": "0dd8cc5ee5a7455c8748cc06d04c93c3",
    >     "revision_number": 10,
    >     "routes": [
    >       {
    >         "nexthop": "10.10.3.203",
    >         "destination": "10.4.200.0/24"
    >       }
    >     ],
    >     "status": "ACTIVE",
    >     "tags": [],
    >     "updated_at": "2022-01-20T07:40:20Z"
    >   }


# -----------------------------------------------------
# Get details for our Ceph router.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        router show \
            --format json \
            a346d974-4d51-4640-8185-e05dc3cbe332

    >   {
    >     "admin_state_up": true,
    >     "availability_zone_hints": [],
    >     "availability_zones": [
    >       "nova"
    >     ],
    >     "created_at": "2022-01-20T07:39:39Z",
    >     "description": "",
    >     "external_gateway_info": {
    >       "network_id": "410920fb-5714-4447-b26a-e7b06092fc62",
    >       "enable_snat": true,
    >       "external_fixed_ips": [
    >         {
    >           "subnet_id": "5699fb5d-8316-4b88-b889-b05c8a1ec975",
    >           "ip_address": "10.9.1.129"
    >         }
    >       ]
    >     },
    >     "flavor_id": null,
    >     "id": "a346d974-4d51-4640-8185-e05dc3cbe332",
    >     "interfaces_info": [
    >       {
    >         "port_id": "4408fe3c-58b6-47b5-95c5-16e4ee804d39",
    >         "ip_address": "10.10.3.203",
    >         "subnet_id": "646e0318-084f-408d-9a20-5b82efaadd1c"
    >       }
    >     ],
    >     "name": "iris-gaia-red-20220120-cephfs-router",
    >     "project_id": "0dd8cc5ee5a7455c8748cc06d04c93c3",
    >     "revision_number": 10,
    >     "routes": [
    >       {
    >         "nexthop": "10.9.0.1",
    >         "destination": "10.4.200.0/24"
    >       }
    >     ],
    >     "status": "ACTIVE",
    >     "tags": [],
    >     "updated_at": "2022-01-20T07:40:29Z"
    >   }


# -----------------------------------------------------
# See if we can reach one of the CephFS server nodes.
#[root@ansibler]

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        ping -c 5 10.4.200.17
        '

    >   Thu Jan 20 13:09:19 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   PING 10.4.200.17 (10.4.200.17) 56(84) bytes of data.
    >   64 bytes from 10.4.200.17: icmp_seq=1 ttl=62 time=3.43 ms
    >   From 10.10.0.1 icmp_seq=2 Redirect Host(New nexthop: 203.3.10.10)
    >   64 bytes from 10.4.200.17: icmp_seq=2 ttl=62 time=0.701 ms
    >   From 10.10.0.1 icmp_seq=3 Redirect Host(New nexthop: 203.3.10.10)
    >   64 bytes from 10.4.200.17: icmp_seq=3 ttl=62 time=0.525 ms
    >
    >   --- 10.4.200.17 ping statistics ---
    >   3 packets transmitted, 3 received, +2 errors, 0% packet loss, time 2065ms
    >   rtt min/avg/max/mdev = 0.525/1.551/3.427/1.328 ms

    >   Thu Jan 20 13:09:53 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   PING 10.4.200.17 (10.4.200.17) 56(84) bytes of data.
    >   64 bytes from 10.4.200.17: icmp_seq=1 ttl=62 time=1.11 ms
    >   64 bytes from 10.4.200.17: icmp_seq=2 ttl=62 time=0.416 ms
    >   64 bytes from 10.4.200.17: icmp_seq=3 ttl=62 time=0.397 ms
    >   64 bytes from 10.4.200.17: icmp_seq=4 ttl=62 time=0.360 ms
    >   64 bytes from 10.4.200.17: icmp_seq=5 ttl=62 time=0.462 ms
    >
    >   --- 10.4.200.17 ping statistics ---
    >   5 packets transmitted, 5 received, 0% packet loss, time 4079ms
    >   rtt min/avg/max/mdev = 0.360/0.549/1.110/0.282 ms


# -----------------------------------------------------
# Check the share contents.
#[root@ansibler]

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        ls -al /data/twomass/2MASSPSC/
        echo "----"
        df -h  /data/twomass/2MASSPSC/
        '

    >   Thu Jan 20 13:14:17 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   total 8
    >   drwxr-xr-x. 2 root root 4096 Jan 20 07:44 .
    >   drwxr-xr-x. 3 root root 4096 Jan 20 07:44 ..
    >   ----
    >   Filesystem      Size  Used Avail Use% Mounted on
    >   /dev/vda1        20G  6.0G   13G  32% /


# -----------------------------------------------------
# Check the fstab entries.
#[root@ansibler]

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        cat /etc/fstab
        '

    >   Thu Jan 20 13:28:00 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   UUID=0e28d03c-9307-4c5c-b31e-7b0574239ccf /                       ext4    defaults        1 1
    >   /dev/vdb	/mnt	auto	defaults,nofail,comment=cloudconfig	0	2
    >   /dev/vdb /mnt/local/vdb ext4 defaults 0 0
    >   /dev/vdc /mnt/cinder/vdc btrfs defaults 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/d6ce1262-7f83-4079-b364-befc1f166142 /data/gaia/GDR2_6514 ceph name=aglais-data-gaia-dr2-6514-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/1b80478c-e419-44d2-ac19-762543d385a4 /data/gaia/GEDR3_11932 ceph name=aglais-data-gaia-edr3-11932-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/5e74d2f7-dba9-40aa-ab90-526c8d0d58e5 /data/gaia/GEDR3_2048 ceph name=aglais-data-gaia-edr3-2048-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/453a8d26-d896-48dc-8a12-dda8c2d41888 /data/gaia/GEDR3_4096 ceph name=aglais-data-gaia-edr3-4096-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/4754ffb6-5101-4cfe-a1ed-1f39cca340c5 /data/gaia/GEDR3_8192 ceph name=aglais-data-gaia-edr3-8192-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/c5b0aa15-6afa-4f73-a6b2-d5e94fed1b1b /data/wise/ALLWISE ceph name=aglais-data-wise-allwise-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/7bf5fe90-7902-4bed-92d9-c798866bb417 /data/panstarrs/PS1 ceph name=aglais-data-panstarrs-ps1-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/3d98f750-5bb8-4e4c-ba95-2b38c0f0ffd5 /data/twomass/2MASSPSC ceph name=aglais-data-twomass-allsky-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0


# -----------------------------------------------------
# Try mounting a share.
#[root@ansibler]

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        sudo mount /data/twomass/2MASSPSC
        '

    >   Thu Jan 20 13:30:26 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   mount error 22 = Invalid argument

    #
    # What links the fftab mount entry to the access key ?
    # There is no reference to the user account !?
    #


# -----------------------------------------------------
# Check our ceph config files.
#[root@ansibler]

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        ls -al /etc/ceph
        '

    >   Thu Jan 20 13:34:06 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   total 48
    >   drwxr-xr-x.  2 root root 4096 Jan 20 07:44 .
    >   drwxr-xr-x. 80 root root 4096 Jan 20 07:40 ..
    >   -rw-r--r--.  1 root root  147 Jan 20 07:41 ceph.client.aglais-data-gaia-dr2-6514-ro.keyring
    >   -rw-r--r--.  1 root root  149 Jan 20 07:41 ceph.client.aglais-data-gaia-edr3-11932-ro.keyring
    >   -rw-r--r--.  1 root root  148 Jan 20 07:42 ceph.client.aglais-data-gaia-edr3-2048-ro.keyring
    >   -rw-r--r--.  1 root root  148 Jan 20 07:42 ceph.client.aglais-data-gaia-edr3-4096-ro.keyring
    >   -rw-r--r--.  1 root root  148 Jan 20 07:43 ceph.client.aglais-data-gaia-edr3-8192-ro.keyring
    >   -rw-r--r--.  1 root root  147 Jan 20 07:43 ceph.client.aglais-data-panstarrs-ps1-ro.keyring
    >   -rw-r--r--.  1 root root  148 Jan 20 07:44 ceph.client.aglais-data-twomass-allsky-ro.keyring
    >   -rw-r--r--.  1 root root  146 Jan 20 07:43 ceph.client.aglais-data-wise-allwise-ro.keyring
    >   -rw-r--r--.  1 root root  156 Jan 20 07:41 ceph.conf
    >   -rw-r--r--.  1 root root   92 Oct 21 13:38 rbdmap


    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        cat /etc/ceph/ceph.conf
        '

    >   Thu Jan 20 13:34:38 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   # BEGIN ANSIBLE MANAGED BLOCK
    >   [client]
    >       client quota = true
    >       mon host = 10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789
    >   # END ANSIBLE MANAGED BLOCK


# -----------------------------------------------------
# Check our fstab entries.
#[root@ansibler]

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        tail -n 4 /etc/fstab
        '

    >   Thu Jan 20 13:46:46 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/4754ffb6-5101-4cfe-a1ed-1f39cca340c5 /data/gaia/GEDR3_8192 ceph name=aglais-data-gaia-edr3-8192-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/c5b0aa15-6afa-4f73-a6b2-d5e94fed1b1b /data/wise/ALLWISE ceph name=aglais-data-wise-allwise-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/7bf5fe90-7902-4bed-92d9-c798866bb417 /data/panstarrs/PS1 ceph name=aglais-data-panstarrs-ps1-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/3d98f750-5bb8-4e4c-ba95-2b38c0f0ffd5 /data/twomass/2MASSPSC ceph name=aglais-data-twomass-allsky-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0



    # One fstab entry

    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/3d98f750-5bb8-4e4c-ba95-2b38c0f0ffd5 /data/twomass/2MASSPSC ceph name=aglais-data-twomass-allsky-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0

    # contains node IP addresses

    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:....

    # remote path

    >   ....:/volumes/_nogroup/3d98f750-5bb8-4e4c-ba95-2b38c0f0ffd5 ....

    # local path

    >   .... /data/twomass/2MASSPSC ...

    # mount type

    >   .... ceph ....

    # mount options

    >   .... name=aglais-data-twomass-allsky-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0

    # the 'name' option identifies the ceph user id

    >   .... name=aglais-data-twomass-allsky-ro,....

    # which identifies the keyring file to use

# -----------------------------------------------------
# Check a chep keyring file.
#[root@ansibler]

    cephuser=aglais-data-twomass-allsky-ro

    ssh zeppelin \
        "
        date
        hostname
        echo "----"
        cat /etc/ceph/ceph.client.${cephuser:?}.keyring
        "

    >   Thu Jan 20 13:47:30 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   # BEGIN ANSIBLE MANAGED BLOCK
    >   [client.aglais-data-twomass-allsky-ro]
    >       key = AQCi99JhNSxPOhAApE+NkKfDlz5aL4x5GPvVkA==
    >   # END ANSIBLE MANAGED BLOCK

    #
    # In theory these could all be in one config file ?
    # Later ..
    #


# -----------------------------------------------------
# Check the cephfs network.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        network list

    >   +--------------------------------------+-----------------------------------------+--------------------------------------+
    >   | ID                                   | Name                                    | Subnets                              |
    >   +--------------------------------------+-----------------------------------------+--------------------------------------+
    >   | 410920fb-5714-4447-b26a-e7b06092fc62 | cephfs                                  | 5699fb5d-8316-4b88-b889-b05c8a1ec975 |
    >   | 57add367-d205-4030-a929-d75617a7c63e | CUDN-Internet                           | 3fcaa5a5-ba8e-49a9-bf94-d87fbb0afc42 |
    >   | a625dae5-3979-4583-a8ba-024126074f1e | iris-gaia-red-20220120-internal-network | 646e0318-084f-408d-9a20-5b82efaadd1c |
    >   +--------------------------------------+-----------------------------------------+--------------------------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        network show \
        410920fb-5714-4447-b26a-e7b06092fc62

    >   +---------------------------+--------------------------------------+
    >   | Field                     | Value                                |
    >   +---------------------------+--------------------------------------+
    >   | admin_state_up            | UP                                   |
    >   | availability_zone_hints   |                                      |
    >   | availability_zones        | nova                                 |
    >   | created_at                | 2020-02-20T22:38:27Z                 |
    >   | description               |                                      |
    >   | dns_domain                |                                      |
    >   | id                        | 410920fb-5714-4447-b26a-e7b06092fc62 |
    >   | ipv4_address_scope        | None                                 |
    >   | ipv6_address_scope        | None                                 |
    >   | is_default                | False                                |
    >   | is_vlan_transparent       | None                                 |
    >   | mtu                       | 1500                                 |
    >   | name                      | cephfs                               |
    >   | port_security_enabled     | True                                 |
    >   | project_id                | 6282a39cdfce49a7893312d3c965a2d4     |
    >   | provider:network_type     | None                                 |
    >   | provider:physical_network | None                                 |
    >   | provider:segmentation_id  | None                                 |
    >   | qos_policy_id             | None                                 |
    >   | revision_number           | 20                                   |
    >   | router:external           | External                             |
    >   | segments                  | None                                 |
    >   | shared                    | False                                |
    >   | status                    | ACTIVE                               |
    >   | subnets                   | 5699fb5d-8316-4b88-b889-b05c8a1ec975 |
    >   | tags                      |                                      |
    >   | updated_at                | 2022-01-14T16:31:23Z                 |
    >   +---------------------------+--------------------------------------+


    openstack \
        --os-cloud "${cloudname:?}" \
        subnet show \
        5699fb5d-8316-4b88-b889-b05c8a1ec975

    >   No Subnet found for 5699fb5d-8316-4b88-b889-b05c8a1ec975

    #
    # Is this because it is not public ?
    #



# -----------------------------------------------------
# Try the same on the cumulus cloud
#[root@ansibler]

    openstack \
        --os-cloud 'gaia-dev' \
        network list

    >   +--------------------------------------+------------------+----------------------------------------------------------------------------+
    >   | ID                                   | Name             | Subnets                                                                    |
    >   +--------------------------------------+------------------+----------------------------------------------------------------------------+
    >   | a929e8db-1bf4-4a5f-a80c-fabd39d06a26 | internet         | 180dc961-c52f-461a-b241-8f7a30d022a5, 273123bb-70f6-4f51-a406-7fc4b446532d |
    >   | ecb791d5-1022-447a-a79c-8f38a0f5c990 | cumulus-internal | 01b76c7c-3c1a-4c5c-9a5a-14bcf6c0c290                                       |
    >   +--------------------------------------+------------------+----------------------------------------------------------------------------+


    openstack \
        --os-cloud 'gaia-dev' \
        network show \
            ecb791d5-1022-447a-a79c-8f38a0f5c990

    >   +---------------------------+--------------------------------------+
    >   | Field                     | Value                                |
    >   +---------------------------+--------------------------------------+
    >   | admin_state_up            | UP                                   |
    >   | availability_zone_hints   |                                      |
    >   | availability_zones        | nova                                 |
    >   | created_at                | 2019-04-05T14:02:57Z                 |
    >   | description               |                                      |
    >   | dns_domain                |                                      |
    >   | id                        | ecb791d5-1022-447a-a79c-8f38a0f5c990 |
    >   | ipv4_address_scope        | None                                 |
    >   | ipv6_address_scope        | None                                 |
    >   | is_default                | False                                |
    >   | is_vlan_transparent       | None                                 |
    >   | mtu                       | 1500                                 |
    >   | name                      | cumulus-internal                     |
    >   | port_security_enabled     | False                                |
    >   | project_id                | 481837de9b39406d93c7782d0d29e48e     |
    >   | provider:network_type     | None                                 |
    >   | provider:physical_network | None                                 |
    >   | provider:segmentation_id  | None                                 |
    >   | qos_policy_id             | None                                 |
    >   | revision_number           | 6                                    |
    >   | router:external           | External                             |
    >   | segments                  | None                                 |
    >   | shared                    | True                                 |
    >   | status                    | ACTIVE                               |
    >   | subnets                   | 01b76c7c-3c1a-4c5c-9a5a-14bcf6c0c290 |
    >   | tags                      |                                      |
    >   | updated_at                | 2019-09-03T15:32:55Z                 |
    >   +---------------------------+--------------------------------------+


    openstack \
        --os-cloud 'gaia-dev' \
        subnet show \
            01b76c7c-3c1a-4c5c-9a5a-14bcf6c0c290

    >   +----------------------+---------------------------------------------------+
    >   | Field                | Value                                             |
    >   +----------------------+---------------------------------------------------+
    >   | allocation_pools     | 10.218.1.1-10.218.10.199                          |
    >   | cidr                 | 10.218.0.0/16                                     |
    >   | created_at           | 2019-04-05T14:03:07Z                              |
    >   | description          |                                                   |
    >   | dns_nameservers      | 131.111.12.20, 131.111.8.42                       |
    >   | dns_publish_fixed_ip | None                                              |
    >   | enable_dhcp          | True                                              |
    >   | gateway_ip           | 10.218.0.1                                        |
    >   | host_routes          | destination='10.206.0.0/16', gateway='10.218.0.3' |
    >   | id                   | 01b76c7c-3c1a-4c5c-9a5a-14bcf6c0c290              |
    >   | ip_version           | 4                                                 |
    >   | ipv6_address_mode    | None                                              |
    >   | ipv6_ra_mode         | None                                              |
    >   | name                 | cumulus-internal                                  |
    >   | network_id           | ecb791d5-1022-447a-a79c-8f38a0f5c990              |
    >   | prefix_length        | None                                              |
    >   | project_id           | 481837de9b39406d93c7782d0d29e48e                  |
    >   | revision_number      | 2                                                 |
    >   | segment_id           | None                                              |
    >   | service_types        |                                                   |
    >   | subnetpool_id        | None                                              |
    >   | tags                 |                                                   |
    >   | updated_at           | 2019-09-03T15:32:55Z                              |
    >   +----------------------+---------------------------------------------------+

    #
    # Is this the cause ?
    # On the cumulus cloud, the Ceph network subnet is visible, and we can see a static route to the 'hidden' subnet.
    #

    >   +----------------------+---------------------------------------------------+
    >   | Field                | Value                                             |
    >   +----------------------+---------------------------------------------------+
    >   ....
    >   | host_routes          | destination='10.206.0.0/16', gateway='10.218.0.3' |
    >   ....
    >   +----------------------+---------------------------------------------------+

    #
    # On the Arcus cloud, we can't see the subnet or the route.
    #

    >   No Subnet found for 5699fb5d-8316-4b88-b889-b05c8a1ec975

# -----------------------------------------------------

    Resorting to screenshots of the Horizon GUI.

    Cumulus network list shows 'cumulus-internal' network linked to 'cumulus-internal 10.218.0.0/16' subnet.
    screenshots/screenshot-20220120-135720.png

    arcus-data network list shows 'cephfs' linked to 'cephfs 10.9.0.0/16' subnet.
    screenshots/screenshot-20220120-135615.png

    arcus-red network list shows 'cephfs' is not linked a subnet.
    screenshots/screenshot-20220120-135648.png

# -----------------------------------------------------

    These are all just access permissions in Openstack.
    The actual networks, subnets and routes are all in place.

    Once the hidden routes added we can ping the target machines.

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        ping -c 5 10.4.200.17
        '

    >   Thu Jan 20 14:26:53 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   PING 10.4.200.17 (10.4.200.17) 56(84) bytes of data.
    >   64 bytes from 10.4.200.17: icmp_seq=1 ttl=62 time=3.60 ms
    >   From 10.10.0.1 icmp_seq=2 Redirect Host(New nexthop: 203.3.10.10)
    >   64 bytes from 10.4.200.17: icmp_seq=2 ttl=62 time=0.580 ms
    >   64 bytes from 10.4.200.17: icmp_seq=3 ttl=62 time=0.572 ms
    >   64 bytes from 10.4.200.17: icmp_seq=4 ttl=62 time=0.400 ms
    >   
    >   --- 10.4.200.17 ping statistics ---
    >   4 packets transmitted, 4 received, +1 errors, 0% packet loss, time 3083ms
    >   rtt min/avg/max/mdev = 0.400/1.288/3.603/1.338 ms


    .. but mount still fails with 'error 22 = Invalid argument'

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        grep '2MASSPSC' /etc/fstab
        echo "----"
        sudo mount '/data/twomass/2MASSPSC'
        '

    >   Thu Jan 20 14:28:31 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/3d98f750-5bb8-4e4c-ba95-2b38c0f0ffd5 /data/twomass/2MASSPSC ceph name=aglais-data-twomass-allsky-ro,config=/etc/ceph/ceph.conf,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   ----
    >   mount error 22 = Invalid argument

    #
    # I seem to remember when hacking around on the test system, this version of the Ceph client didn't like the 'config' param ?
    #


# -----------------------------------------------------
# Try removing the config option from fstab.
#[root@ansibler]

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        sudo sed -i 's/,config=[^,]*,/,/' /etc/fstab
        '

    >   Thu Jan 20 14:42:55 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----


    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        grep '2MASSPSC' /etc/fstab
        echo "----"
        sudo mount '/data/twomass/2MASSPSC'
        '

    >   Thu Jan 20 14:43:38 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/3d98f750-5bb8-4e4c-ba95-2b38c0f0ffd5 /data/twomass/2MASSPSC ceph name=aglais-data-twomass-allsky-ro,async,auto,nodev,noexec,nosuid,ro,_netdev 0 0
    >   ----


    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        ls -al /data/twomass/2MASSPSC/
        echo "----"
        df -h  /data/twomass/2MASSPSC/
        '

    >   Thu Jan 20 14:44:28 UTC 2022
    >   iris-gaia-red-20220120-zeppelin
    >   ----
    >   total 38333320
    >   drwxrwxrwx. 2 root   root       1187 Jan  4 09:51 .
    >   drwxr-xr-x. 3 root   root       4096 Jan 20 07:44 ..
    >   -rw-r--r--. 1 fedora fedora        0 Jan 11  2021 _SUCCESS
    >   -rw-r--r--. 1 fedora fedora 33894203 Jan 11  2021 part-00000-ce75a128-1cde-4ce1-90fc-4a36208209b2-c000.snappy.parquet
    >   -rw-r--r--. 1 fedora fedora 34120132 Jan 11  2021 part-00001-ce75a128-1cde-4ce1-90fc-4a36208209b2-c000.snappy.parquet
    >   ....
    >   ....
    >   -rw-r--r--. 1 fedora fedora 31078087 Jan 11  2021 part-01184-ce75a128-1cde-4ce1-90fc-4a36208209b2-c000.snappy.parquet
    >   -rw-r--r--. 1 fedora fedora 14460710 Jan 11  2021 part-01185-ce75a128-1cde-4ce1-90fc-4a36208209b2-c000.snappy.parquet
    >   ----
    >   Filesystem                                                                                                Size  Used Avail Use% Mounted on
    >   10.4.200.9:6789,10.4.200.13:6789,10.4.200.17:6789:/volumes/_nogroup/3d98f750-5bb8-4e4c-ba95-2b38c0f0ffd5  821T   69T  752T   9% /data/twomass/2MASSPSC

    #
    # OK, a (undocumented) 'feature' of the different version of cehpfs-client on this version of Fedora ?
    #

# -----------------------------------------------------
# -----------------------------------------------------
# Update our Ansible script and try again ...
#[user@desktop]

    gedit "${AGLAIS_CODE:?}/deployments/hadoop-yarn/ansible/51-cephfs-mount.yml" &

        - name: "Creating CephFS fstab entry [{{mntpath}}]"
          become: true
          mount:
            src:    "{{cephnodes}}:{{cephpath}}"
            path:   "{{mntpath}}"
            fstype: "ceph"
    -       opts:   "name={{cephuser}},config={{cfgfile}},{{mntopts}}"
    +       opts:   "name={{cephuser}},{{mntopts}}"
            state:  mounted


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2021.08.25 \
        bash


# -----------------------------------------------------
# Set the cloud and configuration.
#[root@ansibler]

    cloudname=iris-gaia-red

    configname=zeppelin-27.45-spark-6.27.45

# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}" \


# -----------------------------------------------------
# Create everything, using the new config.
# Using 'prod' to skip the built-in tests.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
            'prod' \
        | tee /tmp/create-all.log









