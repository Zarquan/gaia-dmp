#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    Target:

        Get Spark to work with the new configuration.

        Test config:
            no gateway
            medium zeppelin
            4 medium workers

    Results:

        Work in progress ....


# -----------------------------------------------------
# Update the Openstack cloud name.
#[user@desktop]

    cloudname=gaia-dev

    sed -i '
        s/^\(AGLAIS_CLOUD\)=.*$/\1='${cloudname:?}'/
        ' "${HOME}/aglais.env"


# -----------------------------------------------------
# Create a container to work with.
# (*) extra volume mount for /common
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/common:/common:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/openstack:/openstack:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/hadoop-yarn:/hadoop-yarn:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Create our Aglais configuration.
#[root@kubernator]

cat > '/tmp/aglais-config.yml' << EOF
aglais:
    version: 1.0
    spec:
        openstack:
            cloud: '${cloudname:?}'

EOF


# -----------------------------------------------------
# Create everything from scratch.
#[root@ansibler]

    time \
        /openstack/bin/delete-all.sh \
            "${cloudname:?}"

    rm -f ~/.ssh/*

    time \
        /hadoop-yarn/bin/create-all.sh


    >   ....
    >   ....


# -----------------------------------------------------
# Check the deployment status.
#[root@ansibler]

    cat '/tmp/aglais-status.yml'

    >   aglais:
    >     spec:
    >       openstack:
    >         cloud: gaia-dev
    >     status:
    >       deployment:
    >         type: hadoop-yarn
    >         name: gaia-dev-20210209
    >         date: 20210209T194001


# -----------------------------------------------------
# Get the public IP address of our Zeppelin node.
#[root@ansibler]

    deployname=$(
        yq read \
            '/tmp/aglais-status.yml' \
                'aglais.status.deployment.name'
        )

    zeppelinid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server list \
                --format json \
        | jq -r '.[] | select(.Name == "'${deployname:?}'-zeppelin") | .ID'
        )

    zeppelinip=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server show \
                --format json \
                "${zeppelinid:?}" \
        | jq -r '.addresses' \
        | sed '
            s/[[:space:]]//
            s/.*=\(.*\)/\1/
            s/.*,\(.*\)/\1/
            '
        )

cat << EOF
Zeppelin ID [${zeppelinid:?}]
Zeppelin IP [${zeppelinip:?}]
EOF

    >   Zeppelin ID [a10a9b20-812a-4cab-ae97-efb2ccaddc0f]
    >   Zeppelin IP [128.232.227.229]


# -----------------------------------------------------
# -----------------------------------------------------

    Update our DNS


# -----------------------------------------------------
# -----------------------------------------------------
# Login to Zeppelin ...
#[user@desktop]

    firefox --new-window "http://zeppelin.metagrid.xyz:8080/" &


# -----------------------------------------------------
# -----------------------------------------------------


    Import notebooks from GitHub, clear the output and run all the cells ...

    Good astrometric solutions via ML Random Forrest classifier
    https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2FRPC4BFS/note.json


# -----------------------------------------------------
# -----------------------------------------------------

    >   org.apache.thrift.transport.TTransportException
    >   	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
    >   	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
    >   	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
    >   	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
    >   	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
    >   	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
    >   	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)
    >   	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)
    >   	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)
    >   	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)
    >   	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)
    >   	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)
    >   	at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)
    >   	at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
    >   	at org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)
    >   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    >   	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    >   	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
    >   	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
    >   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    >   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    >   	at java.lang.Thread.run(Thread.java:748)


# -----------------------------------------------------
# Check the Zeppelin logs.
#[user@zeppelin]

    pushd /home/fedora/zeppelin-0.8.2-bin-all/logs
        cat zeppelin-interpreter-spark-fedora-gaia-dev-20210210-zeppelin.novalocal.log

    >   ....
    >   ....
    >    INFO [2021-02-10 12:33:29,264] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/home/fedora/zeppelin-0.8.2-bin-all/interpreter/spark/spark-interpreter-0.8.2.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
    >    INFO [2021-02-10 12:33:29,284] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 10.10.2.210:36095
    >    INFO [2021-02-10 12:33:29,286] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 36095
    >    INFO [2021-02-10 12:33:29,287] ({Thread-3} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 36095
    >    INFO [2021-02-10 12:33:29,291] ({Thread-4} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 10.10.2.210, callbackPort: 42139, callbackInfo: CallbackInfo(host:10.10.2.210, port:36095)
    >    INFO [2021-02-10 12:33:29,354] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
    >    INFO [2021-02-10 12:33:29,355] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
    >    INFO [2021-02-10 12:33:29,360] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
    >    INFO [2021-02-10 12:33:29,363] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
    >    INFO [2021-02-10 12:33:29,366] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
    >    INFO [2021-02-10 12:33:29,368] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
    >    WARN [2021-02-10 12:33:29,456] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
    >    INFO [2021-02-10 12:33:29,470] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:129) - Server Host: 127.0.0.1
    >    INFO [2021-02-10 12:33:29,470] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
    >    INFO [2021-02-10 12:33:29,470] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:135) - Context Path: /
    >    INFO [2021-02-10 12:33:29,472] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
    >    INFO [2021-02-10 12:33:29,472] ({pool-1-thread-1} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
    >    INFO [2021-02-10 12:33:29,475] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20201013-131649_1734629667 started by scheduler interpreter_1097442532
    >    INFO [2021-02-10 12:33:29,818] ({pool-2-thread-2} IPythonInterpreter.java[checkIPythonPrerequisite]:200) - IPython prerequisite is met
    >    INFO [2021-02-10 12:33:29,820] ({pool-2-thread-2} NewSparkInterpreter.java[open]:83) - Using Scala Version: 2.11
    >    INFO [2021-02-10 12:33:33,057] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Running Spark version 2.4.7
    >    WARN [2021-02-10 12:33:33,104] ({pool-2-thread-2} Logging.scala[logWarning]:66) - Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
    >    INFO [2021-02-10 12:33:33,113] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
    >    INFO [2021-02-10 12:33:33,162] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls to: fedora
    >    INFO [2021-02-10 12:33:33,163] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls to: fedora
    >    INFO [2021-02-10 12:33:33,163] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls groups to:
    >    INFO [2021-02-10 12:33:33,163] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls groups to:
    >    INFO [2021-02-10 12:33:33,163] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fedora); groups with view permissions: Set(); users  with modify permissions: Set(fedora); groups with modify permissions: Set()
    >    INFO [2021-02-10 12:33:33,343] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 36301.
    >    INFO [2021-02-10 12:33:33,365] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering MapOutputTracker
    >    INFO [2021-02-10 12:33:33,381] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
    >    INFO [2021-02-10 12:33:33,383] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
    >    INFO [2021-02-10 12:33:33,384] ({pool-2-thread-2} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
    >   ERROR [2021-02-10 12:33:33,394] ({pool-2-thread-2} Logging.scala[logError]:91) - Failed to create local dir in /var/spark/temp. Ignoring this directory.
    >   java.io.IOException: Failed to create a temp directory (under /var/spark/temp) after 10 attempts!
    >   	at org.apache.spark.util.Utils$.createDirectory(Utils.scala:311)
    >   	at org.apache.spark.storage.DiskBlockManager$$anonfun$createLocalDirs$1.apply(DiskBlockManager.scala:141)
    >   	at org.apache.spark.storage.DiskBlockManager$$anonfun$createLocalDirs$1.apply(DiskBlockManager.scala:139)
    >   	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
    >   	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
    >   	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
    >   	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
    >   	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
    >   	at scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)
    >   	at org.apache.spark.storage.DiskBlockManager.createLocalDirs(DiskBlockManager.scala:139)
    >   	at org.apache.spark.storage.DiskBlockManager.<init>(DiskBlockManager.scala:42)
    >   	at org.apache.spark.storage.BlockManager.<init>(BlockManager.scala:143)
    >   	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:349)
    >   	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:175)
    >   	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:257)
    >   	at org.apache.spark.SparkContext.<init>(SparkContext.scala:424)
    >   	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2520)
    >   	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
    >   	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
    >   	at scala.Option.getOrElse(Option.scala:121)
    >   	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
    >   	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    >   	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    >   	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    >   	at java.lang.reflect.Method.invoke(Method.java:498)
    >   	at org.apache.zeppelin.spark.BaseSparkScalaInterpreter.spark2CreateContext(BaseSparkScalaInterpreter.scala:263)
    >   	at org.apache.zeppelin.spark.BaseSparkScalaInterpreter.createSparkContext(BaseSparkScalaInterpreter.scala:182)
    >   	at org.apache.zeppelin.spark.SparkScala211Interpreter.open(SparkScala211Interpreter.scala:90)
    >   	at org.apache.zeppelin.spark.NewSparkInterpreter.open(NewSparkInterpreter.java:102)
    >   	at org.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:62)
    >   	at org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:69)
    >   	at org.apache.zeppelin.spark.IPySparkInterpreter.getSparkInterpreter(IPySparkInterpreter.java:94)
    >   	at org.apache.zeppelin.spark.IPySparkInterpreter.open(IPySparkInterpreter.java:54)
    >   	at org.apache.zeppelin.spark.PySparkInterpreter.open(PySparkInterpreter.java:129)
    >   	at org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:69)
    >   	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:616)
    >   	at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
    >   	at org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)
    >   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    >   	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    >   	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
    >   	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
    >   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    >   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    >   	at java.lang.Thread.run(Thread.java:748)
    >   ERROR [2021-02-10 12:33:33,396] ({pool-2-thread-2} Logging.scala[logError]:70) - Failed to create any local dir.
    >    INFO [2021-02-10 12:33:33,399] ({Thread-1} Logging.scala[logInfo]:54) - Shutdown hook called
    >    INFO [2021-02-10 12:33:33,400] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-c78cdeb5-667e-4ad4-bdf4-c8da522abd15

    #
    # Zeppelin is actibg as the Spark master, and is looking for the /var/spark/temp local directory.
    #

    #
    # Now that we have removed the gateway node, can we change Zeppelin into a medium node
    # and add the /var/spark/temp local directory.
    #
    # Yes - needed to add the /var/spark/temp local directory to Zeppelin node to get notebook to run.
    #

    #
    # Zeppelin node is running a single threaded python task at 100% cpu.
    # Logs on Zeppelin node show it is sending out tasks to the other nodes ..


    100% active thread is ipython_server

        python /tmp/zeppelin_ipython8675898749474775789/ipython_server.py 43261


# -----------------------------------------------------
# Check the Zeppelin logs.
#[user@zeppelin]

    pushd /home/fedora

        tail -f zeppelin-0.8.2-bin-all/logs/zeppelin-interpreter-spark-fedora-gaia-dev-20210210-zeppelin.novalocal.log

    >   ....
    >   ....
    >    INFO [2021-02-10 18:15:13,368] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 674.0 in stage 92.0 (TID 318172, worker01, executor 2, partition 674, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:13,368] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 541.0 in stage 92.0 (TID 318039) in 201169 ms on worker01 (executor 2) (663/5720)
    >    INFO [2021-02-10 18:15:15,880] ({dispatcher-event-loop-11} Logging.scala[logInfo]:54) - Starting task 675.0 in stage 92.0 (TID 318173, worker02, executor 3, partition 675, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:15,880] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 529.0 in stage 92.0 (TID 318027) in 215511 ms on worker02 (executor 3) (664/5720)
    >    INFO [2021-02-10 18:15:15,884] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 676.0 in stage 92.0 (TID 318174, worker04, executor 1, partition 676, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:15,884] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 652.0 in stage 92.0 (TID 318150) in 57495 ms on worker04 (executor 1) (665/5720)
    >    INFO [2021-02-10 18:15:16,153] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Starting task 677.0 in stage 92.0 (TID 318175, worker04, executor 1, partition 677, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:16,153] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 676.0 in stage 92.0 (TID 318174) in 269 ms on worker04 (executor 1) (666/5720)
    >   ....
    >   ....
    >    INFO [2021-02-10 18:15:42,232] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 678.0 in stage 92.0 (TID 318176, worker01, executor 2, partition 678, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:42,232] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 628.0 in stage 92.0 (TID 318126) in 129777 ms on worker01 (executor 2) (667/5720)
    >    INFO [2021-02-10 18:15:42,662] ({dispatcher-event-loop-12} Logging.scala[logInfo]:54) - Starting task 679.0 in stage 92.0 (TID 318177, worker01, executor 2, partition 679, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:42,662] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 678.0 in stage 92.0 (TID 318176) in 430 ms on worker01 (executor 2) (668/5720)
    >    INFO [2021-02-10 18:15:51,745] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 680.0 in stage 92.0 (TID 318178, worker04, executor 1, partition 680, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:51,746] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 673.0 in stage 92.0 (TID 318171) in 60263 ms on worker04 (executor 1) (669/5720)
    >    INFO [2021-02-10 18:15:51,988] ({dispatcher-event-loop-7} Logging.scala[logInfo]:54) - Starting task 681.0 in stage 92.0 (TID 318179, worker04, executor 1, partition 681, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:51,988] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 680.0 in stage 92.0 (TID 318178) in 243 ms on worker04 (executor 1) (670/5720)
    >    INFO [2021-02-10 18:15:52,201] ({dispatcher-event-loop-6} Logging.scala[logInfo]:54) - Starting task 682.0 in stage 92.0 (TID 318180, worker04, executor 1, partition 682, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:52,202] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 681.0 in stage 92.0 (TID 318179) in 214 ms on worker04 (executor 1) (671/5720)
    >    INFO [2021-02-10 18:15:52,388] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - Starting task 683.0 in stage 92.0 (TID 318181, worker04, executor 1, partition 683, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:52,388] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 682.0 in stage 92.0 (TID 318180) in 187 ms on worker04 (executor 1) (672/5720)
    >    INFO [2021-02-10 18:15:52,822] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 684.0 in stage 92.0 (TID 318182, worker04, executor 1, partition 684, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:52,822] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 683.0 in stage 92.0 (TID 318181) in 434 ms on worker04 (executor 1) (673/5720)
    >    INFO [2021-02-10 18:15:53,118] ({dispatcher-event-loop-10} Logging.scala[logInfo]:54) - Starting task 685.0 in stage 92.0 (TID 318183, worker04, executor 1, partition 685, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:53,118] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 684.0 in stage 92.0 (TID 318182) in 296 ms on worker04 (executor 1) (674/5720)
    >    INFO [2021-02-10 18:15:53,312] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 686.0 in stage 92.0 (TID 318184, worker04, executor 1, partition 686, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:53,313] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 685.0 in stage 92.0 (TID 318183) in 194 ms on worker04 (executor 1) (675/5720)
    >    INFO [2021-02-10 18:15:53,522] ({dispatcher-event-loop-7} Logging.scala[logInfo]:54) - Starting task 687.0 in stage 92.0 (TID 318185, worker04, executor 1, partition 687, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:53,522] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 686.0 in stage 92.0 (TID 318184) in 210 ms on worker04 (executor 1) (676/5720)
    >    INFO [2021-02-10 18:15:54,158] ({dispatcher-event-loop-6} Logging.scala[logInfo]:54) - Starting task 688.0 in stage 92.0 (TID 318186, worker04, executor 1, partition 688, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:54,159] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 687.0 in stage 92.0 (TID 318185) in 637 ms on worker04 (executor 1) (677/5720)
    >    INFO [2021-02-10 18:15:54,408] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - Starting task 689.0 in stage 92.0 (TID 318187, worker04, executor 1, partition 689, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:54,408] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 688.0 in stage 92.0 (TID 318186) in 250 ms on worker04 (executor 1) (678/5720)
    >    INFO [2021-02-10 18:15:57,157] ({dispatcher-event-loop-7} Logging.scala[logInfo]:54) - Starting task 690.0 in stage 92.0 (TID 318188, worker02, executor 3, partition 690, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:57,157] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 675.0 in stage 92.0 (TID 318173) in 41277 ms on worker02 (executor 3) (679/5720)
    >    INFO [2021-02-10 18:15:57,825] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Starting task 691.0 in stage 92.0 (TID 318189, worker02, executor 3, partition 691, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-02-10 18:15:57,825] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 690.0 in stage 92.0 (TID 318188) in 668 ms on worker02 (executor 3) (680/5720)

    top on the worker nodes show 90% idle, then peaks of activity

        50%cpu to cheph-fuse
        10%cpu to java

# -----------------------------------------------------
# Check the Spark temp on Zeppelin.
#[user@zeppelin]

    ls -1 /var/spark/temp/

    >   blockmgr-ddd69876-f595-49bf-bc89-b4c5d52204a3
    >   spark-668f91a5-2e20-4f67-8fa5-bc68e679243b


    du -h -d 1 /var/spark/temp/

    >   220K	/var/spark/temp/spark-668f91a5-2e20-4f67-8fa5-bc68e679243b
    >   200K	/var/spark/temp/blockmgr-ddd69876-f595-49bf-bc89-b4c5d52204a3
    >   424K	/var/spark/temp/


# -----------------------------------------------------
# Check the Spark temp on workers.
#[user@worker01]

    ls -1 /var/spark/temp/



    du -h -d 1 /var/spark/temp/

    >   4.0K	/var/spark/temp/


    #
    # Zeppelin node is acting as the Spark masert.
    # ipython process is single thread 100% cpu, the rest is idle.
    # using <55k of spark/temp
    #

    #
    # worker nodes are 10-50% ceph, 0-10% java
    # mostly idle
    # not using spark/temp
    #


    Initial select query (10%)
    Took 17 min 48 sec. Last updated by gaiauser at February 10 2021, 6:22:12 PM.

    First graph
    Took 18 min 11 sec. Last updated by gaiauser at February 10 2021, 6:40:23 PM.

    Good/bad selection
    Took 42 min 13 sec. Last updated by gaiauser at February 10 2021, 7:22:37 PM.

    RandomForestClassifier
    Took 2 hrs 59 min 26 sec. Last updated by gaiauser at February 10 2021, 10:22:03 PM.

    Confusion matrix
    Took 42 min 6 sec. Last updated by gaiauser at February 10 2021, 11:04:09 PM.

    Second graph
    Took 1 hrs 18 min 18 sec. Last updated by gaiauser at February 11 2021, 12:22:28 AM.

    Histogram
    Took 19 min 17 sec. Last updated by gaiauser at February 11 2021, 12:41:45 AM.

    Good plot
    Took 40 min 3 sec. Last updated by gaiauser at February 11 2021, 1:21:48 AM.

    Bad plot
    Took 40 min 8 sec. Last updated by gaiauser at February 11 2021, 2:01:56 AM.

    Good/bad count
    Took 40 min 4 sec. Last updated by gaiauser at February 11 2021, 2:42:00 AM.

    Histogram
    Took 40 min 15 sec. Last updated by gaiauser at February 11 2021, 3:22:15 AM.

    Null count
    Took 25 min 30 sec. Last updated by gaiauser at February 11 2021, 3:47:45 AM.


