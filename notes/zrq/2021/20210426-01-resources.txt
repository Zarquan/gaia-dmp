#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#


    How did a request for 1540 cores (physical) get transformed into 600 cores ?

    I was expecting a 4x step increase from 383 to 1540 .. we got 1.5


    The Resource Request Call zip file contained documents dated 2020.
    "aglais/documents/allocation 2021/[IRIS-TWG] IRIS RSAP Resource Request Call FY21_22.zip"

        Guidance document dated '20'
        "aglais/documents/allocation 2021/[IRIS-TWG] IRIS RSAP Resource Request Call FY21_22/IRIS-Resource-Request-Guidance-20.pdf"

            Spread sheet should contain:
            * A firm estimate for 2021
            * Preliminary estimates for 2022-2025

            * CPU units: = CPU-Cores
            * GPU units: = GPU cards
            * Storage units: = Disk-TB and Tape-TB


            The dates set out in the document says 2020, but I suspect that is a typo

            29 th January 2020(sic)
                Preliminary allocations are agreed by RSAP and submitted to TWG
                and DB. Feedback on preliminary allocation decisions sent to
                partners.
            1 st April
                Formal responses to partners issued. Grants issued ASAP after this
                date.

            What was the feedback in January ?
            If grants are issued on 1st April, then can the hardware already be bought ?


    Our request document
    "aglais/documents/allocation 2021/Gaia-SciencePlatform-IRIS-Resource-Request-FY21.docx"

        CPU:     in 2021 we request a total of 18500 CPU-months (1540 CPU cores available for the full year)
        GPU:     none
        Storage: 144 TB

        (*) nothing in the request says we are asking for hyperthreaded virtual cores



    The result document
    "aglais/documents/allocation 2021/result/final_GAIA .docx"

        Re: Notice of Allocation of IRIS Resources for 2021/2022:  GAIA

        Science platform
            600 cores 144Tbyte disc


        (*) nothing in the result says if they are real or hyperthreaded cores


    For comparison, the result document for 2020 has 383 cores

        Request    383
        Allocation 383


    Again - nothing to indicate if these are real or hyperthreaded cores


    The 2021 results email from Nigel via Nick W.
    ---- ---- ---- ----

        Hi

        Finally the official RSAP allocation for FY 21/22: they’ve given us 600 CPU/cores
        (we asked for 1200, but I suppose they’re factoring in hyper threading in the hypervisors…?!)
        and 0.144 PB storage (exactly what we asked for).

        Cheers

        N

    ---- ---- ---- ----

        Begin forwarded message:

        From: "naw@ast.cam.ac.uk<mailto:naw@ast.cam.ac.uk>" <naw@ast.cam.ac.uk<mailto:naw@ast.cam.ac.uk>>
        Subject: Fwd: RSAP Allocation : GAIA
        Date: 21 April 2021 at 10:07:14 BST
        To: nigelhambly nigelhambly <nch@roe.ac.uk<mailto:nch@roe.ac.uk>>, "pwb@ast.cam.ac.uk<mailto:pwb@ast.cam.ac.uk>" <pwb@ast.cam.ac.uk<mailto:pwb@ast.cam.ac.uk>>

        Hi Nigel, Patrick,

        See attached - we have the IRIS allocations for 2021/2022 (the letter has the correct years!)

        We have the full request for the science platform and the 1/2 the PUs for the core - but we can get the full request as soon as we are up and running.

        Cheers, Nic
        ========================================================================
        Dr Nicholas A. Walton
        Institute of Astronomy            Tel:   +44 1223 337503
        University of Cambridge         Fax:   +44 1223 337523
        Madingley Road                     WWW:   https://www.ast.cam.ac.uk/people/Nicholas.Walton
        Cambridge, CB3 0HA           email: naw@ast.cam.ac.uk<mailto:naw@ast.cam.ac.uk>
        ========================================================================

    ---- ---- ---- ----

        Begin forwarded message:

        From: Jonathan Hays <j.hays@qmul.ac.uk<mailto:j.hays@qmul.ac.uk>>
        Subject: RSAP Allocation : GAIA
        Date: 20 April 2021 at 18:31:27 BST
        To: "naw@ast.cam.ac.uk<mailto:naw@ast.cam.ac.uk>" <naw@ast.cam.ac.uk<mailto:naw@ast.cam.ac.uk>>
        Cc: Jonathan Hays <j.hays@qmul.ac.uk<mailto:j.hays@qmul.ac.uk>>, "philip.jackson@stfc.ac.uk<mailto:philip.jackson@stfc.ac.uk>" <philip.jackson@stfc.ac.uk<mailto:philip.jackson@stfc.ac.uk>>, "peter.clarke@ed.ac.uk<mailto:peter.clarke@ed.ac.uk>" <peter.clarke@ed.ac.uk<mailto:peter.clarke@ed.ac.uk>>

        Dear Nic ,

        Please find attached your IRIS RSAP Allocation letter regarding the GAIA  activity for the 2020/21 application cycle. If you have any questions about this allocation, please contact the IRIS project manager (Philip Jackson Philip.Jackson@stfc.ac.uk<mailto:Philip.Jackson@stfc.ac.uk>) and the RSAP Chair (Jon Hays j.hays@qmul.ac.uk<mailto:j.hays@qmul.ac.uk> ).

        Best regards,

        Dr Jon Hays

        RSAP Chair

    ---- ---- ---- ----

    What we currently have:

    >   Paul Browne
    >   They have 4 full Cascade Lake nodes all to themselves
    >   RAM is probably limiting factor, then local disk
    >   Each of these 4 nodes have these physical resources ;
    >
    >       cpu-p-633:
    >       local_gb: 880
    >       memory_mb: 191855 (188G)
    >       vcpus: 110

    The 2020 allocation from IRIS was 383 cpus not vcpus.
    Hyperthreaded vcpus might not be sucha big deal, but the associated memory and local disc are.

    Updated details page for Cambridge
    https://github.com/RSE-Cambridge/iris-openstack/blob/master/cambridge.md#resources

    Storage:

        External storage is all provided by a small Ceph cluster.
        Currently it has around 45TB of usable space, provided by spinning disks attached
        to three servers, each with 4 x 10GbE bond.
        There are plans to upgrade this capacity depending on the demand seen.

    SkyLake:

        Each hypervisor (Dell PowerEdge C6420) has two Intel Xeon Gold 6142
        (i.e. a total of 64 hyperthreaded cores runing at 2.60-3.70 GHz per hypervisor)
        with 192GB RAM (i.e. 3GB per hyperthreaded core) and around 400GB of local SSD.

        There is a bonded 2 x 25GbE link to a redundant pair of switches.

        For VM sizing, two 90GB VMs, using under 200GB of local disk, should fit into a
        single hypervisor. Typically 56 vCPUs are available per host, although unless you
        have a dedicated agregate, hyperthreading will be turned off and you will get 2:1
        oversubscribed to physical CPUs.

    CascadeLake:

        Each hypervisor (Dell PowerEdge C6420) has two Intel Xeon Platinum 8276
        (i.e. a total of 112 hyperthreaded cores runing at 2.20-4.00 GHz per hypervisor)
        with 192GB RAM (i.e. 1.7GB per hyperthreaded core) and around 800GB of local SSD.

        There is a single 50GbE Mellanox ConnectEx-6 ethernet link (with the option for RoCEv2 via SR-IOV).

        For VM sizing, two 90GB VMs, using under 400GB of local disk, should fit into a single hypervisor.
        Typiucally there are 108 vCPUs available for VMs. If you are in a dedicated aggregate,
        this can be 1:1 hyperthreads to vCPUs.

            192GB RAM / 112 cores ~= 1.7G/vcpu

        CPU Specifications
        https://www.intel.com/content/www/us/en/products/sku/192470/intel-xeon-platinum-8276-processor-38-5m-cache-2-20-ghz/specifications.html

            28 Cores
            56 Threads
            2.20 GHz Base Frequency
            4.00 GHz Max Turbo Frequency
            38.5 MB Cache

        So 28 physical cores per physical CPU, two CPU per motherboard.

            56 physical cores per motherboard
            112 hyperthread vcpu cores per motherboard

            "If you are in a dedicated aggregate, this can be 1:1 hyperthreads to vCPUs."
            I think we are in a dedicated aggregate, although some resources still used by others.

    Short form:

        SkyLake: 64 hyperthreads, 3GB RAM per hyperthreaded core, 400GB SSD per machine

        CascadeLake: 112 hyperthreads, 1.7GB RAM per hyperthreaded core, 800GB SSD per machine

    ---- ---- ---- ----

    In 2020 Allocation from IRIS said 383 cores (p/v?).
    In 2020 We have 4*112 hyperthreads (minus some for others)

    In 2021 Allocation from IRIS says 600 cores (p/v?).

    ---- ---- ---- ----

    Email from John Garbutt

        We are doing some planning for the Scientific OpenStack digital assets
        for Q2/Q3.
        It would be great to get some input from you on those plans.

        There will be limits on what is available, given the hardware is
        already in place.
        Could you share a rough idea of what you would like in an ideal world?

        I know you mentioned becoming IO bound in certain cases.
        It would be good to get a better understanding of your various storage needs.
        I suspect there are some interesting options that could be tested there.
        (Specifically thinking about getting a DAC node (or two) for a month or so)
        Local NVMe (or Cinder with NVMe-over-fabrics) could be worth a look.

        We have been looking at working with the STFC AI benchmarking group.
        Looking at characterising performance, and identifying bottlenecks, etc.
        It would be great to apply that to your specific workload.

    Discussion about IO limited processes will be useful.
    Details about repairs to the Ceph storage system would be good.
    Details about planned upgrades to the Ceph storage system would be good.

    Confirmation about the resource requesting process

        If we ask for 1 core from IRIS, assuming we are allocated a dedicated aggregate that maps to either:

            SkyLake:
                1 hyperthreaded vcpu with 3GB RAM and 6G disc

            CascadeLake:
                1 hyperthreaded vcpu with 1.7GB RAM and 7G disc

    How did a request for 1540 cores result in an allocation of 600 cores ?

        Where did we go wrong and how do we fix it ?








