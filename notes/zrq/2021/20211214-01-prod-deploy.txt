#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#


    Target:

        Last steps to complete a deployment.

    Result:

        Success.
        Passes basic tests.
        Ready to transfer to prod ...


# -----------------------------------------------------
# Check the current branch.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        git branch

    popd

    >     20210113-zrq-source-build
    >   * 20211011-zrq-hdbscan-config
    >     20211105-zrq-iris-2022
    >     20211202-zrq-PR-testing
    >     master


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2021.08.25 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudname=gaia-dev

    configname=zeppelin-28.180-spark-6.27.45

# -----------------------------------------------------
# Delete everything from dev and test.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            'gaia-dev'

    >   real    3m35.877s
    >   user    1m19.387s
    >   sys     0m10.073s


    time \
        /deployments/openstack/bin/delete-all.sh \
            'gaia-test'

    >   real    1m0.683s
    >   user    0m27.209s
    >   sys     0m3.439s


# -----------------------------------------------------
# Create everything, using the new config.
# Using 'prod' to skip the built-in tests.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
            'prod' \
        | tee /tmp/create-all.log

    >   real    113m31.405s
    >   user    25m30.513s
    >   sys     6m40.841s


# -----------------------------------------------------
# -----------------------------------------------------
# Setup a SSH tunnel SOCKS proxy.
# https://www.digitalocean.com/community/tutorials/how-to-route-web-traffic-securely-without-a-vpn-using-a-socks-tunnel
# Running 'htop' on the Zeppelin node to keep the connection alive.
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh \
                -t \
                -D "3000"  \
                zeppelin \
                    "
                    htop
                    "
            '


# -----------------------------------------------------
# Login to the Zeppelin UI using FoxyProxy SOCKS proxy.
#[user@desktop]

    firefox \
        'http://zeppelin:8080/' \
        'http://master01:8088/cluster' \
        'http://monitor:3000/login' \
        &

    firefox \
        'http://monitor:3000/datasources/new' \
        'http://monitor:3000/dashboard/import' \
        'http://monitor:3000/dashboard/import' \
        &

        Create our Prometheus data source.
        http://monitor:3000/datasources/new

            URL: http://monitor:9090/
            scrape: 1s

        Import our dashboards from local disc.
        http://monitor:3000/dashboard/import

            deployments/common/grafana/20210705-02-grafana-dash.json
            deployments/common/grafana/node-exporter-v20201010-1633446087511.json

            http://monitor:3000/d/34S3C8k7z/my-first-dash&refresh=5s
            http://monitor:3000/d/xfpJB9FGz/1-node-exporter-for-prometheus-dashboard-en-v20201010?orgId=1&refresh=5s


# -----------------------------------------------------
# Check the deployment status.
#[root@ansibler]

    cat '/tmp/aglais-status.yml'

    >   aglais:
    >     status:
    >       deployment:
    >         type: hadoop-yarn
    >         conf: zeppelin-28.180-spark-6.27.45
    >         name: gaia-dev-20211214
    >         date: 20211214T114345
    >     spec:
    >       openstack:
    >         cloud: gaia-dev


# -----------------------------------------------------
# Add the Zeppelin user accounts.
#[root@ansibler]

    ssh zeppelin

        pushd "${HOME}"
        ln -s "zeppelin-0.10.0-bin-all" "zeppelin"

            pushd "zeppelin"

                # Manual edit to add names and passwords
                vi conf/shiro.ini

                # Restart Zeppelin for the changes to take.
                bin/zeppelin-daemon.sh restart

            popd
        popd
    exit

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# Add the notebooks from github.
#[root@ansibler]

    ssh zeppelin

        pushd /home/fedora/zeppelin

            mv -b notebook \
               notebook-old

	        git clone git@github.com:wfau/aglais-notebooks.git notebook

	        bin/zeppelin-daemon.sh restart

        popd
    exit

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# Add our secret function to the ansibler container.
#[root@ansibler]

    # TODO Move this into the Ansible setup.
    # TODO Move our secrets onto our infra-ops server.

    if [ ! -e "${HOME}/bin" ]
    then
        mkdir "${HOME}/bin"
    fi

    cat > "${HOME}/bin/secret" << 'EOF'
ssh -n \
    'secretserver' \
    "bin/secret '${1}'"
EOF

    chmod u+x "${HOME}/bin/secret"

    if [ ! -e "${HOME}/.ssh" ]
    then
        mkdir "${HOME}/.ssh"
    fi

    cat >> "${HOME}/.ssh/config" << 'EOF'
Host secretserver
  User     Zarquan
  Hostname data.metagrid.co.uk
  PubkeyAcceptedKeyTypes +ssh-rsa
EOF

    ssh-keyscan 'data.metagrid.co.uk' >> "${HOME}/.ssh/known_hosts"

    secret frog

    >   Green Frog


# -----------------------------------------------------
# Get the public IP address of our Zeppelin node.
#[root@ansibler]

    cloudname=$(
        yq eval \
            '.aglais.spec.openstack.cloud' \
            '/tmp/aglais-status.yml'
        )

    deployname=$(
        yq eval \
            '.aglais.status.deployment.name' \
            '/tmp/aglais-status.yml'
        )

    zeppelinid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server list \
                --format json \
        | jq -r '.[] | select(.Name == "'${deployname:?}'-zeppelin") | .ID'
        )

    zeppelinip=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server show \
                --format json \
                "${zeppelinid:?}" \
        | jq -r ".addresses | .\"${deployname}-internal-network\" | .[1]"
        )

cat << EOF
Zeppelin ID [${zeppelinid:?}]
Zeppelin IP [${zeppelinip:?}]
EOF

    >   Zeppelin ID [9e386a34-d098-4014-8e30-9cf6cf0330ad]
    >   Zeppelin IP [128.232.227.243]


# -----------------------------------------------------
# Update our DuckDNS record.
#[root@ansibler]

    # Using prod as dev because Dennis is using dev as prod.

    duckhost=aglais-dev
    duckipv4=${zeppelinip:?}
    ducktoken=$(secret 'aglais.duckdns.token')

    curl "https://www.duckdns.org/update/${duckhost:?}/${ducktoken:?}/${duckipv4:?}"

    >   OK


# -----------------------------------------------------
# Add bind-utils to the client.
# https://github.com/wfau/atolmis/issues/17
#[root@ansibler]

    dnf -y install bind-utils

    >   ....
    >   Installed:
    >     bind-libs-32:9.16.21-1.fc34.x86_64
    >     bind-license-32:9.16.21-1.fc34.noarch
    >     bind-utils-32:9.16.21-1.fc34.x86_64


# -----------------------------------------------------
# Check the DNS record.
#[root@ansibler]

    dig "${duckhost:?}.duckdns.org"

    >   ....
    >   ;; ANSWER SECTION:
    >   aglais-dev.duckdns.org.	60	IN	A	128.232.227.243
    >   ....


    dig "zeppelin.${cloudname}.aglais.uk"

    >   ....
    >   ;; ANSWER SECTION:
    >   zeppelin.gaia-dev.aglais.uk. 600 IN	CNAME	aglais-dev.duckdns.org.
    >   aglais-dev.duckdns.org.	46	IN	A	128.232.227.243
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Load our tests scripts.
#[root@ansibler]

    zeppelinhost=zeppelin.${cloudname:?}.aglais.uk
    zeppelinport=8080
    zeppelinurl=http://${zeppelinhost:?}:${zeppelinport:?}

    source /deployments/zeppelin/test/bin/rest-tests.sh


# -----------------------------------------------------
# Login to Zeppelin as a normal user.
#[root@ansibler]

    gaiauser=$(secret aglais.zeppelin.gaiauser)
    gaiapass=$(secret aglais.zeppelin.gaiapass)

    zeplogin "${gaiauser:?}" "${gaiapass}"

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "principal": "gaiauser",
    >       "ticket": "c614bb61-4a47-4b39-85d6-12dda1f13302",
    >       "roles": "[\"user\"]"
    >     }
    >   }


# -----------------------------------------------------
# Run the SetUp notebook.
#[root@ansibler]

    noteid=2GP53P3PZ

    zepnbclear     ${noteid}
    zepnbexecstep  ${noteid}
    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   Para [20210504-130917_57061499][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210504-131126_1544574772][Catalogue structure definitions]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210504-131319_1186301617][Utility function definitions]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210504-131439_625331903][Set up the catalogues on the platform]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210504-132955_1641890430][Show details of databases and tables]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210504-141425_1480464936][Check location on disk for main catalogue table from metastore]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210521-084938_875368697][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "SetUp",
    >       "id": "2GP53P3PZ",
    >       "defaultInterpreterGroup": "spark",
    >       "version": "0.10.0",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {},
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {},
    >       "path": "/AglaisPublicExamples/SetUp"
    >     }
    >   }

    >   0:0:36


# -----------------------------------------------------
# Run the HealpixSourceCounts notebook
#[root@ansibler]

    noteid=2GQ6WMH9W

    zepnbclear     ${noteid}
    zepnbexecstep  ${noteid}
    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   {
    >     "status": "OK",
    >     "message": ""
    >   }

    >   Para [20210507-084613_357121151][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20200826-105718_1698521515][Set the resolution level and define the query]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20200826-110030_2095441495][Plot up the results]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210507-091244_670006530][Further reading and resources]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20200826-110146_414730471][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20211029-084414_730906497][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "Source counts over the sky",
    >       "id": "2GQ6WMH9W",
    >       "defaultInterpreterGroup": "spark",
    >       "version": "0.10.0",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {},
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {},
    >       "path": "/AglaisPublicExamples/Source counts over the sky"
    >     }
    >   }

    >   0:0:31


# -----------------------------------------------------
# Run the MeanProperMotions notebook
#[root@ansibler]

    noteid=2GSNYBDWB

    zepnbclear     ${noteid}
    zepnbexecstep  ${noteid}
    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   {
    >     "status": "OK",
    >     "message": ""
    >   }

    >   Para [20210507-084613_357121151][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20200826-105718_1698521515][Set the resolution level and define the query]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20200826-110030_2095441495][Plot up the results]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210507-091244_670006530][Further reading and resources]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20200826-110146_414730471][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20211029-084414_730906497][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "Source counts over the sky",
    >       "id": "2GQ6WMH9W",
    >       "defaultInterpreterGroup": "spark",
    >       "version": "0.10.0",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {},
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {},
    >       "path": "/AglaisPublicExamples/Source counts over the sky"
    >     }
    >   }

    >   0:0:26


# -----------------------------------------------------
# Run the RandomForest notebook (first pass).
#[root@ansibler]

    noteid=2GQDKZ59J

    zepnbclear     ${noteid}
    zepnbexecstep  ${noteid}
    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   {
    >     "status": "OK",
    >     "message": ""
    >   }

    >   Para [20201013-131059_546082898][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201013-131649_1734629667][Basic catalogue query selections and predicates]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201013-132418_278702125][Raw catalogue with selected columns]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201120-094650_221463065][Visualisation (colour / absolute-magnitue diagram) of the raw catalogue]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201120-110502_1704727157][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201123-105445_95907042][Define the training samples]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201015-161110_18118893][Assemble training and reserve test sets]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201013-152110_1282917873][Train up the Random Forrest]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210504-153521_1591875670][Check feature set for nulls]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201015-131823_1744793710][Classify the reserved test sets]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201016-154755_24366630][Classification confusion matrix]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201123-163421_1811049882][Relative importance of the selected features]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201123-162249_1468741293][Apply the classification model and plot sample results]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201124-100512_110153564][Histogram of classification probability]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201125-103046_1353183691][Sky distribution of good source sample]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20201125-163312_728555601][Sky distribution of bad source sample]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210428-140519_1288739408][Further reading and resources]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]
    >
    >   Para [20210506-134212_1741520795][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS"
    >     }
    >   }
    >   Result [SUCCESS]

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "Good astrometric solutions via ML Random Forrest classifier",
    >       "id": "2GQDKZ59J",
    >       "defaultInterpreterGroup": "spark",
    >       "version": "0.10.0",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {},
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {},
    >       "path": "/AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier"
    >     }
    >   }

    >   0:8:4


# -----------------------------------------------------
# Run the RandomForest notebook (second pass, no restart).
#[root@ansibler]

    noteid=2GQDKZ59J

    zepnbclear     ${noteid}
    zepnbexecstep  ${noteid}
    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   ....
    >   ....

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "Good astrometric solutions via ML Random Forrest classifier",
    >       "id": "2GQDKZ59J",
    >       "defaultInterpreterGroup": "spark",
    >       "version": "0.10.0",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {},
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {},
    >       "path": "/AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier"
    >     }
    >   }

    >   0:7:52


# -----------------------------------------------------
# Run the RandomForest notebook (third pass, no restart).
#[root@ansibler]

    noteid=2GQDKZ59J

    zepnbclear     ${noteid}
    zepnbexecstep  ${noteid}
    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   ....
    >   ....

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "Good astrometric solutions via ML Random Forrest classifier",
    >       "id": "2GQDKZ59J",
    >       "defaultInterpreterGroup": "spark",
    >       "version": "0.10.0",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {},
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {},
    >       "path": "/AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier"
    >     }
    >   }

    >   0:8:14


# -----------------------------------------------------
# Run the RandomForest notebook (fourth pass, no restart).
#[root@ansibler]

    noteid=2GQDKZ59J

    zepnbclear     ${noteid}
    zepnbexecstep  ${noteid}
    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}


    >   ....
    >   ....

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "Good astrometric solutions via ML Random Forrest classifier",
    >       "id": "2GQDKZ59J",
    >       "defaultInterpreterGroup": "spark",
    >       "version": "0.10.0",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {},
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {},
    >       "path": "/AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier"
    >     }
    >   }

    >   0:8:15

