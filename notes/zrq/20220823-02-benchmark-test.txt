#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Run our benchmark tests on our new deployment.

    Result:

        FAIL - looks like our tests are out of date.


# -----------------------------------------------------
# Deploy everything.
#[root@ansibler]

    time \
        source /deployments/hadoop-yarn/bin/deploy.sh

    >   ....
    >   ....


# -----------------------------------------------------
# Import our test users.
#[root@ansibler]

    source /deployments/zeppelin/bin/create-user-tools.sh

    import-test-users

    >   ....
    >   ....


# -----------------------------------------------------
# Create our list of credentials.
#[root@ansibler]

    jq '
        {
        "users": [
                {
                "shirouser":
                    .users[] | .shirouser | {"name": .name, "pass": .password}
                }
            ]
        }
        ' /tmp/test-users.json \
    | tee /tmp/test-creds.json


    >   {
    >     "users": [
    >       {
    >         "shirouser": {
    >           "name": "Reyesfan",
    >           "pass": "unclip atrium bullfrog heftiness"
    >         }
    >       },
    >       ....
    >       ....
    >       {
    >         "shirouser": {
    >           "name": "Drizzbinson",
    >           "pass": "unmasking walmart amendable endanger"
    >         }
    >       }
    >     ]
    >   }

    #
    # TODO Update the benchmark code to accept the updated format generated by the create-user tools.
    #


# -----------------------------------------------------
# Create our benchmark script.
#[root@ansibler]

    cat > /tmp/run-benchmark.py << 'EOF'
#!/bin/python3
import sys
from aglais_benchmark import AglaisBenchmarker

try:

    opts = [opt for opt in sys.argv[1:] if opt.startswith("-")]
    args = [arg for arg in sys.argv[1:] if not arg.startswith("-")]

    endpoint = args[0]
    testconfig = args[1]
    userlist = args[2]
    usercount = int(args[3])
    delaystart = int(args[4])
    delaynotebook = int(args[5])

except IndexError:

    raise SystemExit(f"Usage: {sys.argv[0]} <Zepelin endpoint> <test config> <list of users> <number of users>")

print("{")
print(
"""
\"config\": {{
    \"endpoint\":   \"{}\",
    \"testconfig\": \"{}\",
    \"userlist\":   \"{}\",
    \"usercount\":  \"{}\",
    \"delaystart\":  \"{}\",
    \"delaynotebook\":  \"{}\"
    }},
\"output\":
""".format(
        endpoint,
        testconfig,
        userlist,
        usercount,
        delaystart,
        delaynotebook
        )
    )

print("---start---")
AglaisBenchmarker(
    testconfig,
    userlist,
    "/tmp/",
    endpoint
    ).run(
        concurrent=True,
        users=usercount,
        delay_start=delaystart,
        delay_notebook=delaynotebook
        )
print("---end---")
print("}")
EOF

    chmod 'a+x' /tmp/run-benchmark.py


# -----------------------------------------------------
# Run one test.
#[root@ansibler]

    usercount=2

    endpoint="http://zeppelin:8080"
    testconfig=/deployments/zeppelin/test/config/quick.json
    testusers=/tmp/test-creds.json

    testname="multi-user-$(printf "%02d" ${usercount})-00"

    delaystart=4
    delaynotebook=5

    /tmp/run-benchmark.py \
        "${endpoint:?}" \
        "${testconfig:?}" \
        "${testusers:?}" \
        "${usercount:?}" \
        "${delaystart:?}" \
        "${delaynotebook:?}" \
    | tee "/tmp/results/${testname:?}.txt"

    >   {
    >
    >   "config": {
    >       "endpoint":   "http://zeppelin:8080",
    >       "testconfig": "/deployments/zeppelin/test/config/quick.json",
    >       "userlist":   "/tmp/test-creds.json",
    >       "usercount":  "2",
    >       "delaystart":  "4",
    >       "delaynotebook":  "5"
    >       },
    >   "output":
    >
    >   ---start---
    >   Test started [Multi User]
    >   ....
    >   ....


    #
    # Test hangs because side effect of adding HTTPS proxy blocked port 8080 in the firewall ...
    # TODO Fix the HTTPS proxy configuration (#838)
    #
    # Can we use a SSH tunnelled connection ?
    #


# -----------------------------------------------------
# Setup a SSH tunnel.
# https://linux.die.net/man/1/ssh
#[root@ansibler]

    ssh \
        -n \
        -f \
        -N \
        -L 8080:zeppelin:8080 \
        zeppelin

    >   ....
    >   ....


# -----------------------------------------------------
# Run one test.
#[root@ansibler]

    usercount=2

    endpoint="http://localhost:8080"
    testconfig=/deployments/zeppelin/test/config/quick.json
    testusers=/tmp/test-creds.json

    testname="multi-user-$(printf "%02d" ${usercount})-00"

    delaystart=4
    delaynotebook=5

    /tmp/run-benchmark.py \
        "${endpoint:?}" \
        "${testconfig:?}" \
        "${testusers:?}" \
        "${usercount:?}" \
        "${delaystart:?}" \
        "${delaynotebook:?}" \
    | tee "/tmp/results/${testname:?}.txt"



    >   {
    >
    >   "config": {
    >       "endpoint":   "http://localhost:8080",
    >       "testconfig": "/deployments/zeppelin/test/config/quick.json",
    >       "userlist":   "/tmp/test-creds.json",
    >       "usercount":  "2",
    >       "delaystart":  "4",
    >       "delaynotebook":  "5"
    >       },
    >   "output":
    >
    >   ---start---
    >   Test started [Multi User]
    >   Test completed! (226.67 seconds)
    >   [[{"name": "GaiaDMPSetup", "result": "ERROR",.... }]]
    >   ---end---
    >   }


# -----------------------------------------------------
# Add a function to filter our results.
#[root@ansibler]

    filter-results()
        {
        local testname=${1:?'testname required'}
        sed "
            /^---start---/ d
            /^---end---/ d
            /^Test started/   d
            /^Test completed/ d
            " \
            "/tmp/results/${testname:?}.txt" \
          | tee "/tmp/results/${testname:?}.json"
        }


    filter-results $testname | jq '.'

    >   {
    >     "config": {
    >       "endpoint": "http://localhost:8080",
    >       "testconfig": "/deployments/zeppelin/test/config/quick.json",
    >       "userlist": "/tmp/test-creds.json",
    >       "usercount": "2",
    >       "delaystart": "4",
    >       "delaynotebook": "5"
    >     },
    >     "output": [
    >       [
    >         {
    >           "name": "GaiaDMPSetup",
    >           "result": "ERROR",
    >           "outputs": {
    >             "valid": true
    >           },
    >           "messages": [],
    >           "time": {
    >             "result": "FAST",
    >             "elapsed": "39.88",
    >             "expected": "45.00",
    >             "percent": "-11.39",
    >             "start": "2022-08-23T04:44:15.645111",
    >             "finish": "2022-08-23T04:44:55.520665"
    >           },
    >           "logs": "Fail to execute line 5: assert all(item in actual_tables for item in expected_tables)\nTraceback (most recent call last):\n  File \"/tmp/1661229884701-0/zeppelin_python.py\", line 158, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 5, in <module>\nAssertionError"
    >         },
    >         {
    >           "name": "Mean_proper_motions_over_the_sky",
    >           "result": "PASS",
    >           "outputs": {
    >             "valid": true
    >           },
    >           "messages": [],
    >           "time": {
    >             "result": "SLOW",
    >             "elapsed": "119.27",
    >             "expected": "55.00",
    >             "percent": "116.86",
    >             "start": "2022-08-23T04:45:00.525956",
    >             "finish": "2022-08-23T04:46:59.798450"
    >           },
    >           "logs": ""
    >         },
    >         {
    >           "name": "Source_counts_over_the_sky.json",
    >           "result": "PASS",
    >           "outputs": {
    >             "valid": true
    >           },
    >           "messages": [],
    >           "time": {
    >             "result": "SLOW",
    >             "elapsed": "44.89",
    >             "expected": "22.00",
    >             "percent": "104.02",
    >             "start": "2022-08-23T04:47:04.803259",
    >             "finish": "2022-08-23T04:47:49.688575"
    >           },
    >           "logs": ""
    >         },
    >         {
    >           "name": "Library_Validation.json",
    >           "result": "ERROR",
    >           "outputs": {
    >             "valid": true
    >           },
    >           "messages": [],
    >           "time": {
    >             "result": "FAST",
    >             "elapsed": "2.57",
    >             "expected": "60.00",
    >             "percent": "-95.72",
    >             "start": "2022-08-23T04:47:54.694194",
    >             "finish": "2022-08-23T04:47:57.264877"
    >           },
    >           "logs": "Fail to execute line 6: assert numpy.__version__ == \"1.20.3\" \nTraceback (most recent call last):\n  File \"/tmp/1661229884701-0/zeppelin_python.py\", line 158, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 6, in <module>\nAssertionError"
    >         }
    >       ],
    >       [
    >         {
    >           "name": "GaiaDMPSetup",
    >           "result": "ERROR",
    >           "outputs": {
    >             "valid": true
    >           },
    >           "messages": [],
    >           "time": {
    >             "result": "FAST",
    >             "elapsed": "43.26",
    >             "expected": "45.00",
    >             "percent": "-3.87",
    >             "start": "2022-08-23T04:44:19.648468",
    >             "finish": "2022-08-23T04:45:02.906328"
    >           },
    >           "logs": "Fail to execute line 5: assert all(item in actual_tables for item in expected_tables)\nTraceback (most recent call last):\n  File \"/tmp/1661229891717-0/zeppelin_python.py\", line 158, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 5, in <module>\nAssertionError"
    >         },
    >         {
    >           "name": "Mean_proper_motions_over_the_sky",
    >           "result": "PASS",
    >           "outputs": {
    >             "valid": true
    >           },
    >           "messages": [],
    >           "time": {
    >             "result": "SLOW",
    >             "elapsed": "112.01",
    >             "expected": "55.00",
    >             "percent": "103.66",
    >             "start": "2022-08-23T04:45:07.911238",
    >             "finish": "2022-08-23T04:46:59.922260"
    >           },
    >           "logs": ""
    >         },
    >         {
    >           "name": "Source_counts_over_the_sky.json",
    >           "result": "PASS",
    >           "outputs": {
    >             "valid": true
    >           },
    >           "messages": [],
    >           "time": {
    >             "result": "SLOW",
    >             "elapsed": "44.72",
    >             "expected": "22.00",
    >             "percent": "103.29",
    >             "start": "2022-08-23T04:47:04.927177",
    >             "finish": "2022-08-23T04:47:49.650831"
    >           },
    >           "logs": ""
    >         },
    >         {
    >           "name": "Library_Validation.json",
    >           "result": "ERROR",
    >           "outputs": {
    >             "valid": true
    >           },
    >           "messages": [],
    >           "time": {
    >             "result": "FAST",
    >             "elapsed": "2.60",
    >             "expected": "60.00",
    >             "percent": "-95.67",
    >             "start": "2022-08-23T04:47:54.656329",
    >             "finish": "2022-08-23T04:47:57.255344"
    >           },
    >           "logs": "Fail to execute line 6: assert numpy.__version__ == \"1.20.3\" \nTraceback (most recent call last):\n  File \"/tmp/1661229891717-0/zeppelin_python.py\", line 158, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 6, in <module>\nAssertionError"
    >         }
    >       ]
    >     ]
    >   }

    #
    # The test infrastructure works .. but the tests fail.
    # Possibly because the database structure has changed ?
    # Possibly because the version of dependencies have changed ?
    # TODO Create a set of tests that pass.
    #

    #
    # Same problem as before - we need to be able to apply source control to a set of notebooks.
    #
    # The test configuration points to a JSON file that lists the tests.
    # /deployments/zeppelin/test/config/quick.json
    #
    # So why don't we point to our own tests ...
    #


