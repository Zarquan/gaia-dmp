#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Run tests to compare the Spark2 branch.
        gitpull: https://github.com/wfau/aglais/pull/590
        branch: stvoutsin:issue-upgrade-spark-3
        config: cclake-medium-04

    Result:

        Sucess.
        Spark2 mathplotlib works.
        Imported notebooks have code names.

# -----------------------------------------------------
# Revert to the main (Spark2) branch.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        git checkout master

    popd

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2021.08.25 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudname=gaia-dev


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

    >   real    14m3.077s
    >   user    1m16.318s
    >   sys     0m9.969s


# -----------------------------------------------------
# Create everything, using the (old) medium config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            'cclake-medium-04' \
            'test' \
        | tee /tmp/create.log

    >   real    289m54.989s
    >   user    56m56.353s
    >   sys     8m5.092s

    #
    # Note the results come in after everything has completed.
    # So once it starts the tests, skip to setting up the monitoring and come back to collect the results at the end.
    #

    >   ....
    >   ....
    >   TASK [Run benchmarker] ..
    >   changed: [localhost] => {
    >       "changed": true,
    >       "cmd": ["python3", "/tmp/run-test.py"],
    >       "delta": "4:04:10.096603",
    >       "end": "2021-12-02 15:42:38.861800",
    >       "rc": 0,
    >       "start": "2021-12-02 11:38:28.765197",
    >       "stderr": "",
    >       "stderr_lines": [],
    >       "stdout": "Test completed after: 14649.81 seconds ....",
    >       "stdout_lines": [
    >           "Test completed after: 14649.81 seconds",
    >           ....
    >           ]
    >       }
    >
    >   PLAY RECAP ..
    >   localhost : ok=9    changed=6    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

    >   ....
    >   Test completed after: 14649.81 seconds
    >   stdout:{
    >       'SetUp': {
    >           'totaltime': '45.44',
    >           'status': 'SLOW',
    >           'msg': '',
    >           'valid': 'TRUE'
    >           },
    >       'Mean_proper_motions_over_the_sky': {
    >           'totaltime': '50.92',
    >           'status': 'SUCCESS',
    >           'msg': '',
    >           'valid': 'TRUE'
    >           },
    >       'Source_counts_over_the_sky.json': {
    >           'totaltime': '16.01',
    >           'status': 'SUCCESS',
    >           'msg': '',
    >           'valid': 'TRUE'
    >           },
    >       'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {
    >           'totaltime': '517.88',
    >           'status': 'SLOW',
    >           'msg': '',
    >           'valid': 'TRUE'
    >           },
    >       'QC_cuts_dev.json': {
    >           'totaltime': '6350.56',
    >           'status': 'SLOW',
    >           'msg': '',
    >           'valid': 'TRUE'
    >           },
    >       'WD_detection_dev.json': {
    >           'totaltime': '7668.99',
    >           'status': 'SLOW',
    >           'msg': '',
    >           'valid': 'TRUE'
    >           }
    >       }
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Setup a SSH tunnel SOCKS proxy.
# https://www.digitalocean.com/community/tutorials/how-to-route-web-traffic-securely-without-a-vpn-using-a-socks-tunnel
# Running 'htop' on the Zeppelin node to keep the connection alive.
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh \
                -t \
                -D "3000"  \
                zeppelin \
                    "
                    htop
                    "
            '

# -----------------------------------------------------
# Login to the Zeppelin UI using FoxyProxy SOCKS proxy.
#[user@desktop]

    firefox --new-window 'http://zeppelin:8080/' &


# -----------------------------------------------------
# Login to the Spark UI using FoxyProxy SOCKS proxy.
#[user@desktop]

    firefox --new-window 'http://master01:8088/cluster' &


# -----------------------------------------------------
# Login to Grafana UI using FoxyProxy SOCKS proxy.
#[user@desktop]

    firefox --new-window 'http://monitor:3000/login' &

        Create our Prometheus data source.
        http://monitor:3000/datasources/new

            URL: http://monitor:9090/
            scrape: 1s

        Import our dashboards from local disc.
        http://monitor:3000/dashboard/import

            deployments/common/grafana/20210705-02-grafana-dash.json
            deployments/common/grafana/node-exporter-v20201010-1633446087511.json

            http://monitor:3000/d/34S3C8k7z/my-first-dash&refresh=5s
            http://monitor:3000/d/xfpJB9FGz/1-node-exporter-for-prometheus-dashboard-en-v20201010?orgId=1&refresh=5s


# -----------------------------------------------------

    Screenshots
    /home/Zarquan/Desktop/projects/WFAU/aglais/screenshots/20211202

    Zeppelin main page, after tests completed
    screenshots/20211202/screenshot-20211202-161230.png

    Using ML to define an astrometrically clean sample of stars
    screenshots/20211202/screenshot-20211202-160619.png

    HEALPix density map
    screenshots/20211202/screenshot-20211202-160311.png

    Mean RA proper motion plot
    screenshots/20211202/screenshot-20211202-160213.png

    Training a Random Forest to identify White Dwarf Stars
    screenshots/20211202/screenshot-20211202-160116.png

# -----------------------------------------------------

    Spark UI
    screenshots/20211202/screenshot-20211202-162154.png

    Grafana
    screenshots/20211202/screenshot-20211202-162224.png

    Grafana
    screenshots/20211202/screenshot-20211202-162258.png


