#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2024, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#
# AIMetrics: []
#

    Target:

        Move everything up one step in the directory tree.
        Dropping the redundant bootstrap directory.

    Result:

        Work in progress ...


# -----------------------------------------------------
# Move everything out of the bootstrap directory.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE:?}"

        pushd deployments/cluster-api

            git mv bootstrap/ansible ansible
            git mv bootstrap/docker  docker
            git mv bootstrap/helm    helm

        popd
    popd


# -----------------------------------------------------
# -----------------------------------------------------
# Check the custom DNS addresses are set.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE:?}"

        vi deployments/cluster-api/ansible/templates/clusterapi-config.j2

        ~     # Custom nameservers to use for the hosts
        ~     dnsNameservers:
        ~     - "{{ deployments[aglais.openstack.cloud.site].dnsservers }}"

    popd


# -----------------------------------------------------
# -----------------------------------------------------
# Delete and create everything on jade.
#[user@desktop]

    source "${HOME}/aglais.env"

    agclient jade

        export cloudsite='somerville-jade'

        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

        ansible-playbook \
            --inventory 'bootstrap,' \
            '/deployments/cluster-api/ansible/00-create-all.yml'

    >   ....
    >   ....
    >   PLAY RECAP *******************************************************************************************************
    >   bootstrap                  : ok=58   changed=45   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   localhost                  : ok=35   changed=26   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


# -----------------------------------------------------
# Login to our bootstrap node and check the work cluster status.
#[root@ansibler]

    ssh -t bootstrap \
        '
        source loadconfig
        watch clusterctl \
            --kubeconfig "${kindclusterconf:?}" \
            describe cluster \
                "${workclustername:?}"
        '

    >   NAME                                                                              READY  SEVERITY  REASON                       SINCE  MESSAGE
    >   Cluster/somerville-jade-20240115-work                                             True                                          3m50s
    >   ├─ClusterInfrastructure - OpenStackCluster/somerville-jade-20240115-work
    >   ├─ControlPlane - KubeadmControlPlane/somerville-jade-20240115-work-control-plane  True                                          3m50s
    >   │ └─Machine/somerville-jade-20240115-work-control-plane-4mx5t                     True                                          5m40s
    >   └─Workers
    >     └─MachineDeployment/somerville-jade-20240115-work-md-0                          False  Warning   WaitingForAvailableMachines  7m54s  Minimum availability requires 2 replicas, current 0 available
    >       └─3 Machines...                                                               True                                          3m17s  See somerville-jade-20240115-work-md-0-x8dnx-bvcd4, somerville-jade-20240115-work-md-0-x8dnx-d4mlf, ...

    #
    # Still fails, but looks the same as yesterday.
    # Assume the directory move worked OK.
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Delete and create everything on blue.
#[user@desktop]

    source "${HOME}/aglais.env"

    agclient blue

        export cloudsite='cambridge-arcus'

        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

        ansible-playbook \
            --inventory 'bootstrap,' \
            '/deployments/cluster-api/ansible/00-create-all.yml'

    >   ....
    >   ....
    >   PLAY RECAP ****************************************************************************************************************
    >   bootstrap                  : ok=58   changed=45   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    >   localhost                  : ok=35   changed=26   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


        ssh -t bootstrap \
            '
            source loadconfig
            watch clusterctl \
                --kubeconfig "${kindclusterconf:?}" \
                describe cluster \
                    "${workclustername:?}"
            '

    >   NAME                                                                             READY  SEVERITY  REASON                       SINCE  MESSAGE
    >   Cluster/iris-gaia-blue-20240115-work                                             False  Warning   ScalingUp                    11m    Scaling up control plane to 3 replicas (actual 1)
    >   ├─ClusterInfrastructure - OpenStackCluster/iris-gaia-blue-20240115-work
    >   ├─ControlPlane - KubeadmControlPlane/iris-gaia-blue-20240115-work-control-plane  False  Warning   ScalingUp                    11m    Scaling up control plane to 3 replicas (actual 1)
    >   │ └─Machine/iris-gaia-blue-20240115-work-control-plane-89thk                     True                                          11m
    >   └─Workers
    >     └─MachineDeployment/iris-gaia-blue-20240115-work-md-0                          False  Warning   WaitingForAvailableMachines  13m    Minimum availability requires 5 replicas, current 0 available
    >       └─6 Machines...                                                              True                                          9m2s   See iris-gaia-blue-20240115-work-md-0-5r6jz-7vb94, iris-gaia-blue-20240115-work-md-0-5r6jz-df5z2, ...

    #
    # OK, so we get the same issue on Arcus and Jade.
    # Assume the directory move worked OK.
    #



