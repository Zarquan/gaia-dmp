#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2024, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#
# AIMetrics: []
#

    Target:

        We have a woking cluster .. time to test it.

    Result:

        Work in progress ...

# -----------------------------------------------------
# Get the location of our cluster config files.
#[root@ansibler]

    # TODO something to put this into the PATH
    export PATH=${PATH}:/deployments/cluster-api/ansible/files/aglais/bin
    source loadconfig


# -----------------------------------------------------
# Run a SOCKS proxy linking our client container to our bootstrap node.
# https://unix.stackexchange.com/questions/34004/how-does-tcp-keepalive-work-in-ssh
# https://unix.stackexchange.com/a/34201
#[root@ansibler]

    ssh \
        -n \
        -f \
        -N \
        -D '*:3000' \
        -o ServerAliveInterval=10 \
        -o ServerAliveCountMax=12 \
        bootstrap

    >   ....
    >   ....


# -----------------------------------------------------
# Modify our kubectl config to add a SOCKS proxy.
#[root@ansibler]

    source loadconfig
    vi "${workclusterconf:?}"

        apiVersion: v1
        kind: Config
        clusters:
        - cluster:
          name: somerville-jade-20240118-work
            ....
            server: https://192.41.122.195:6443
    +       proxy-url: socks5://localhost:3000/


# -----------------------------------------------------
# Check we can access the cluster-info.
#[root@ansibler]

    source loadconfig
    kubectl \
        --kubeconfig "${workclusterconf:?}" \
        cluster-info

    >   Kubernetes control plane is running at https://192.41.122.78:6443
    >   CoreDNS is running at https://192.41.122.78:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy


# -----------------------------------------------------
# Deploy our gaia-dmp Helm chart.
#[root@ansibler]

    source loadconfig

    helm dependency build \
        --kubeconfig "${workclusterconf:?}" \
        '/deployments/cluster-api/helm/gaia-dmp'

    >   Saving 2 charts
    >   Deleting outdated charts


    helm upgrade \
        --wait \
        --debug \
        --kubeconfig "${workclusterconf:?}" \
        'gaia-dmp' \
        '/deployments/cluster-api/helm/gaia-dmp' \
        --install

    >   history.go:56: [debug] getting history for release gaia-dmp
    >   Release "gaia-dmp" does not exist. Installing it now.
    >   install.go:194: [debug] Original chart version: ""
    >   install.go:211: [debug] CHART PATH: /deployments/cluster-api/helm/gaia-dmp
    >   ....
    >   ....
    >   
    >   ready.go:277: [debug] Deployment is not ready: default/zeppelin-server. 0 out of 1 expected pods are ready
    >   ready.go:277: [debug] Deployment is not ready: default/zeppelin-server. 0 out of 1 expected pods are ready
    >   Error: timed out waiting for the condition
    >   helm.go:84: [debug] timed out waiting for the condition


    helm upgrade \
        --wait \
        --debug \
        --kubeconfig "${workclusterconf:?}" \
        'gaia-dmp' \
        '/deployments/cluster-api/helm/gaia-dmp' \
        --install

    >   history.go:56: [debug] getting history for release gaia-dmp
    >   upgrade.go:144: [debug] preparing upgrade for gaia-dmp
    >   upgrade.go:152: [debug] performing update for gaia-dmp
    >   upgrade.go:324: [debug] creating upgraded release for gaia-dmp
    >   client.go:338: [debug] checking 10 resources for changes
    >   client.go:617: [debug] Looks like there are no changes for Namespace "gaia-dmp"
    >   client.go:617: [debug] Looks like there are no changes for ServiceAccount "dashboard-admin-account"
    >   client.go:617: [debug] Looks like there are no changes for ServiceAccount "zeppelin-server"
    >   client.go:617: [debug] Looks like there are no changes for ConfigMap "zeppelin-server-conf-map"
    >   client.go:617: [debug] Looks like there are no changes for ConfigMap "zeppelin-server-conf"
    >   client.go:617: [debug] Looks like there are no changes for ClusterRole "zeppelin-server-role"
    >   client.go:617: [debug] Looks like there are no changes for ClusterRoleBinding "dashboard-admin-binding"
    >   client.go:617: [debug] Looks like there are no changes for RoleBinding "zeppelin-server-role-binding"
    >   client.go:617: [debug] Looks like there are no changes for Service "zeppelin-server"
    >   client.go:626: [debug] Patch Deployment "zeppelin-server" in namespace default
    >   upgrade.go:396: [debug] waiting for release gaia-dmp resources (created: 0 updated: 10  deleted: 0)
    >   wait.go:48: [debug] beginning wait for 10 resources with timeout of 5m0s
    >   upgrade.go:159: [debug] updating status for upgraded release for gaia-dmp
    >   Release "gaia-dmp" has been upgraded. Happy Helming!
    >   NAME: gaia-dmp
    >   LAST DEPLOYED: Thu Jan 25 12:20:23 2024
    >   NAMESPACE: default
    >   STATUS: deployed
    >   REVISION: 2
    >   TEST SUITE: None
    >   ....
    >   ....


# -----------------------------------------------------
# Generate a dashboard token.
#[root@ansibler]

    kubectl \
        --kubeconfig "${workclusterconf:?}" \
        --namespace "gaia-dmp" \
        create token \
            "dashboard-admin-account"

    >   ....
    >   ....


# -----------------------------------------------------
# Launch a kubectl proxy.
#[root@ansibler]

    kubectl \
        --kubeconfig "${workclusterconf:?}" \
        --address 0.0.0.0 \
        proxy \
        &

    >   Starting to serve on [::]:8001


# -----------------------------------------------------
# -----------------------------------------------------
# Get the published port number for our agclient.
#[user@desktop]

    agcolour=jade

    kubeport=$(
        podman container \
            inspect \
                "ansibler-${agcolour:?}" \
                --format json \
        | jq -r '
            .[0]
            | .HostConfig.PortBindings
            | ."8001/tcp"
            | .[0].HostPort
            '
        )

    echo "kubeport [${kubeport}]"

    >   kubeport [41667]


# -----------------------------------------------------
# Launch browser pointed at the dashboard.
#[user@desktop]

    firefox \
        --new-window \
        "http://localhost:${kubeport:?}/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:https/proxy/#/login" \
        &

    #
    # Dashboard works :-)
    #


# -----------------------------------------------------
# Launch browser pointed at Zeppelin.
#[user@desktop]

    firefox \
        --new-window \
        "http://localhost:${kubeport:?}/api/v1/namespaces/default/services/http:zeppelin-server:http/proxy/#/" \
        &

    #
    # Zeppelin responds .. but only part of the front page is displayed.
    # Suspect that multiple proxies ontop of proxies is mangling the 'clever' JS UI app.
    #



