#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2023, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#
# AIMetrics: [{"name": "ChatGPT","contribution": {"value": 0,"units": "%"}}]
#


    Target:

        Test notebook recovery on a test system.

    Result:

        Work in progress ...

# -----------------------------------------------------

    My guess is we can fix this by re-installing the examples for each user using the create-user-tools script.
    https://github.com/wfau/gaia-dmp/blob/15ef8549aaa0a9064cfa399aa719b9772c46f8e1/deployments/zeppelin/bin/create-user-tools.sh#L163-L175

        username='AKrause'
        linuxuid=10012

        username='NWalton'
        linuxuid=10013

        username='HHeinl'
        linuxuid=10014

        username='ZWay'
        linuxuid=10015

        username='SSagear'
        linuxuid=10016

        username='MNizovkina'
        linuxuid=10017

        username='MLucey'
        linuxuid=10018

        username='CWorley'
        linuxuid=10019

        username='MFouesneau'
        linuxuid=10020

        username='SHodgkin'
        linuxuid=10021

        username='MVioque'
        linuxuid=10022


# -----------------------------------------------------
# Check which cloud is currently live.
#[user@desktop]

    ssh fedora@live.gaia-dmp.uk \
        '
        date
        hostname
        '

    >   Thu 18 May 05:17:27 UTC 2023
    >   iris-gaia-green-20230308-zeppelin


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    #
    # Live is green, selecting red for the deployment.
    #

    source "${HOME:?}/aglais.env"

    agcolour=red
    configname=zeppelin-54.86-spark-6.26.43

    agproxymap=3000:3000
    clientname=ansibler-${agcolour}
    cloudname=iris-gaia-${agcolour}

    podman run \
        --rm \
        --tty \
        --interactive \
        --name     "${clientname:?}" \
        --hostname "${clientname:?}" \
        --publish  "${agproxymap:?}" \
        --env "cloudname=${cloudname:?}" \
        --env "configname=${configname:?}" \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK:?}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.07.25 \
        bash

    >   ....
    >   ....


# -----------------------------------------------------
# Deploy everything.
#[root@ansibler]

    time \
        source /deployments/hadoop-yarn/bin/deploy.sh

    >   aglais:
    >     status:
    >       deployment:
    >         type: hadoop-yarn
    >         conf: zeppelin-54.86-spark-6.26.43
    >         name: iris-gaia-red-20230518
    >         date: 20230518T055212
    >         hostname: zeppelin.gaia-dmp.uk
    >     spec:
    >       openstack:
    >         cloud:
    >           base: arcus
    >           name: iris-gaia-red

    >   real    75m8.235s
    >   user    17m37.543s
    >   sys     4m49.487s

    >   ....
    >   ....
    >   changed: [worker03]
    >   changed: [worker01]
    >   changed: [worker02]
    >   changed: [worker04]
    >   changed: [master01]
    >   fatal: [worker06]: FAILED! => {"changed": false, "msg": "Failure downloading https://archive.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz, Request failed: <urlopen error [Errno 101] Network is unreachable>"}
    >   fatal: [worker05]: FAILED! => {"changed": false, "msg": "Failure downloading https://archive.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz, Request failed: <urlopen error [Errno 101] Network is unreachable>"}
    >   fatal: [zeppelin]: FAILED! => {"changed": false, "msg": "Failure downloading https://archive.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz, Request failed: <urlopen error _ssl.c:1059: The handshake operation timed out>"}

    #
    # Some worked, some failed ?
    # Random network issues :-(
    # Contacted Paul Browne on IRIS-TWG Slack to check.

    @Paul Browne
    Hi Paul, just checking, we are seeing some issues downloading files onto our VMs. The download works on some VMs and fails from others. Are there any known network issues ?
    ```
    changed: [worker04]
    changed: [master01]
    fatal: [worker06]: FAILED! => {"changed": false, "msg": "Failure downloading https://archive.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz, Request failed: <urlopen error [Errno 101] Network is unreachable>"}
    fatal: [worker05]: FAILED! => {"changed": false, "msg": "Failure downloading https://archive.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz, Request failed: <urlopen error [Errno 101] Network is unreachable>"}
    fatal: [zeppelin]: FAILED! => {"changed": false, "msg": "Failure downloading https://archive.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz, Request failed: <urlopen error _ssl.c:1059: The handshake operation timed out>"}
    ```

    #
    # Reply from Paul.

    We have been seeing some issues with the OpenVSwitch version that was moved to in recent cloud upgrades
    that smells a bit like this, sporadic outages of outbound traffic. If you can generate a definitive list
    of affected instances, I'll track them down to their hosts and take a look.


